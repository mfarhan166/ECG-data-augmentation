{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "3z162U963uD3",
        "outputId": "a5a9d3e8-9f9e-4730-a467-0fa285edde57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.0\n"
          ]
        }
      ],
      "source": [
        "#Tensorflow version\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "HV0cQHHS3uD3"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Conv2D, Dense, Flatten, BatchNormalization, Dropout, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.efficientnet import EfficientNetB0\n",
        "from keras.preprocessing import image\n",
        "#from keras.preprocessing.image import load_img\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VUCPwgv3uD4"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Rw67Dhca3uD4"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join('path_to/dataset/training/')\n",
        "validation_dir = os.path.join('path_to/dataset/validation/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "OiaD7nlc3uD4",
        "outputId": "65cc8f6f-276c-40e9-9775-04320039b743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 9506 images belonging to 2 classes.\n",
            "Found 1500 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(124, 124),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    )\n",
        "\n",
        "val_data = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(124,124),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B43T3rRd3uD4"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "    # First convolution layer\n",
        "    tf.keras.layers.Conv1D(32, 3, activation='relu', input_shape=(124, 124, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Second convolution layer\n",
        "    tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Third convolution layer\n",
        "    tf.keras.layers.Conv1D(128, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv1D(128, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(96, activation='relu'),\n",
        "   # tf.keras.layers.Dense(100, activation='relu'),\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "qq_OPnJ23uD4",
        "outputId": "afa53875-65fb-4558-c0d8-a0b39195451f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 124, 122, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 62, 61, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 62, 59, 64)        6208      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 31, 29, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 31, 27, 128)       24704     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 15, 13, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 15, 11, 128)       49280     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 7, 5, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 7, 5, 128)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4480)              0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 4480)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 96)                430176    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 97        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 510,785\n",
            "Trainable params: 510,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#print model summary\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "FJQVWmeQ3uD4"
      },
      "outputs": [],
      "source": [
        "#Performance evaluation Metrics delcaration\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adamax,Nadam, Ftrl, Adadelta\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision, AUC\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0001),  #Adamax, 3e-4\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5), AUC(num_thresholds=200,curve='ROC')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "8k51Rp-_3uD4"
      },
      "outputs": [],
      "source": [
        "class mycallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('val_accuracy')>0.99):\n",
        "            print(\"\\n Reached 99% accuracy so cancelling training!\")\n",
        "            self.model.stop_training=True\n",
        "\n",
        "mycallback=mycallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "6tw7c5kn3uD5",
        "outputId": "37aeb763-23dd-4bc1-8f08-7e26682bd882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device Spec:  /job:localhost/replica:0/device:GPU:*\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6918 - accuracy: 0.5508 - sensitivity_at_specificity_2: 0.5000 - specificity_at_sensitivity_2: 0.5135 - recall_2: 0.1759 - precision_2: 0.4222 - auc_2: 0.4947\n",
            "Epoch 1: val_accuracy improved from -inf to 0.48125, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 3s 134ms/step - loss: 0.6849 - accuracy: 0.5719 - sensitivity_at_specificity_2: 0.5385 - specificity_at_sensitivity_2: 0.5526 - recall_2: 0.1462 - precision_2: 0.4222 - auc_2: 0.5067 - val_loss: 0.7342 - val_accuracy: 0.4812 - val_sensitivity_at_specificity_2: 0.1807 - val_specificity_at_sensitivity_2: 0.0649 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.3427\n",
            "Epoch 2/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.6904 - accuracy: 0.5580 - sensitivity_at_specificity_2: 0.5000 - specificity_at_sensitivity_2: 0.5079 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.5243\n",
            "Epoch 2: val_accuracy did not improve from 0.48125\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.6842 - accuracy: 0.5781 - sensitivity_at_specificity_2: 0.4627 - specificity_at_sensitivity_2: 0.4301 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4916 - val_loss: 0.7289 - val_accuracy: 0.4625 - val_sensitivity_at_specificity_2: 0.3256 - val_specificity_at_sensitivity_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4525\n",
            "Epoch 3/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6988 - accuracy: 0.5035 - sensitivity_at_specificity_2: 0.4964 - specificity_at_sensitivity_2: 0.4765 - recall_2: 0.0144 - precision_2: 0.2500 - auc_2: 0.5213        \n",
            "Epoch 3: val_accuracy improved from 0.48125 to 0.53750, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.6979 - accuracy: 0.5000 - sensitivity_at_specificity_2: 0.5294 - specificity_at_sensitivity_2: 0.5210 - recall_2: 0.0196 - precision_2: 0.2308 - auc_2: 0.5175 - val_loss: 0.6910 - val_accuracy: 0.5375 - val_sensitivity_at_specificity_2: 0.0541 - val_specificity_at_sensitivity_2: 0.1860 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4610\n",
            "Epoch 4/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6852 - accuracy: 0.5625 - sensitivity_at_specificity_2: 0.4563 - specificity_at_sensitivity_2: 0.4902 - recall_2: 0.1553 - precision_2: 0.3902 - auc_2: 0.5099\n",
            "Epoch 4: val_accuracy did not improve from 0.53750\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6849 - accuracy: 0.5688 - sensitivity_at_specificity_2: 0.5231 - specificity_at_sensitivity_2: 0.5158 - recall_2: 0.1538 - precision_2: 0.4167 - auc_2: 0.5172 - val_loss: 0.7017 - val_accuracy: 0.4688 - val_sensitivity_at_specificity_2: 0.4706 - val_specificity_at_sensitivity_2: 0.0533 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.5788\n",
            "Epoch 5/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6860 - accuracy: 0.5625 - sensitivity_at_specificity_2: 0.4352 - specificity_at_sensitivity_2: 0.4662 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4784\n",
            "Epoch 5: val_accuracy did not improve from 0.53750\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6911 - accuracy: 0.5437 - sensitivity_at_specificity_2: 0.4930 - specificity_at_sensitivity_2: 0.4270 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4868 - val_loss: 0.7028 - val_accuracy: 0.5125 - val_sensitivity_at_specificity_2: 0.0385 - val_specificity_at_sensitivity_2: 0.3537 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4955\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6807 - accuracy: 0.5938 - sensitivity_at_specificity_2: 0.4308 - specificity_at_sensitivity_2: 0.3895 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4720\n",
            "Epoch 6: val_accuracy did not improve from 0.53750\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6807 - accuracy: 0.5938 - sensitivity_at_specificity_2: 0.4308 - specificity_at_sensitivity_2: 0.3895 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4720 - val_loss: 0.6937 - val_accuracy: 0.5250 - val_sensitivity_at_specificity_2: 0.6842 - val_specificity_at_sensitivity_2: 0.6071 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.6412\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.5437 - sensitivity_at_specificity_2: 0.5141 - specificity_at_sensitivity_2: 0.5056 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4892\n",
            "Epoch 7: val_accuracy did not improve from 0.53750\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6893 - accuracy: 0.5437 - sensitivity_at_specificity_2: 0.5141 - specificity_at_sensitivity_2: 0.5056 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4892 - val_loss: 0.6890 - val_accuracy: 0.5375 - val_sensitivity_at_specificity_2: 0.7568 - val_specificity_at_sensitivity_2: 0.5581 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.6560\n",
            "Epoch 8/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6833 - accuracy: 0.5820 - sensitivity_at_specificity_2: 0.3905 - specificity_at_sensitivity_2: 0.4040 - recall_2: 0.0190 - precision_2: 0.3333 - auc_2: 0.4621       \n",
            "Epoch 8: val_accuracy improved from 0.53750 to 0.55625, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6881 - accuracy: 0.5594 - sensitivity_at_specificity_2: 0.3669 - specificity_at_sensitivity_2: 0.4365 - recall_2: 0.0144 - precision_2: 0.3333 - auc_2: 0.4734 - val_loss: 0.6842 - val_accuracy: 0.5562 - val_sensitivity_at_specificity_2: 0.2394 - val_specificity_at_sensitivity_2: 0.3820 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.7092\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6832 - accuracy: 0.5483 - sensitivity_at_specificity_2: 0.5878 - specificity_at_sensitivity_2: 0.6164 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.5877\n",
            "Epoch 9: val_accuracy did not improve from 0.55625\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.6832 - accuracy: 0.5483 - sensitivity_at_specificity_2: 0.5878 - specificity_at_sensitivity_2: 0.6164 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.5877 - val_loss: 0.7346 - val_accuracy: 0.4062 - val_sensitivity_at_specificity_2: 0.8947 - val_specificity_at_sensitivity_2: 0.5385 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.7406\n",
            "Epoch 10/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6880 - accuracy: 0.5508 - sensitivity_at_specificity_2: 0.4957 - specificity_at_sensitivity_2: 0.4539 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.5200\n",
            "Epoch 10: val_accuracy did not improve from 0.55625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6895 - accuracy: 0.5469 - sensitivity_at_specificity_2: 0.4690 - specificity_at_sensitivity_2: 0.4857 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.5193 - val_loss: 0.7106 - val_accuracy: 0.4500 - val_sensitivity_at_specificity_2: 0.8068 - val_specificity_at_sensitivity_2: 0.5000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.6806\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.5250 - sensitivity_at_specificity_2: 0.4333 - specificity_at_sensitivity_2: 0.4412 - recall_2: 0.0267 - precision_2: 0.4000 - auc_2: 0.4886      \n",
            "Epoch 11: val_accuracy did not improve from 0.55625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6948 - accuracy: 0.5250 - sensitivity_at_specificity_2: 0.4333 - specificity_at_sensitivity_2: 0.4412 - recall_2: 0.0267 - precision_2: 0.4000 - auc_2: 0.4886 - val_loss: 0.6947 - val_accuracy: 0.4812 - val_sensitivity_at_specificity_2: 0.6988 - val_specificity_at_sensitivity_2: 0.6234 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.6817\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.5781 - sensitivity_at_specificity_2: 0.4429 - specificity_at_sensitivity_2: 0.4611 - recall_2: 0.2071 - precision_2: 0.5472 - auc_2: 0.4997\n",
            "Epoch 12: val_accuracy did not improve from 0.55625\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.6886 - accuracy: 0.5781 - sensitivity_at_specificity_2: 0.4429 - specificity_at_sensitivity_2: 0.4611 - recall_2: 0.2071 - precision_2: 0.5472 - auc_2: 0.4997 - val_loss: 0.6930 - val_accuracy: 0.4812 - val_sensitivity_at_specificity_2: 0.6988 - val_specificity_at_sensitivity_2: 0.7143 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.7153\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.5063 - sensitivity_at_specificity_2: 0.5316 - specificity_at_sensitivity_2: 0.5185 - recall_2: 0.1582 - precision_2: 0.5000 - auc_2: 0.5290\n",
            "Epoch 13: val_accuracy did not improve from 0.55625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6923 - accuracy: 0.5063 - sensitivity_at_specificity_2: 0.5316 - specificity_at_sensitivity_2: 0.5185 - recall_2: 0.1582 - precision_2: 0.5000 - auc_2: 0.5290 - val_loss: 0.6879 - val_accuracy: 0.5063 - val_sensitivity_at_specificity_2: 0.8228 - val_specificity_at_sensitivity_2: 0.6296 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.7784\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6743 - accuracy: 0.6031 - sensitivity_at_specificity_2: 0.5194 - specificity_at_sensitivity_2: 0.5497 - recall_2: 0.0543 - precision_2: 0.5833 - auc_2: 0.5557\n",
            "Epoch 14: val_accuracy did not improve from 0.55625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6743 - accuracy: 0.6031 - sensitivity_at_specificity_2: 0.5194 - specificity_at_sensitivity_2: 0.5497 - recall_2: 0.0543 - precision_2: 0.5833 - auc_2: 0.5557 - val_loss: 0.6970 - val_accuracy: 0.5188 - val_sensitivity_at_specificity_2: 0.8571 - val_specificity_at_sensitivity_2: 0.8193 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.7677\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6975 - accuracy: 0.5219 - sensitivity_at_specificity_2: 0.5948 - specificity_at_sensitivity_2: 0.5329 - recall_2: 0.0065 - precision_2: 0.5000 - auc_2: 0.5608        \n",
            "Epoch 15: val_accuracy did not improve from 0.55625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6975 - accuracy: 0.5219 - sensitivity_at_specificity_2: 0.5948 - specificity_at_sensitivity_2: 0.5329 - recall_2: 0.0065 - precision_2: 0.5000 - auc_2: 0.5608 - val_loss: 0.6831 - val_accuracy: 0.5250 - val_sensitivity_at_specificity_2: 0.8947 - val_specificity_at_sensitivity_2: 0.8095 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.8582\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.5437 - sensitivity_at_specificity_2: 0.5789 - specificity_at_sensitivity_2: 0.6190 - recall_2: 0.2566 - precision_2: 0.5417 - auc_2: 0.5577\n",
            "Epoch 16: val_accuracy improved from 0.55625 to 0.69375, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6886 - accuracy: 0.5437 - sensitivity_at_specificity_2: 0.5789 - specificity_at_sensitivity_2: 0.6190 - recall_2: 0.2566 - precision_2: 0.5417 - auc_2: 0.5577 - val_loss: 0.6854 - val_accuracy: 0.6938 - val_sensitivity_at_specificity_2: 0.8243 - val_specificity_at_sensitivity_2: 0.8953 - val_recall_2: 0.8649 - val_precision_2: 0.6214 - val_auc_2: 0.7987\n",
            "Epoch 17/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6867 - accuracy: 0.5742 - sensitivity_at_specificity_2: 0.5126 - specificity_at_sensitivity_2: 0.5766 - recall_2: 0.4286 - precision_2: 0.5543 - auc_2: 0.5706\n",
            "Epoch 17: val_accuracy did not improve from 0.69375\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.6845 - accuracy: 0.5875 - sensitivity_at_specificity_2: 0.5857 - specificity_at_sensitivity_2: 0.6056 - recall_2: 0.4214 - precision_2: 0.5364 - auc_2: 0.5785 - val_loss: 0.6859 - val_accuracy: 0.4625 - val_sensitivity_at_specificity_2: 0.9205 - val_specificity_at_sensitivity_2: 0.8750 - val_recall_2: 0.0227 - val_precision_2: 1.0000 - val_auc_2: 0.8410\n",
            "Epoch 18/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6882 - accuracy: 0.5312 - sensitivity_at_specificity_2: 0.6129 - specificity_at_sensitivity_2: 0.5455 - recall_2: 0.0806 - precision_2: 0.6250 - auc_2: 0.5767\n",
            "Epoch 18: val_accuracy did not improve from 0.69375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6928 - accuracy: 0.5188 - sensitivity_at_specificity_2: 0.5633 - specificity_at_sensitivity_2: 0.5370 - recall_2: 0.0633 - precision_2: 0.6250 - auc_2: 0.5510 - val_loss: 0.6904 - val_accuracy: 0.4750 - val_sensitivity_at_specificity_2: 0.8929 - val_specificity_at_sensitivity_2: 0.8158 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.7979\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6788 - accuracy: 0.5688 - sensitivity_at_specificity_2: 0.5643 - specificity_at_sensitivity_2: 0.5667 - recall_2: 0.0643 - precision_2: 0.5625 - auc_2: 0.6037      \n",
            "Epoch 19: val_accuracy did not improve from 0.69375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6788 - accuracy: 0.5688 - sensitivity_at_specificity_2: 0.5643 - specificity_at_sensitivity_2: 0.5667 - recall_2: 0.0643 - precision_2: 0.5625 - auc_2: 0.6037 - val_loss: 0.6851 - val_accuracy: 0.4812 - val_sensitivity_at_specificity_2: 0.9157 - val_specificity_at_sensitivity_2: 0.8701 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.8507\n",
            "Epoch 20/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6796 - accuracy: 0.5469 - sensitivity_at_specificity_2: 0.6667 - specificity_at_sensitivity_2: 0.6115 - recall_2: 0.0342 - precision_2: 0.5714 - auc_2: 0.6295\n",
            "Epoch 20: val_accuracy did not improve from 0.69375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6823 - accuracy: 0.5406 - sensitivity_at_specificity_2: 0.6400 - specificity_at_sensitivity_2: 0.5941 - recall_2: 0.0467 - precision_2: 0.6364 - auc_2: 0.6162 - val_loss: 0.6849 - val_accuracy: 0.4812 - val_sensitivity_at_specificity_2: 0.8434 - val_specificity_at_sensitivity_2: 0.8442 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.7901\n",
            "Epoch 21/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.6793 - accuracy: 0.5670 - sensitivity_at_specificity_2: 0.6200 - specificity_at_sensitivity_2: 0.6371 - recall_2: 0.0900 - precision_2: 0.6000 - auc_2: 0.6118\n",
            "Epoch 21: val_accuracy did not improve from 0.69375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6844 - accuracy: 0.5375 - sensitivity_at_specificity_2: 0.5894 - specificity_at_sensitivity_2: 0.6391 - recall_2: 0.0662 - precision_2: 0.5882 - auc_2: 0.6060 - val_loss: 0.6685 - val_accuracy: 0.5437 - val_sensitivity_at_specificity_2: 0.9041 - val_specificity_at_sensitivity_2: 0.8736 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.8442\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6709 - accuracy: 0.5897 - sensitivity_at_specificity_2: 0.7063 - specificity_at_sensitivity_2: 0.7317 - recall_2: 0.1270 - precision_2: 0.6400 - auc_2: 0.6653\n",
            "Epoch 22: val_accuracy did not improve from 0.69375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6709 - accuracy: 0.5897 - sensitivity_at_specificity_2: 0.7063 - specificity_at_sensitivity_2: 0.7317 - recall_2: 0.1270 - precision_2: 0.6400 - auc_2: 0.6653 - val_loss: 0.6917 - val_accuracy: 0.4875 - val_sensitivity_at_specificity_2: 0.9024 - val_specificity_at_sensitivity_2: 0.7821 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.7792\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.5344 - sensitivity_at_specificity_2: 0.7133 - specificity_at_sensitivity_2: 0.7059 - recall_2: 0.0067 - precision_2: 1.0000 - auc_2: 0.6468        \n",
            "Epoch 23: val_accuracy did not improve from 0.69375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6811 - accuracy: 0.5344 - sensitivity_at_specificity_2: 0.7133 - specificity_at_sensitivity_2: 0.7059 - recall_2: 0.0067 - precision_2: 1.0000 - auc_2: 0.6468 - val_loss: 0.6695 - val_accuracy: 0.5125 - val_sensitivity_at_specificity_2: 0.8718 - val_specificity_at_sensitivity_2: 0.8780 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.8286\n",
            "Epoch 24/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6661 - accuracy: 0.6055 - sensitivity_at_specificity_2: 0.7586 - specificity_at_sensitivity_2: 0.7643 - recall_2: 0.1466 - precision_2: 0.8947 - auc_2: 0.7066\n",
            "Epoch 24: val_accuracy improved from 0.69375 to 0.73125, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6650 - accuracy: 0.6062 - sensitivity_at_specificity_2: 0.7708 - specificity_at_sensitivity_2: 0.7500 - recall_2: 0.1528 - precision_2: 0.8462 - auc_2: 0.7072 - val_loss: 0.6585 - val_accuracy: 0.7312 - val_sensitivity_at_specificity_2: 0.9200 - val_specificity_at_sensitivity_2: 0.8706 - val_recall_2: 0.4267 - val_precision_2: 1.0000 - val_auc_2: 0.8525\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6720 - accuracy: 0.6531 - sensitivity_at_specificity_2: 0.7200 - specificity_at_sensitivity_2: 0.7706 - recall_2: 0.5067 - precision_2: 0.6726 - auc_2: 0.6855\n",
            "Epoch 25: val_accuracy did not improve from 0.73125\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6720 - accuracy: 0.6531 - sensitivity_at_specificity_2: 0.7200 - specificity_at_sensitivity_2: 0.7706 - recall_2: 0.5067 - precision_2: 0.6726 - auc_2: 0.6855 - val_loss: 0.6585 - val_accuracy: 0.6687 - val_sensitivity_at_specificity_2: 0.9405 - val_specificity_at_sensitivity_2: 0.8553 - val_recall_2: 0.4881 - val_precision_2: 0.8039 - val_auc_2: 0.8356\n",
            "Epoch 26/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6997 - accuracy: 0.5708 - sensitivity_at_specificity_2: 0.5208 - specificity_at_sensitivity_2: 0.5000 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.5146           \n",
            "Epoch 26: val_accuracy did not improve from 0.73125\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.7111 - accuracy: 0.5448 - sensitivity_at_specificity_2: 0.5420 - specificity_at_sensitivity_2: 0.5094 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.5402 - val_loss: 0.6719 - val_accuracy: 0.5000 - val_sensitivity_at_specificity_2: 0.9125 - val_specificity_at_sensitivity_2: 0.9250 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.8430\n",
            "Epoch 27/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.6709 - accuracy: 0.6116 - sensitivity_at_specificity_2: 0.6733 - specificity_at_sensitivity_2: 0.7073 - recall_2: 0.5941 - precision_2: 0.5660 - auc_2: 0.6447       \n",
            "Epoch 27: val_accuracy did not improve from 0.73125\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6782 - accuracy: 0.5750 - sensitivity_at_specificity_2: 0.6791 - specificity_at_sensitivity_2: 0.6774 - recall_2: 0.6866 - precision_2: 0.4946 - auc_2: 0.6270 - val_loss: 0.6596 - val_accuracy: 0.6812 - val_sensitivity_at_specificity_2: 0.9277 - val_specificity_at_sensitivity_2: 0.9481 - val_recall_2: 0.9880 - val_precision_2: 0.6212 - val_auc_2: 0.8873\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6683 - accuracy: 0.6125 - sensitivity_at_specificity_2: 0.6857 - specificity_at_sensitivity_2: 0.6944 - recall_2: 0.2929 - precision_2: 0.6212 - auc_2: 0.6239\n",
            "Epoch 28: val_accuracy did not improve from 0.73125\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.6683 - accuracy: 0.6125 - sensitivity_at_specificity_2: 0.6857 - specificity_at_sensitivity_2: 0.6944 - recall_2: 0.2929 - precision_2: 0.6212 - auc_2: 0.6239 - val_loss: 0.6357 - val_accuracy: 0.6062 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 0.8969 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.8542\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.5188 - sensitivity_at_specificity_2: 0.7083 - specificity_at_sensitivity_2: 0.6184 - recall_2: 0.1190 - precision_2: 0.7692 - auc_2: 0.6330       \n",
            "Epoch 29: val_accuracy did not improve from 0.73125\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6928 - accuracy: 0.5188 - sensitivity_at_specificity_2: 0.7083 - specificity_at_sensitivity_2: 0.6184 - recall_2: 0.1190 - precision_2: 0.7692 - auc_2: 0.6330 - val_loss: 0.6640 - val_accuracy: 0.7125 - val_sensitivity_at_specificity_2: 0.8493 - val_specificity_at_sensitivity_2: 0.8621 - val_recall_2: 0.8219 - val_precision_2: 0.6452 - val_auc_2: 0.8040\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6756 - accuracy: 0.5969 - sensitivity_at_specificity_2: 0.6934 - specificity_at_sensitivity_2: 0.6448 - recall_2: 0.4964 - precision_2: 0.5312 - auc_2: 0.6267\n",
            "Epoch 30: val_accuracy did not improve from 0.73125\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6756 - accuracy: 0.5969 - sensitivity_at_specificity_2: 0.6934 - specificity_at_sensitivity_2: 0.6448 - recall_2: 0.4964 - precision_2: 0.5312 - auc_2: 0.6267 - val_loss: 0.6554 - val_accuracy: 0.5562 - val_sensitivity_at_specificity_2: 0.8734 - val_specificity_at_sensitivity_2: 0.9136 - val_recall_2: 0.1013 - val_precision_2: 1.0000 - val_auc_2: 0.8306\n",
            "Epoch 31/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.6492 - accuracy: 0.6116 - sensitivity_at_specificity_2: 0.7241 - specificity_at_sensitivity_2: 0.7591 - recall_2: 0.0460 - precision_2: 0.5000 - auc_2: 0.6741\n",
            "Epoch 31: val_accuracy did not improve from 0.73125\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6544 - accuracy: 0.5938 - sensitivity_at_specificity_2: 0.6846 - specificity_at_sensitivity_2: 0.6789 - recall_2: 0.0308 - precision_2: 0.5000 - auc_2: 0.6476 - val_loss: 0.6733 - val_accuracy: 0.5125 - val_sensitivity_at_specificity_2: 0.9487 - val_specificity_at_sensitivity_2: 0.8537 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.8269\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6514 - accuracy: 0.5813 - sensitivity_at_specificity_2: 0.8095 - specificity_at_sensitivity_2: 0.8439 - recall_2: 0.1565 - precision_2: 0.6970 - auc_2: 0.7465      \n",
            "Epoch 32: val_accuracy improved from 0.73125 to 0.78125, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6514 - accuracy: 0.5813 - sensitivity_at_specificity_2: 0.8095 - specificity_at_sensitivity_2: 0.8439 - recall_2: 0.1565 - precision_2: 0.6970 - auc_2: 0.7465 - val_loss: 0.6446 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.8690 - val_specificity_at_sensitivity_2: 0.8947 - val_recall_2: 0.7738 - val_precision_2: 0.8025 - val_auc_2: 0.8225\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6546 - accuracy: 0.6625 - sensitivity_at_specificity_2: 0.8199 - specificity_at_sensitivity_2: 0.8050 - recall_2: 0.7453 - precision_2: 0.6417 - auc_2: 0.7442\n",
            "Epoch 33: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6546 - accuracy: 0.6625 - sensitivity_at_specificity_2: 0.8199 - specificity_at_sensitivity_2: 0.8050 - recall_2: 0.7453 - precision_2: 0.6417 - auc_2: 0.7442 - val_loss: 0.6382 - val_accuracy: 0.7125 - val_sensitivity_at_specificity_2: 0.8721 - val_specificity_at_sensitivity_2: 0.8784 - val_recall_2: 0.8721 - val_precision_2: 0.6818 - val_auc_2: 0.7967\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6364 - accuracy: 0.6781 - sensitivity_at_specificity_2: 0.8099 - specificity_at_sensitivity_2: 0.8427 - recall_2: 0.5282 - precision_2: 0.6757 - auc_2: 0.7405\n",
            "Epoch 34: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.6364 - accuracy: 0.6781 - sensitivity_at_specificity_2: 0.8099 - specificity_at_sensitivity_2: 0.8427 - recall_2: 0.5282 - precision_2: 0.6757 - auc_2: 0.7405 - val_loss: 0.6511 - val_accuracy: 0.5125 - val_sensitivity_at_specificity_2: 0.8608 - val_specificity_at_sensitivity_2: 0.8765 - val_recall_2: 0.0127 - val_precision_2: 1.0000 - val_auc_2: 0.8216\n",
            "Epoch 35/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6211 - accuracy: 0.5938 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.7671 - recall_2: 0.1455 - precision_2: 0.6154 - auc_2: 0.7627\n",
            "Epoch 35: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6156 - accuracy: 0.6125 - sensitivity_at_specificity_2: 0.9270 - specificity_at_sensitivity_2: 0.7923 - recall_2: 0.1898 - precision_2: 0.6667 - auc_2: 0.7746 - val_loss: 0.6136 - val_accuracy: 0.7063 - val_sensitivity_at_specificity_2: 0.9079 - val_specificity_at_sensitivity_2: 0.8929 - val_recall_2: 0.5000 - val_precision_2: 0.8085 - val_auc_2: 0.8103\n",
            "Epoch 36/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6249 - accuracy: 0.6367 - sensitivity_at_specificity_2: 0.7980 - specificity_at_sensitivity_2: 0.7325 - recall_2: 0.1717 - precision_2: 0.6071 - auc_2: 0.6860\n",
            "Epoch 36: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6355 - accuracy: 0.6156 - sensitivity_at_specificity_2: 0.8088 - specificity_at_sensitivity_2: 0.7337 - recall_2: 0.1912 - precision_2: 0.6667 - auc_2: 0.7047 - val_loss: 0.5884 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9552 - val_specificity_at_sensitivity_2: 0.8925 - val_recall_2: 0.8209 - val_precision_2: 0.6471 - val_auc_2: 0.8592\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6485 - accuracy: 0.6344 - sensitivity_at_specificity_2: 0.8042 - specificity_at_sensitivity_2: 0.8362 - recall_2: 0.8951 - precision_2: 0.5565 - auc_2: 0.7447\n",
            "Epoch 37: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6485 - accuracy: 0.6344 - sensitivity_at_specificity_2: 0.8042 - specificity_at_sensitivity_2: 0.8362 - recall_2: 0.8951 - precision_2: 0.5565 - auc_2: 0.7447 - val_loss: 0.6061 - val_accuracy: 0.6500 - val_sensitivity_at_specificity_2: 0.9750 - val_specificity_at_sensitivity_2: 0.8625 - val_recall_2: 0.4125 - val_precision_2: 0.7857 - val_auc_2: 0.8453\n",
            "Epoch 38/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6535 - accuracy: 0.5938 - sensitivity_at_specificity_2: 0.8190 - specificity_at_sensitivity_2: 0.7929 - recall_2: 0.1466 - precision_2: 0.7727 - auc_2: 0.7036\n",
            "Epoch 38: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6474 - accuracy: 0.6094 - sensitivity_at_specificity_2: 0.8227 - specificity_at_sensitivity_2: 0.7318 - recall_2: 0.2057 - precision_2: 0.6905 - auc_2: 0.6863 - val_loss: 0.6021 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9259 - val_specificity_at_sensitivity_2: 0.8228 - val_recall_2: 0.8272 - val_precision_2: 0.6907 - val_auc_2: 0.8133\n",
            "Epoch 39/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.6258 - accuracy: 0.6830 - sensitivity_at_specificity_2: 0.8584 - specificity_at_sensitivity_2: 0.8649 - recall_2: 0.8053 - precision_2: 0.6500 - auc_2: 0.7650\n",
            "Epoch 39: val_accuracy improved from 0.78125 to 0.78750, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6235 - accuracy: 0.6812 - sensitivity_at_specificity_2: 0.8659 - specificity_at_sensitivity_2: 0.8526 - recall_2: 0.7988 - precision_2: 0.6550 - auc_2: 0.7582 - val_loss: 0.5741 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9014 - val_specificity_at_sensitivity_2: 0.8876 - val_recall_2: 0.8310 - val_precision_2: 0.7284 - val_auc_2: 0.8517\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.6483 - sensitivity_at_specificity_2: 0.8615 - specificity_at_sensitivity_2: 0.8000 - recall_2: 0.4000 - precision_2: 0.6842 - auc_2: 0.7398\n",
            "Epoch 40: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6197 - accuracy: 0.6483 - sensitivity_at_specificity_2: 0.8615 - specificity_at_sensitivity_2: 0.8000 - recall_2: 0.4000 - precision_2: 0.6842 - auc_2: 0.7398 - val_loss: 0.6888 - val_accuracy: 0.5063 - val_sensitivity_at_specificity_2: 0.8293 - val_specificity_at_sensitivity_2: 0.8077 - val_recall_2: 0.0366 - val_precision_2: 1.0000 - val_auc_2: 0.7511\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.6406 - sensitivity_at_specificity_2: 0.8108 - specificity_at_sensitivity_2: 0.7442 - recall_2: 0.5405 - precision_2: 0.6299 - auc_2: 0.7249\n",
            "Epoch 41: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6193 - accuracy: 0.6406 - sensitivity_at_specificity_2: 0.8108 - specificity_at_sensitivity_2: 0.7442 - recall_2: 0.5405 - precision_2: 0.6299 - auc_2: 0.7249 - val_loss: 0.5739 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.8977 - val_specificity_at_sensitivity_2: 0.9167 - val_recall_2: 0.8750 - val_precision_2: 0.7196 - val_auc_2: 0.8492\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6084 - accuracy: 0.6469 - sensitivity_at_specificity_2: 0.8478 - specificity_at_sensitivity_2: 0.7582 - recall_2: 0.5290 - precision_2: 0.6033 - auc_2: 0.7194\n",
            "Epoch 42: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6084 - accuracy: 0.6469 - sensitivity_at_specificity_2: 0.8478 - specificity_at_sensitivity_2: 0.7582 - recall_2: 0.5290 - precision_2: 0.6033 - auc_2: 0.7194 - val_loss: 0.6196 - val_accuracy: 0.6750 - val_sensitivity_at_specificity_2: 0.9048 - val_specificity_at_sensitivity_2: 0.8684 - val_recall_2: 0.4643 - val_precision_2: 0.8478 - val_auc_2: 0.8125\n",
            "Epoch 43/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.6367 - accuracy: 0.6518 - sensitivity_at_specificity_2: 0.7879 - specificity_at_sensitivity_2: 0.7680 - recall_2: 0.5859 - precision_2: 0.6105 - auc_2: 0.6924\n",
            "Epoch 43: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6308 - accuracy: 0.6562 - sensitivity_at_specificity_2: 0.8058 - specificity_at_sensitivity_2: 0.8066 - recall_2: 0.6619 - precision_2: 0.5935 - auc_2: 0.7117 - val_loss: 0.5815 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9157 - val_specificity_at_sensitivity_2: 0.9351 - val_recall_2: 0.6386 - val_precision_2: 0.8281 - val_auc_2: 0.8454\n",
            "Epoch 44/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5783 - accuracy: 0.6389 - sensitivity_at_specificity_2: 0.9083 - specificity_at_sensitivity_2: 0.8512 - recall_2: 0.2667 - precision_2: 0.6667 - auc_2: 0.7905\n",
            "Epoch 44: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5763 - accuracy: 0.6562 - sensitivity_at_specificity_2: 0.9104 - specificity_at_sensitivity_2: 0.8495 - recall_2: 0.3060 - precision_2: 0.7069 - auc_2: 0.7961 - val_loss: 0.5654 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9398 - val_specificity_at_sensitivity_2: 0.9091 - val_recall_2: 0.6024 - val_precision_2: 0.8621 - val_auc_2: 0.8528\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.6875 - sensitivity_at_specificity_2: 0.8679 - specificity_at_sensitivity_2: 0.8012 - recall_2: 0.8050 - precision_2: 0.6497 - auc_2: 0.7378\n",
            "Epoch 45: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6156 - accuracy: 0.6875 - sensitivity_at_specificity_2: 0.8679 - specificity_at_sensitivity_2: 0.8012 - recall_2: 0.8050 - precision_2: 0.6497 - auc_2: 0.7378 - val_loss: 0.5579 - val_accuracy: 0.7188 - val_sensitivity_at_specificity_2: 0.9186 - val_specificity_at_sensitivity_2: 0.9324 - val_recall_2: 0.8837 - val_precision_2: 0.6847 - val_auc_2: 0.8484\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5937 - accuracy: 0.7063 - sensitivity_at_specificity_2: 0.8824 - specificity_at_sensitivity_2: 0.8443 - recall_2: 0.6797 - precision_2: 0.6980 - auc_2: 0.7696\n",
            "Epoch 46: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5937 - accuracy: 0.7063 - sensitivity_at_specificity_2: 0.8824 - specificity_at_sensitivity_2: 0.8443 - recall_2: 0.6797 - precision_2: 0.6980 - auc_2: 0.7696 - val_loss: 0.5175 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9733 - val_specificity_at_sensitivity_2: 0.9059 - val_recall_2: 0.8000 - val_precision_2: 0.7229 - val_auc_2: 0.8693\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6048 - accuracy: 0.6531 - sensitivity_at_specificity_2: 0.7800 - specificity_at_sensitivity_2: 0.8235 - recall_2: 0.7400 - precision_2: 0.6066 - auc_2: 0.7470\n",
            "Epoch 47: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6048 - accuracy: 0.6531 - sensitivity_at_specificity_2: 0.7800 - specificity_at_sensitivity_2: 0.8235 - recall_2: 0.7400 - precision_2: 0.6066 - auc_2: 0.7470 - val_loss: 0.5452 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9419 - val_specificity_at_sensitivity_2: 0.8649 - val_recall_2: 0.8605 - val_precision_2: 0.7255 - val_auc_2: 0.8203\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5580 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.9247 - specificity_at_sensitivity_2: 0.8391 - recall_2: 0.6644 - precision_2: 0.6879 - auc_2: 0.7877\n",
            "Epoch 48: val_accuracy improved from 0.78750 to 0.79375, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.5580 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.9247 - specificity_at_sensitivity_2: 0.8391 - recall_2: 0.6644 - precision_2: 0.6879 - auc_2: 0.7877 - val_loss: 0.5124 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9560 - val_specificity_at_sensitivity_2: 0.9275 - val_recall_2: 0.8352 - val_precision_2: 0.8085 - val_auc_2: 0.8620\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5917 - accuracy: 0.6906 - sensitivity_at_specificity_2: 0.8333 - specificity_at_sensitivity_2: 0.8176 - recall_2: 0.7000 - precision_2: 0.6604 - auc_2: 0.7529\n",
            "Epoch 49: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5917 - accuracy: 0.6906 - sensitivity_at_specificity_2: 0.8333 - specificity_at_sensitivity_2: 0.8176 - recall_2: 0.7000 - precision_2: 0.6604 - auc_2: 0.7529 - val_loss: 0.5205 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9659 - val_specificity_at_sensitivity_2: 0.9306 - val_recall_2: 0.7955 - val_precision_2: 0.7955 - val_auc_2: 0.8504\n",
            "Epoch 50/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5582 - accuracy: 0.7455 - sensitivity_at_specificity_2: 0.8710 - specificity_at_sensitivity_2: 0.8550 - recall_2: 0.7527 - precision_2: 0.6731 - auc_2: 0.7941\n",
            "Epoch 50: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5534 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.8832 - specificity_at_sensitivity_2: 0.8743 - recall_2: 0.7372 - precision_2: 0.6918 - auc_2: 0.7998 - val_loss: 0.5125 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9241 - val_specificity_at_sensitivity_2: 0.9383 - val_recall_2: 0.7595 - val_precision_2: 0.7692 - val_auc_2: 0.8606\n",
            "Epoch 51/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5641 - accuracy: 0.7009 - sensitivity_at_specificity_2: 0.9020 - specificity_at_sensitivity_2: 0.8689 - recall_2: 0.7255 - precision_2: 0.6549 - auc_2: 0.7907\n",
            "Epoch 51: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5453 - accuracy: 0.7156 - sensitivity_at_specificity_2: 0.9565 - specificity_at_sensitivity_2: 0.8626 - recall_2: 0.7319 - precision_2: 0.6516 - auc_2: 0.8026 - val_loss: 0.5829 - val_accuracy: 0.6812 - val_sensitivity_at_specificity_2: 0.9012 - val_specificity_at_sensitivity_2: 0.8861 - val_recall_2: 0.4691 - val_precision_2: 0.8261 - val_auc_2: 0.8294\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.7031 - sensitivity_at_specificity_2: 0.8533 - specificity_at_sensitivity_2: 0.8059 - recall_2: 0.7200 - precision_2: 0.6708 - auc_2: 0.7581\n",
            "Epoch 52: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5859 - accuracy: 0.7031 - sensitivity_at_specificity_2: 0.8533 - specificity_at_sensitivity_2: 0.8059 - recall_2: 0.7200 - precision_2: 0.6708 - auc_2: 0.7581 - val_loss: 0.5069 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9432 - val_specificity_at_sensitivity_2: 0.9167 - val_recall_2: 0.8068 - val_precision_2: 0.7889 - val_auc_2: 0.8608\n",
            "Epoch 53/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.6049 - accuracy: 0.6964 - sensitivity_at_specificity_2: 0.8400 - specificity_at_sensitivity_2: 0.8548 - recall_2: 0.5700 - precision_2: 0.6951 - auc_2: 0.7570\n",
            "Epoch 53: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5872 - accuracy: 0.6906 - sensitivity_at_specificity_2: 0.8357 - specificity_at_sensitivity_2: 0.8278 - recall_2: 0.6357 - precision_2: 0.6496 - auc_2: 0.7594 - val_loss: 0.5152 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9459 - val_specificity_at_sensitivity_2: 0.9302 - val_recall_2: 0.8514 - val_precision_2: 0.7241 - val_auc_2: 0.8559\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5604 - accuracy: 0.6906 - sensitivity_at_specificity_2: 0.9172 - specificity_at_sensitivity_2: 0.8800 - recall_2: 0.7241 - precision_2: 0.6402 - auc_2: 0.7894\n",
            "Epoch 54: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5604 - accuracy: 0.6906 - sensitivity_at_specificity_2: 0.9172 - specificity_at_sensitivity_2: 0.8800 - recall_2: 0.7241 - precision_2: 0.6402 - auc_2: 0.7894 - val_loss: 0.5091 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9359 - val_specificity_at_sensitivity_2: 0.8902 - val_recall_2: 0.8077 - val_precision_2: 0.7326 - val_auc_2: 0.8498\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5638 - accuracy: 0.6969 - sensitivity_at_specificity_2: 0.8873 - specificity_at_sensitivity_2: 0.8933 - recall_2: 0.7324 - precision_2: 0.6380 - auc_2: 0.7953\n",
            "Epoch 55: val_accuracy improved from 0.79375 to 0.85625, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.5638 - accuracy: 0.6969 - sensitivity_at_specificity_2: 0.8873 - specificity_at_sensitivity_2: 0.8933 - recall_2: 0.7324 - precision_2: 0.6380 - auc_2: 0.7953 - val_loss: 0.4949 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9405 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8214 - val_precision_2: 0.8961 - val_auc_2: 0.8983\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.7156 - sensitivity_at_specificity_2: 0.9000 - specificity_at_sensitivity_2: 0.8353 - recall_2: 0.7600 - precision_2: 0.6746 - auc_2: 0.7912\n",
            "Epoch 56: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5574 - accuracy: 0.7156 - sensitivity_at_specificity_2: 0.9000 - specificity_at_sensitivity_2: 0.8353 - recall_2: 0.7600 - precision_2: 0.6746 - auc_2: 0.7912 - val_loss: 0.4882 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9655 - val_specificity_at_sensitivity_2: 0.9315 - val_recall_2: 0.8391 - val_precision_2: 0.7935 - val_auc_2: 0.8763\n",
            "Epoch 57/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5736 - accuracy: 0.7227 - sensitivity_at_specificity_2: 0.8814 - specificity_at_sensitivity_2: 0.8841 - recall_2: 0.6864 - precision_2: 0.7043 - auc_2: 0.7927\n",
            "Epoch 57: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5629 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8944 - specificity_at_sensitivity_2: 0.8764 - recall_2: 0.6831 - precision_2: 0.6929 - auc_2: 0.7949 - val_loss: 0.5465 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9189 - val_specificity_at_sensitivity_2: 0.9070 - val_recall_2: 0.5946 - val_precision_2: 0.8000 - val_auc_2: 0.8264\n",
            "Epoch 58/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5551 - accuracy: 0.7227 - sensitivity_at_specificity_2: 0.8852 - specificity_at_sensitivity_2: 0.8881 - recall_2: 0.7377 - precision_2: 0.6977 - auc_2: 0.7999\n",
            "Epoch 58: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5469 - accuracy: 0.7219 - sensitivity_at_specificity_2: 0.8782 - specificity_at_sensitivity_2: 0.9024 - recall_2: 0.7628 - precision_2: 0.6959 - auc_2: 0.8065 - val_loss: 0.5353 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9024 - val_specificity_at_sensitivity_2: 0.8846 - val_recall_2: 0.8537 - val_precision_2: 0.7000 - val_auc_2: 0.8336\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5485 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8926 - specificity_at_sensitivity_2: 0.8538 - recall_2: 0.7517 - precision_2: 0.6871 - auc_2: 0.8014\n",
            "Epoch 59: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5485 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8926 - specificity_at_sensitivity_2: 0.8538 - recall_2: 0.7517 - precision_2: 0.6871 - auc_2: 0.8014 - val_loss: 0.5032 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9079 - val_specificity_at_sensitivity_2: 0.9643 - val_recall_2: 0.8421 - val_precision_2: 0.7356 - val_auc_2: 0.8614\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5161 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9051 - specificity_at_sensitivity_2: 0.9016 - recall_2: 0.7591 - precision_2: 0.6842 - auc_2: 0.8298\n",
            "Epoch 60: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5161 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9051 - specificity_at_sensitivity_2: 0.9016 - recall_2: 0.7591 - precision_2: 0.6842 - auc_2: 0.8298 - val_loss: 0.6180 - val_accuracy: 0.7188 - val_sensitivity_at_specificity_2: 0.9011 - val_specificity_at_sensitivity_2: 0.9855 - val_recall_2: 0.5714 - val_precision_2: 0.8966 - val_auc_2: 0.8422\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9270 - specificity_at_sensitivity_2: 0.9344 - recall_2: 0.7372 - precision_2: 0.7266 - auc_2: 0.8520\n",
            "Epoch 61: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4943 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9270 - specificity_at_sensitivity_2: 0.9344 - recall_2: 0.7372 - precision_2: 0.7266 - auc_2: 0.8520 - val_loss: 0.4974 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9296 - val_specificity_at_sensitivity_2: 0.9326 - val_recall_2: 0.8169 - val_precision_2: 0.7436 - val_auc_2: 0.8612\n",
            "Epoch 62/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5179 - accuracy: 0.7305 - sensitivity_at_specificity_2: 0.9364 - specificity_at_sensitivity_2: 0.9178 - recall_2: 0.7364 - precision_2: 0.6694 - auc_2: 0.8276\n",
            "Epoch 62: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5260 - accuracy: 0.7219 - sensitivity_at_specificity_2: 0.9225 - specificity_at_sensitivity_2: 0.9157 - recall_2: 0.7254 - precision_2: 0.6732 - auc_2: 0.8203 - val_loss: 0.5029 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9659 - val_specificity_at_sensitivity_2: 0.9861 - val_recall_2: 0.7159 - val_precision_2: 0.8630 - val_auc_2: 0.8840\n",
            "Epoch 63/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5675 - accuracy: 0.7109 - sensitivity_at_specificity_2: 0.8793 - specificity_at_sensitivity_2: 0.8500 - recall_2: 0.7845 - precision_2: 0.6500 - auc_2: 0.7849\n",
            "Epoch 63: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5700 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.8792 - specificity_at_sensitivity_2: 0.8480 - recall_2: 0.7517 - precision_2: 0.6667 - auc_2: 0.7798 - val_loss: 0.4915 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9718 - val_specificity_at_sensitivity_2: 0.9438 - val_recall_2: 0.4789 - val_precision_2: 0.8718 - val_auc_2: 0.8855\n",
            "Epoch 64/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5762 - accuracy: 0.7232 - sensitivity_at_specificity_2: 0.9000 - specificity_at_sensitivity_2: 0.8070 - recall_2: 0.6909 - precision_2: 0.7308 - auc_2: 0.7686\n",
            "Epoch 64: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5684 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.9013 - specificity_at_sensitivity_2: 0.8274 - recall_2: 0.7763 - precision_2: 0.6782 - auc_2: 0.7743 - val_loss: 0.5167 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9605 - val_specificity_at_sensitivity_2: 0.8929 - val_recall_2: 0.8684 - val_precision_2: 0.6735 - val_auc_2: 0.8412\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5759 - accuracy: 0.7063 - sensitivity_at_specificity_2: 0.8947 - specificity_at_sensitivity_2: 0.8452 - recall_2: 0.6118 - precision_2: 0.7266 - auc_2: 0.7877\n",
            "Epoch 65: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5759 - accuracy: 0.7063 - sensitivity_at_specificity_2: 0.8947 - specificity_at_sensitivity_2: 0.8452 - recall_2: 0.6118 - precision_2: 0.7266 - auc_2: 0.7877 - val_loss: 0.5229 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.8625 - val_specificity_at_sensitivity_2: 0.9500 - val_recall_2: 0.8375 - val_precision_2: 0.7528 - val_auc_2: 0.8423\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6103 - accuracy: 0.6500 - sensitivity_at_specificity_2: 0.8129 - specificity_at_sensitivity_2: 0.8242 - recall_2: 0.8516 - precision_2: 0.5973 - auc_2: 0.7552\n",
            "Epoch 66: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6103 - accuracy: 0.6500 - sensitivity_at_specificity_2: 0.8129 - specificity_at_sensitivity_2: 0.8242 - recall_2: 0.8516 - precision_2: 0.5973 - auc_2: 0.7552 - val_loss: 0.5464 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.8851 - val_specificity_at_sensitivity_2: 0.9589 - val_recall_2: 0.7241 - val_precision_2: 0.8514 - val_auc_2: 0.8572\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9500 - specificity_at_sensitivity_2: 0.9312 - recall_2: 0.7812 - precision_2: 0.8065 - auc_2: 0.8659\n",
            "Epoch 67: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5078 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9500 - specificity_at_sensitivity_2: 0.9312 - recall_2: 0.7812 - precision_2: 0.8065 - auc_2: 0.8659 - val_loss: 0.4838 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9259 - val_specificity_at_sensitivity_2: 0.9367 - val_recall_2: 0.8642 - val_precision_2: 0.7368 - val_auc_2: 0.8792\n",
            "Epoch 68/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5554 - accuracy: 0.7148 - sensitivity_at_specificity_2: 0.8990 - specificity_at_sensitivity_2: 0.8854 - recall_2: 0.7778 - precision_2: 0.6016 - auc_2: 0.7874\n",
            "Epoch 68: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5406 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.9134 - specificity_at_sensitivity_2: 0.8964 - recall_2: 0.7480 - precision_2: 0.6376 - auc_2: 0.7994 - val_loss: 0.5887 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9444 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.5778 - val_precision_2: 0.9630 - val_auc_2: 0.8744\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.7000 - sensitivity_at_specificity_2: 0.8146 - specificity_at_sensitivity_2: 0.8521 - recall_2: 0.6556 - precision_2: 0.6923 - auc_2: 0.7691\n",
            "Epoch 69: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.5836 - accuracy: 0.7000 - sensitivity_at_specificity_2: 0.8146 - specificity_at_sensitivity_2: 0.8521 - recall_2: 0.6556 - precision_2: 0.6923 - auc_2: 0.7691 - val_loss: 0.5659 - val_accuracy: 0.7125 - val_sensitivity_at_specificity_2: 0.9024 - val_specificity_at_sensitivity_2: 0.8974 - val_recall_2: 0.9024 - val_precision_2: 0.6607 - val_auc_2: 0.8179\n",
            "Epoch 70/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5422 - accuracy: 0.7148 - sensitivity_at_specificity_2: 0.8958 - specificity_at_sensitivity_2: 0.8875 - recall_2: 0.5938 - precision_2: 0.6264 - auc_2: 0.7787\n",
            "Epoch 70: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5564 - accuracy: 0.7000 - sensitivity_at_specificity_2: 0.8871 - specificity_at_sensitivity_2: 0.8469 - recall_2: 0.5081 - precision_2: 0.6429 - auc_2: 0.7666 - val_loss: 0.4958 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9474 - val_specificity_at_sensitivity_2: 0.9524 - val_recall_2: 0.6053 - val_precision_2: 0.8846 - val_auc_2: 0.8932\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6085 - accuracy: 0.6844 - sensitivity_at_specificity_2: 0.8389 - specificity_at_sensitivity_2: 0.8246 - recall_2: 0.8389 - precision_2: 0.6188 - auc_2: 0.7499\n",
            "Epoch 71: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6085 - accuracy: 0.6844 - sensitivity_at_specificity_2: 0.8389 - specificity_at_sensitivity_2: 0.8246 - recall_2: 0.8389 - precision_2: 0.6188 - auc_2: 0.7499 - val_loss: 0.5217 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.8989 - val_specificity_at_sensitivity_2: 0.9437 - val_recall_2: 0.8764 - val_precision_2: 0.7429 - val_auc_2: 0.8650\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5856 - accuracy: 0.7156 - sensitivity_at_specificity_2: 0.8947 - specificity_at_sensitivity_2: 0.8631 - recall_2: 0.5987 - precision_2: 0.7521 - auc_2: 0.7813\n",
            "Epoch 72: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5856 - accuracy: 0.7156 - sensitivity_at_specificity_2: 0.8947 - specificity_at_sensitivity_2: 0.8631 - recall_2: 0.5987 - precision_2: 0.7521 - auc_2: 0.7813 - val_loss: 0.5047 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9620 - val_specificity_at_sensitivity_2: 0.9383 - val_recall_2: 0.6329 - val_precision_2: 0.8475 - val_auc_2: 0.8790\n",
            "Epoch 73/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5308 - accuracy: 0.7431 - sensitivity_at_specificity_2: 0.9254 - specificity_at_sensitivity_2: 0.8896 - recall_2: 0.8284 - precision_2: 0.6852 - auc_2: 0.8245\n",
            "Epoch 73: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5408 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9178 - specificity_at_sensitivity_2: 0.8851 - recall_2: 0.8288 - precision_2: 0.6685 - auc_2: 0.8116 - val_loss: 0.4850 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 0.9620 - val_recall_2: 0.9012 - val_precision_2: 0.7157 - val_auc_2: 0.8822\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.8992 - specificity_at_sensitivity_2: 0.8901 - recall_2: 0.7209 - precision_2: 0.6838 - auc_2: 0.8176\n",
            "Epoch 74: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5232 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.8992 - specificity_at_sensitivity_2: 0.8901 - recall_2: 0.7209 - precision_2: 0.6838 - auc_2: 0.8176 - val_loss: 0.5135 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9744 - val_specificity_at_sensitivity_2: 0.9390 - val_recall_2: 0.6154 - val_precision_2: 0.8889 - val_auc_2: 0.8866\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4827 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9441 - specificity_at_sensitivity_2: 0.9096 - recall_2: 0.7413 - precision_2: 0.7852 - auc_2: 0.8647\n",
            "Epoch 75: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4827 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9441 - specificity_at_sensitivity_2: 0.9096 - recall_2: 0.7413 - precision_2: 0.7852 - auc_2: 0.8647 - val_loss: 0.5273 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9067 - val_specificity_at_sensitivity_2: 0.9059 - val_recall_2: 0.7867 - val_precision_2: 0.7024 - val_auc_2: 0.8264\n",
            "Epoch 76/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5078 - accuracy: 0.7461 - sensitivity_at_specificity_2: 0.9298 - specificity_at_sensitivity_2: 0.9296 - recall_2: 0.7544 - precision_2: 0.6992 - auc_2: 0.8369\n",
            "Epoch 76: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4987 - accuracy: 0.7594 - sensitivity_at_specificity_2: 0.9241 - specificity_at_sensitivity_2: 0.9371 - recall_2: 0.7517 - precision_2: 0.7267 - auc_2: 0.8479 - val_loss: 0.4215 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9750 - val_specificity_at_sensitivity_2: 0.9750 - val_recall_2: 0.8125 - val_precision_2: 0.8553 - val_auc_2: 0.9146\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5327 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.9291 - specificity_at_sensitivity_2: 0.8492 - recall_2: 0.7872 - precision_2: 0.6810 - auc_2: 0.8124\n",
            "Epoch 77: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5327 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.9291 - specificity_at_sensitivity_2: 0.8492 - recall_2: 0.7872 - precision_2: 0.6810 - auc_2: 0.8124 - val_loss: 0.4934 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9405 - val_specificity_at_sensitivity_2: 0.9474 - val_recall_2: 0.8214 - val_precision_2: 0.7753 - val_auc_2: 0.8606\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5774 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8658 - specificity_at_sensitivity_2: 0.8889 - recall_2: 0.6711 - precision_2: 0.7092 - auc_2: 0.7821\n",
            "Epoch 78: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5774 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8658 - specificity_at_sensitivity_2: 0.8889 - recall_2: 0.6711 - precision_2: 0.7092 - auc_2: 0.7821 - val_loss: 0.5102 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9467 - val_specificity_at_sensitivity_2: 0.8941 - val_recall_2: 0.7867 - val_precision_2: 0.7108 - val_auc_2: 0.8366\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5151 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9173 - specificity_at_sensitivity_2: 0.8930 - recall_2: 0.6541 - precision_2: 0.6905 - auc_2: 0.8206\n",
            "Epoch 79: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5151 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9173 - specificity_at_sensitivity_2: 0.8930 - recall_2: 0.6541 - precision_2: 0.6905 - auc_2: 0.8206 - val_loss: 0.5004 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9659 - val_specificity_at_sensitivity_2: 0.9444 - val_recall_2: 0.7841 - val_precision_2: 0.8118 - val_auc_2: 0.8580\n",
            "Epoch 80/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5241 - accuracy: 0.7266 - sensitivity_at_specificity_2: 0.9138 - specificity_at_sensitivity_2: 0.9214 - recall_2: 0.7414 - precision_2: 0.6825 - auc_2: 0.8228\n",
            "Epoch 80: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5175 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.9296 - specificity_at_sensitivity_2: 0.9213 - recall_2: 0.7465 - precision_2: 0.6795 - auc_2: 0.8264 - val_loss: 0.4320 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9762 - val_specificity_at_sensitivity_2: 0.9868 - val_recall_2: 0.8810 - val_precision_2: 0.8132 - val_auc_2: 0.9088\n",
            "Epoch 81/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5148 - accuracy: 0.7773 - sensitivity_at_specificity_2: 0.8879 - specificity_at_sensitivity_2: 0.9128 - recall_2: 0.7009 - precision_2: 0.7500 - auc_2: 0.8288\n",
            "Epoch 81: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5322 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.8841 - specificity_at_sensitivity_2: 0.9011 - recall_2: 0.6957 - precision_2: 0.7273 - auc_2: 0.8135 - val_loss: 0.5466 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.8941 - val_specificity_at_sensitivity_2: 0.9067 - val_recall_2: 0.7176 - val_precision_2: 0.7821 - val_auc_2: 0.8213\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9155 - specificity_at_sensitivity_2: 0.9045 - recall_2: 0.7746 - precision_2: 0.6918 - auc_2: 0.8175\n",
            "Epoch 82: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5247 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9155 - specificity_at_sensitivity_2: 0.9045 - recall_2: 0.7746 - precision_2: 0.6918 - auc_2: 0.8175 - val_loss: 0.4885 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9277 - val_specificity_at_sensitivity_2: 0.8961 - val_recall_2: 0.8554 - val_precision_2: 0.7634 - val_auc_2: 0.8562\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9348 - specificity_at_sensitivity_2: 0.9286 - recall_2: 0.7609 - precision_2: 0.7343 - auc_2: 0.8536\n",
            "Epoch 83: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4860 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9348 - specificity_at_sensitivity_2: 0.9286 - recall_2: 0.7609 - precision_2: 0.7343 - auc_2: 0.8536 - val_loss: 0.4911 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9398 - val_specificity_at_sensitivity_2: 0.9481 - val_recall_2: 0.8313 - val_precision_2: 0.7931 - val_auc_2: 0.8647\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5296 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.9085 - specificity_at_sensitivity_2: 0.9494 - recall_2: 0.7535 - precision_2: 0.6948 - auc_2: 0.8246\n",
            "Epoch 84: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5296 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.9085 - specificity_at_sensitivity_2: 0.9494 - recall_2: 0.7535 - precision_2: 0.6948 - auc_2: 0.8246 - val_loss: 0.5313 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9136 - val_specificity_at_sensitivity_2: 0.9241 - val_recall_2: 0.6296 - val_precision_2: 0.8793 - val_auc_2: 0.8585\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8966 - specificity_at_sensitivity_2: 0.9429 - recall_2: 0.6552 - precision_2: 0.7600 - auc_2: 0.8245\n",
            "Epoch 85: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5271 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8966 - specificity_at_sensitivity_2: 0.9429 - recall_2: 0.6552 - precision_2: 0.7600 - auc_2: 0.8245 - val_loss: 0.4931 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9651 - val_specificity_at_sensitivity_2: 0.9189 - val_recall_2: 0.9186 - val_precision_2: 0.6930 - val_auc_2: 0.8572\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5151 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.9213 - specificity_at_sensitivity_2: 0.8964 - recall_2: 0.7008 - precision_2: 0.6496 - auc_2: 0.8164\n",
            "Epoch 86: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5151 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.9213 - specificity_at_sensitivity_2: 0.8964 - recall_2: 0.7008 - precision_2: 0.6496 - auc_2: 0.8164 - val_loss: 0.4718 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9750 - val_specificity_at_sensitivity_2: 0.9375 - val_recall_2: 0.7375 - val_precision_2: 0.7468 - val_auc_2: 0.8697\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.8824 - specificity_at_sensitivity_2: 0.9461 - recall_2: 0.7386 - precision_2: 0.7197 - auc_2: 0.8304\n",
            "Epoch 87: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5250 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.8824 - specificity_at_sensitivity_2: 0.9461 - recall_2: 0.7386 - precision_2: 0.7197 - auc_2: 0.8304 - val_loss: 0.4161 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9659 - val_specificity_at_sensitivity_2: 0.9722 - val_recall_2: 0.8750 - val_precision_2: 0.8652 - val_auc_2: 0.9145\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4907 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9390 - specificity_at_sensitivity_2: 0.9167 - recall_2: 0.8415 - precision_2: 0.7841 - auc_2: 0.8575\n",
            "Epoch 88: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4907 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9390 - specificity_at_sensitivity_2: 0.9167 - recall_2: 0.8415 - precision_2: 0.7841 - auc_2: 0.8575 - val_loss: 0.4932 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9250 - val_specificity_at_sensitivity_2: 0.9250 - val_recall_2: 0.7750 - val_precision_2: 0.7381 - val_auc_2: 0.8446\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5235 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8986 - specificity_at_sensitivity_2: 0.9341 - recall_2: 0.7174 - precision_2: 0.7071 - auc_2: 0.8192\n",
            "Epoch 89: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5235 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8986 - specificity_at_sensitivity_2: 0.9341 - recall_2: 0.7174 - precision_2: 0.7071 - auc_2: 0.8192 - val_loss: 0.4383 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9753 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.7901 - val_precision_2: 0.8312 - val_auc_2: 0.9090\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.8889 - specificity_at_sensitivity_2: 0.8865 - recall_2: 0.7185 - precision_2: 0.6690 - auc_2: 0.8103\n",
            "Epoch 90: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5321 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.8889 - specificity_at_sensitivity_2: 0.8865 - recall_2: 0.7185 - precision_2: 0.6690 - auc_2: 0.8103 - val_loss: 0.5207 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9136 - val_specificity_at_sensitivity_2: 0.9367 - val_recall_2: 0.6420 - val_precision_2: 0.8125 - val_auc_2: 0.8433\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8759 - specificity_at_sensitivity_2: 0.9086 - recall_2: 0.7586 - precision_2: 0.7006 - auc_2: 0.8248\n",
            "Epoch 91: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5201 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8759 - specificity_at_sensitivity_2: 0.9086 - recall_2: 0.7586 - precision_2: 0.7006 - auc_2: 0.8248 - val_loss: 0.4537 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9351 - val_specificity_at_sensitivity_2: 0.9518 - val_recall_2: 0.8701 - val_precision_2: 0.8272 - val_auc_2: 0.8840\n",
            "Epoch 92/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4874 - accuracy: 0.7857 - sensitivity_at_specificity_2: 0.9245 - specificity_at_sensitivity_2: 0.9322 - recall_2: 0.7642 - precision_2: 0.7788 - auc_2: 0.8565\n",
            "Epoch 92: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4906 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9079 - specificity_at_sensitivity_2: 0.9405 - recall_2: 0.7632 - precision_2: 0.7733 - auc_2: 0.8543 - val_loss: 0.4785 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9405 - val_specificity_at_sensitivity_2: 0.9737 - val_recall_2: 0.7738 - val_precision_2: 0.8125 - val_auc_2: 0.8739\n",
            "Epoch 93/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5075 - accuracy: 0.7212 - sensitivity_at_specificity_2: 0.9027 - specificity_at_sensitivity_2: 0.9558 - recall_2: 0.8673 - precision_2: 0.6712 - auc_2: 0.8619\n",
            "Epoch 93: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5235 - accuracy: 0.7138 - sensitivity_at_specificity_2: 0.9000 - specificity_at_sensitivity_2: 0.9688 - recall_2: 0.8615 - precision_2: 0.6328 - auc_2: 0.8570 - val_loss: 0.4458 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9398 - val_specificity_at_sensitivity_2: 0.9740 - val_recall_2: 0.8072 - val_precision_2: 0.7791 - val_auc_2: 0.8859\n",
            "Epoch 94/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5387 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.9041 - recall_2: 0.5091 - precision_2: 0.8000 - auc_2: 0.8206\n",
            "Epoch 94: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5246 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.9254 - specificity_at_sensitivity_2: 0.8871 - recall_2: 0.5149 - precision_2: 0.7667 - auc_2: 0.8244 - val_loss: 0.4624 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9625 - val_specificity_at_sensitivity_2: 0.9750 - val_recall_2: 0.8625 - val_precision_2: 0.7841 - val_auc_2: 0.8930\n",
            "Epoch 95/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5511 - accuracy: 0.7266 - sensitivity_at_specificity_2: 0.9052 - specificity_at_sensitivity_2: 0.8929 - recall_2: 0.8190 - precision_2: 0.6597 - auc_2: 0.8075\n",
            "Epoch 95: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5385 - accuracy: 0.7281 - sensitivity_at_specificity_2: 0.9236 - specificity_at_sensitivity_2: 0.8864 - recall_2: 0.7778 - precision_2: 0.6707 - auc_2: 0.8107 - val_loss: 0.4785 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9583 - val_specificity_at_sensitivity_2: 0.9318 - val_recall_2: 0.8056 - val_precision_2: 0.7532 - val_auc_2: 0.8651\n",
            "Epoch 96/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5309 - accuracy: 0.7266 - sensitivity_at_specificity_2: 0.8899 - specificity_at_sensitivity_2: 0.8639 - recall_2: 0.5688 - precision_2: 0.7294 - auc_2: 0.8086\n",
            "Epoch 96: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5341 - accuracy: 0.7281 - sensitivity_at_specificity_2: 0.8849 - specificity_at_sensitivity_2: 0.8674 - recall_2: 0.5899 - precision_2: 0.7321 - auc_2: 0.8074 - val_loss: 0.4404 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9630 - val_specificity_at_sensitivity_2: 0.9494 - val_recall_2: 0.8519 - val_precision_2: 0.7931 - val_auc_2: 0.8855\n",
            "Epoch 97/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5050 - accuracy: 0.7734 - sensitivity_at_specificity_2: 0.8929 - specificity_at_sensitivity_2: 0.9167 - recall_2: 0.8125 - precision_2: 0.7109 - auc_2: 0.8414\n",
            "Epoch 97: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.4952 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9111 - specificity_at_sensitivity_2: 0.9351 - recall_2: 0.7926 - precision_2: 0.6993 - auc_2: 0.8456 - val_loss: 0.4394 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9753 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.6914 - val_precision_2: 0.8889 - val_auc_2: 0.9154\n",
            "Epoch 98/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5178 - accuracy: 0.7455 - sensitivity_at_specificity_2: 0.9065 - specificity_at_sensitivity_2: 0.9316 - recall_2: 0.6822 - precision_2: 0.7604 - auc_2: 0.8343\n",
            "Epoch 98: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5172 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.8844 - specificity_at_sensitivity_2: 0.9595 - recall_2: 0.7143 - precision_2: 0.7095 - auc_2: 0.8272 - val_loss: 0.5527 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.8795 - val_specificity_at_sensitivity_2: 0.9351 - val_recall_2: 0.7349 - val_precision_2: 0.7821 - val_auc_2: 0.8178\n",
            "Epoch 99/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5439 - accuracy: 0.7257 - sensitivity_at_specificity_2: 0.8911 - specificity_at_sensitivity_2: 0.8960 - recall_2: 0.6733 - precision_2: 0.7010 - auc_2: 0.8006\n",
            "Epoch 99: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5336 - accuracy: 0.7345 - sensitivity_at_specificity_2: 0.8971 - specificity_at_sensitivity_2: 0.9091 - recall_2: 0.6838 - precision_2: 0.7323 - auc_2: 0.8140 - val_loss: 0.4709 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9474 - val_specificity_at_sensitivity_2: 0.9643 - val_recall_2: 0.8816 - val_precision_2: 0.7053 - val_auc_2: 0.8845\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5392 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.8609 - specificity_at_sensitivity_2: 0.9349 - recall_2: 0.7417 - precision_2: 0.7134 - auc_2: 0.8095\n",
            "Epoch 100: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5392 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.8609 - specificity_at_sensitivity_2: 0.9349 - recall_2: 0.7417 - precision_2: 0.7134 - auc_2: 0.8095 - val_loss: 0.5049 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9091 - val_specificity_at_sensitivity_2: 0.9306 - val_recall_2: 0.7955 - val_precision_2: 0.8140 - val_auc_2: 0.8551\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5364 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.8389 - specificity_at_sensitivity_2: 0.9474 - recall_2: 0.6510 - precision_2: 0.7886 - auc_2: 0.8123\n",
            "Epoch 101: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5364 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.8389 - specificity_at_sensitivity_2: 0.9474 - recall_2: 0.6510 - precision_2: 0.7886 - auc_2: 0.8123 - val_loss: 0.5329 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.8780 - val_specificity_at_sensitivity_2: 0.9359 - val_recall_2: 0.6585 - val_precision_2: 0.8060 - val_auc_2: 0.8332\n",
            "Epoch 102/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5279 - accuracy: 0.7461 - sensitivity_at_specificity_2: 0.8900 - specificity_at_sensitivity_2: 0.9231 - recall_2: 0.7600 - precision_2: 0.6496 - auc_2: 0.8054\n",
            "Epoch 102: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.5132 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.9055 - specificity_at_sensitivity_2: 0.9275 - recall_2: 0.7638 - precision_2: 0.6599 - auc_2: 0.8209 - val_loss: 0.5068 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9143 - val_specificity_at_sensitivity_2: 0.9222 - val_recall_2: 0.5857 - val_precision_2: 0.7885 - val_auc_2: 0.8560\n",
            "Epoch 103/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5702 - accuracy: 0.6914 - sensitivity_at_specificity_2: 0.8810 - specificity_at_sensitivity_2: 0.8846 - recall_2: 0.6429 - precision_2: 0.7043 - auc_2: 0.7864\n",
            "Epoch 103: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.5599 - accuracy: 0.6906 - sensitivity_at_specificity_2: 0.8239 - specificity_at_sensitivity_2: 0.9068 - recall_2: 0.7170 - precision_2: 0.6786 - auc_2: 0.7934 - val_loss: 0.4741 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9600 - val_specificity_at_sensitivity_2: 0.9765 - val_recall_2: 0.8667 - val_precision_2: 0.6701 - val_auc_2: 0.8733\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9272 - specificity_at_sensitivity_2: 0.8639 - recall_2: 0.6358 - precision_2: 0.7619 - auc_2: 0.8203\n",
            "Epoch 104: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5316 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9272 - specificity_at_sensitivity_2: 0.8639 - recall_2: 0.6358 - precision_2: 0.7619 - auc_2: 0.8203 - val_loss: 0.5006 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9487 - val_specificity_at_sensitivity_2: 0.8780 - val_recall_2: 0.7051 - val_precision_2: 0.7639 - val_auc_2: 0.8433\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5166 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.9400 - specificity_at_sensitivity_2: 0.9412 - recall_2: 0.8467 - precision_2: 0.6546 - auc_2: 0.8382\n",
            "Epoch 105: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5166 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.9400 - specificity_at_sensitivity_2: 0.9412 - recall_2: 0.8467 - precision_2: 0.6546 - auc_2: 0.8382 - val_loss: 0.5468 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.8734 - val_specificity_at_sensitivity_2: 0.9012 - val_recall_2: 0.6709 - val_precision_2: 0.7910 - val_auc_2: 0.8122\n",
            "Epoch 106/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5218 - accuracy: 0.7589 - sensitivity_at_specificity_2: 0.9167 - specificity_at_sensitivity_2: 0.8906 - recall_2: 0.6042 - precision_2: 0.7838 - auc_2: 0.8223\n",
            "Epoch 106: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5335 - accuracy: 0.7345 - sensitivity_at_specificity_2: 0.9024 - specificity_at_sensitivity_2: 0.8563 - recall_2: 0.5935 - precision_2: 0.7300 - auc_2: 0.8060 - val_loss: 0.4796 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9540 - val_specificity_at_sensitivity_2: 0.9589 - val_recall_2: 0.8736 - val_precision_2: 0.7600 - val_auc_2: 0.8551\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5500 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.9000 - specificity_at_sensitivity_2: 0.9167 - recall_2: 0.8714 - precision_2: 0.6193 - auc_2: 0.8275\n",
            "Epoch 107: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5500 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.9000 - specificity_at_sensitivity_2: 0.9167 - recall_2: 0.8714 - precision_2: 0.6193 - auc_2: 0.8275 - val_loss: 0.5132 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9398 - val_specificity_at_sensitivity_2: 0.9221 - val_recall_2: 0.6747 - val_precision_2: 0.8615 - val_auc_2: 0.8652\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5792 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8125 - specificity_at_sensitivity_2: 0.8977 - recall_2: 0.5347 - precision_2: 0.7549 - auc_2: 0.7813\n",
            "Epoch 108: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5792 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8125 - specificity_at_sensitivity_2: 0.8977 - recall_2: 0.5347 - precision_2: 0.7549 - auc_2: 0.7813 - val_loss: 0.4782 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9500 - val_specificity_at_sensitivity_2: 0.9625 - val_recall_2: 0.7750 - val_precision_2: 0.7949 - val_auc_2: 0.8780\n",
            "Epoch 109/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5696 - accuracy: 0.6910 - sensitivity_at_specificity_2: 0.8188 - specificity_at_sensitivity_2: 0.8800 - recall_2: 0.7029 - precision_2: 0.6690 - auc_2: 0.7796\n",
            "Epoch 109: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5603 - accuracy: 0.7000 - sensitivity_at_specificity_2: 0.8212 - specificity_at_sensitivity_2: 0.9053 - recall_2: 0.7219 - precision_2: 0.6687 - auc_2: 0.7909 - val_loss: 0.4873 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9231 - val_specificity_at_sensitivity_2: 0.9390 - val_recall_2: 0.7436 - val_precision_2: 0.8056 - val_auc_2: 0.8596\n",
            "Epoch 110/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5564 - accuracy: 0.7232 - sensitivity_at_specificity_2: 0.8660 - specificity_at_sensitivity_2: 0.8504 - recall_2: 0.6701 - precision_2: 0.6842 - auc_2: 0.7809\n",
            "Epoch 110: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5369 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8811 - specificity_at_sensitivity_2: 0.8983 - recall_2: 0.6713 - precision_2: 0.7442 - auc_2: 0.8121 - val_loss: 0.4769 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9756 - val_specificity_at_sensitivity_2: 0.9744 - val_recall_2: 0.7195 - val_precision_2: 0.8194 - val_auc_2: 0.8839\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.8974 - specificity_at_sensitivity_2: 0.9268 - recall_2: 0.7756 - precision_2: 0.7118 - auc_2: 0.8240\n",
            "Epoch 111: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5262 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.8974 - specificity_at_sensitivity_2: 0.9268 - recall_2: 0.7756 - precision_2: 0.7118 - auc_2: 0.8240 - val_loss: 0.4515 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9770 - val_specificity_at_sensitivity_2: 0.8904 - val_recall_2: 0.8736 - val_precision_2: 0.7835 - val_auc_2: 0.8773\n",
            "Epoch 112/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5233 - accuracy: 0.7545 - sensitivity_at_specificity_2: 0.9070 - specificity_at_sensitivity_2: 0.9130 - recall_2: 0.7326 - precision_2: 0.6632 - auc_2: 0.8074\n",
            "Epoch 112: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5508 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.8651 - specificity_at_sensitivity_2: 0.9175 - recall_2: 0.6587 - precision_2: 0.6975 - auc_2: 0.7836 - val_loss: 0.5152 - val_accuracy: 0.7312 - val_sensitivity_at_specificity_2: 0.9726 - val_specificity_at_sensitivity_2: 0.9425 - val_recall_2: 0.4521 - val_precision_2: 0.9167 - val_auc_2: 0.8866\n",
            "Epoch 113/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5674 - accuracy: 0.6992 - sensitivity_at_specificity_2: 0.8632 - specificity_at_sensitivity_2: 0.8705 - recall_2: 0.6496 - precision_2: 0.6786 - auc_2: 0.7823\n",
            "Epoch 113: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5690 - accuracy: 0.6969 - sensitivity_at_specificity_2: 0.8582 - specificity_at_sensitivity_2: 0.8659 - recall_2: 0.6809 - precision_2: 0.6486 - auc_2: 0.7776 - val_loss: 0.5086 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9286 - val_specificity_at_sensitivity_2: 0.9474 - val_recall_2: 0.8571 - val_precision_2: 0.7273 - val_auc_2: 0.8498\n",
            "Epoch 114/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5361 - accuracy: 0.7227 - sensitivity_at_specificity_2: 0.8929 - specificity_at_sensitivity_2: 0.8889 - recall_2: 0.6339 - precision_2: 0.7030 - auc_2: 0.8041\n",
            "Epoch 114: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5305 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.9014 - specificity_at_sensitivity_2: 0.8989 - recall_2: 0.6268 - precision_2: 0.7177 - auc_2: 0.8121 - val_loss: 0.5133 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9310 - val_specificity_at_sensitivity_2: 0.9726 - val_recall_2: 0.6667 - val_precision_2: 0.8529 - val_auc_2: 0.8662\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.9058 - specificity_at_sensitivity_2: 0.9011 - recall_2: 0.6957 - precision_2: 0.7164 - auc_2: 0.8115\n",
            "Epoch 115: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5347 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.9058 - specificity_at_sensitivity_2: 0.9011 - recall_2: 0.6957 - precision_2: 0.7164 - auc_2: 0.8115 - val_loss: 0.4648 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9333 - val_specificity_at_sensitivity_2: 0.9714 - val_recall_2: 0.7889 - val_precision_2: 0.8452 - val_auc_2: 0.8863\n",
            "Epoch 116/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5008 - accuracy: 0.7617 - sensitivity_at_specificity_2: 0.9174 - specificity_at_sensitivity_2: 0.9116 - recall_2: 0.7431 - precision_2: 0.7105 - auc_2: 0.8382\n",
            "Epoch 116: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4927 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9265 - specificity_at_sensitivity_2: 0.9239 - recall_2: 0.7426 - precision_2: 0.7214 - auc_2: 0.8462 - val_loss: 0.5564 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.8966 - val_specificity_at_sensitivity_2: 0.9315 - val_recall_2: 0.6207 - val_precision_2: 0.8710 - val_auc_2: 0.8435\n",
            "Epoch 117/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4932 - accuracy: 0.7695 - sensitivity_at_specificity_2: 0.9421 - specificity_at_sensitivity_2: 0.9111 - recall_2: 0.6694 - precision_2: 0.8100 - auc_2: 0.8541\n",
            "Epoch 117: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5034 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9220 - specificity_at_sensitivity_2: 0.8715 - recall_2: 0.7021 - precision_2: 0.7279 - auc_2: 0.8320 - val_loss: 0.4837 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9459 - val_specificity_at_sensitivity_2: 0.9419 - val_recall_2: 0.9324 - val_precision_2: 0.6765 - val_auc_2: 0.8864\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4862 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9231 - specificity_at_sensitivity_2: 0.9158 - recall_2: 0.7462 - precision_2: 0.7348 - auc_2: 0.8427\n",
            "Epoch 118: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4862 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9231 - specificity_at_sensitivity_2: 0.9158 - recall_2: 0.7462 - precision_2: 0.7348 - auc_2: 0.8427 - val_loss: 0.5110 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9722 - val_specificity_at_sensitivity_2: 0.9659 - val_recall_2: 0.4583 - val_precision_2: 0.9167 - val_auc_2: 0.8967\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8808 - specificity_at_sensitivity_2: 0.8402 - recall_2: 0.6689 - precision_2: 0.7063 - auc_2: 0.7828\n",
            "Epoch 119: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5676 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8808 - specificity_at_sensitivity_2: 0.8402 - recall_2: 0.6689 - precision_2: 0.7063 - auc_2: 0.7828 - val_loss: 0.5010 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9512 - val_specificity_at_sensitivity_2: 0.9359 - val_recall_2: 0.9024 - val_precision_2: 0.7115 - val_auc_2: 0.8595\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5458 - accuracy: 0.7379 - sensitivity_at_specificity_2: 0.8806 - specificity_at_sensitivity_2: 0.8846 - recall_2: 0.7687 - precision_2: 0.6959 - auc_2: 0.8030\n",
            "Epoch 120: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.5458 - accuracy: 0.7379 - sensitivity_at_specificity_2: 0.8806 - specificity_at_sensitivity_2: 0.8846 - recall_2: 0.7687 - precision_2: 0.6959 - auc_2: 0.8030 - val_loss: 0.5118 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.8630 - val_specificity_at_sensitivity_2: 0.9080 - val_recall_2: 0.6712 - val_precision_2: 0.7656 - val_auc_2: 0.8322\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4762 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9259 - specificity_at_sensitivity_2: 0.9622 - recall_2: 0.6963 - precision_2: 0.7402 - auc_2: 0.8594\n",
            "Epoch 121: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4762 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9259 - specificity_at_sensitivity_2: 0.9622 - recall_2: 0.6963 - precision_2: 0.7402 - auc_2: 0.8594 - val_loss: 0.4381 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9538 - val_specificity_at_sensitivity_2: 0.9579 - val_recall_2: 0.7538 - val_precision_2: 0.7424 - val_auc_2: 0.8892\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5111 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.8963 - specificity_at_sensitivity_2: 0.9351 - recall_2: 0.7630 - precision_2: 0.7203 - auc_2: 0.8286\n",
            "Epoch 122: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5111 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.8963 - specificity_at_sensitivity_2: 0.9351 - recall_2: 0.7630 - precision_2: 0.7203 - auc_2: 0.8286 - val_loss: 0.4740 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9268 - val_specificity_at_sensitivity_2: 0.9744 - val_recall_2: 0.7195 - val_precision_2: 0.8806 - val_auc_2: 0.8840\n",
            "Epoch 123/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4991 - accuracy: 0.7891 - sensitivity_at_specificity_2: 0.9060 - specificity_at_sensitivity_2: 0.9353 - recall_2: 0.7179 - precision_2: 0.8000 - auc_2: 0.8446\n",
            "Epoch 123: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5297 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.8759 - specificity_at_sensitivity_2: 0.9314 - recall_2: 0.6828 - precision_2: 0.7857 - auc_2: 0.8196 - val_loss: 0.4405 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9775 - val_specificity_at_sensitivity_2: 0.9577 - val_recall_2: 0.7753 - val_precision_2: 0.8415 - val_auc_2: 0.8901\n",
            "Epoch 124/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5210 - accuracy: 0.7589 - sensitivity_at_specificity_2: 0.8762 - specificity_at_sensitivity_2: 0.9244 - recall_2: 0.7238 - precision_2: 0.7525 - auc_2: 0.8222\n",
            "Epoch 124: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5258 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.8533 - specificity_at_sensitivity_2: 0.9412 - recall_2: 0.7400 - precision_2: 0.7070 - auc_2: 0.8189 - val_loss: 0.4242 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9750 - val_specificity_at_sensitivity_2: 0.9500 - val_recall_2: 0.8500 - val_precision_2: 0.7816 - val_auc_2: 0.8986\n",
            "Epoch 125/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4914 - accuracy: 0.7383 - sensitivity_at_specificity_2: 0.9478 - specificity_at_sensitivity_2: 0.9291 - recall_2: 0.7043 - precision_2: 0.7105 - auc_2: 0.8427\n",
            "Epoch 125: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4923 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9388 - specificity_at_sensitivity_2: 0.9249 - recall_2: 0.7075 - precision_2: 0.7324 - auc_2: 0.8416 - val_loss: 0.4290 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9737 - val_specificity_at_sensitivity_2: 0.9762 - val_recall_2: 0.7237 - val_precision_2: 0.8462 - val_auc_2: 0.9007\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.8881 - specificity_at_sensitivity_2: 0.9462 - recall_2: 0.6716 - precision_2: 0.7692 - auc_2: 0.8413\n",
            "Epoch 126: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4925 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.8881 - specificity_at_sensitivity_2: 0.9462 - recall_2: 0.6716 - precision_2: 0.7692 - auc_2: 0.8413 - val_loss: 0.4071 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9798 - val_specificity_at_sensitivity_2: 0.9672 - val_recall_2: 0.8283 - val_precision_2: 0.8632 - val_auc_2: 0.9086\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9348 - specificity_at_sensitivity_2: 0.9011 - recall_2: 0.7391 - precision_2: 0.7183 - auc_2: 0.8251\n",
            "Epoch 127: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5087 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9348 - specificity_at_sensitivity_2: 0.9011 - recall_2: 0.7391 - precision_2: 0.7183 - auc_2: 0.8251 - val_loss: 0.4752 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9651 - val_specificity_at_sensitivity_2: 0.9189 - val_recall_2: 0.7209 - val_precision_2: 0.8052 - val_auc_2: 0.8637\n",
            "Epoch 128/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4913 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.9029 - specificity_at_sensitivity_2: 0.9281 - recall_2: 0.6990 - precision_2: 0.6857 - auc_2: 0.8340\n",
            "Epoch 128: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4883 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9098 - specificity_at_sensitivity_2: 0.9305 - recall_2: 0.6917 - precision_2: 0.6970 - auc_2: 0.8391 - val_loss: 0.4502 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9733 - val_specificity_at_sensitivity_2: 0.9294 - val_recall_2: 0.7200 - val_precision_2: 0.7826 - val_auc_2: 0.8803\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.9367 - specificity_at_sensitivity_2: 0.9259 - recall_2: 0.7722 - precision_2: 0.7439 - auc_2: 0.8425\n",
            "Epoch 129: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4904 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.9367 - specificity_at_sensitivity_2: 0.9259 - recall_2: 0.7722 - precision_2: 0.7439 - auc_2: 0.8425 - val_loss: 0.4871 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9231 - val_specificity_at_sensitivity_2: 0.9512 - val_recall_2: 0.8590 - val_precision_2: 0.7701 - val_auc_2: 0.8525\n",
            "Epoch 130/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6179 - accuracy: 0.6875 - sensitivity_at_specificity_2: 0.8083 - specificity_at_sensitivity_2: 0.7941 - recall_2: 0.7000 - precision_2: 0.6562 - auc_2: 0.7392\n",
            "Epoch 130: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.5648 - accuracy: 0.7281 - sensitivity_at_specificity_2: 0.8766 - specificity_at_sensitivity_2: 0.8373 - recall_2: 0.7273 - precision_2: 0.7134 - auc_2: 0.7832 - val_loss: 0.4646 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9359 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7821 - val_precision_2: 0.8243 - val_auc_2: 0.8777\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9423 - specificity_at_sensitivity_2: 0.8720 - recall_2: 0.8462 - precision_2: 0.7174 - auc_2: 0.8289\n",
            "Epoch 131: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.5131 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9423 - specificity_at_sensitivity_2: 0.8720 - recall_2: 0.8462 - precision_2: 0.7174 - auc_2: 0.8289 - val_loss: 0.4851 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9670 - val_specificity_at_sensitivity_2: 0.9275 - val_recall_2: 0.7363 - val_precision_2: 0.8072 - val_auc_2: 0.8638\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5072 - accuracy: 0.7594 - sensitivity_at_specificity_2: 0.9133 - specificity_at_sensitivity_2: 0.9412 - recall_2: 0.7133 - precision_2: 0.7589 - auc_2: 0.8359\n",
            "Epoch 132: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5072 - accuracy: 0.7594 - sensitivity_at_specificity_2: 0.9133 - specificity_at_sensitivity_2: 0.9412 - recall_2: 0.7133 - precision_2: 0.7589 - auc_2: 0.8359 - val_loss: 0.4751 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9222 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7778 - val_precision_2: 0.8046 - val_auc_2: 0.8667\n",
            "Epoch 133/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4791 - accuracy: 0.7882 - sensitivity_at_specificity_2: 0.9071 - specificity_at_sensitivity_2: 0.9730 - recall_2: 0.8357 - precision_2: 0.7548 - auc_2: 0.8668\n",
            "Epoch 133: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4747 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9038 - specificity_at_sensitivity_2: 0.9756 - recall_2: 0.8462 - precision_2: 0.7543 - auc_2: 0.8727 - val_loss: 0.5028 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9467 - val_specificity_at_sensitivity_2: 0.8353 - val_recall_2: 0.7467 - val_precision_2: 0.7273 - val_auc_2: 0.8302\n",
            "Epoch 134/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5063 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9182 - specificity_at_sensitivity_2: 0.9315 - recall_2: 0.6455 - precision_2: 0.7717 - auc_2: 0.8259\n",
            "Epoch 134: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5006 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9184 - specificity_at_sensitivity_2: 0.9364 - recall_2: 0.6531 - precision_2: 0.8000 - auc_2: 0.8375 - val_loss: 0.4533 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9041 - val_specificity_at_sensitivity_2: 0.9540 - val_recall_2: 0.8219 - val_precision_2: 0.8000 - val_auc_2: 0.8766\n",
            "Epoch 135/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5015 - accuracy: 0.7708 - sensitivity_at_specificity_2: 0.9000 - specificity_at_sensitivity_2: 0.9595 - recall_2: 0.8214 - precision_2: 0.7372 - auc_2: 0.8458\n",
            "Epoch 135: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4939 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9108 - specificity_at_sensitivity_2: 0.9509 - recall_2: 0.8280 - precision_2: 0.7429 - auc_2: 0.8508 - val_loss: 0.4563 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9286 - val_specificity_at_sensitivity_2: 0.9868 - val_recall_2: 0.7738 - val_precision_2: 0.7927 - val_auc_2: 0.8774\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5240 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.8777 - specificity_at_sensitivity_2: 0.8950 - recall_2: 0.6547 - precision_2: 0.7459 - auc_2: 0.8175\n",
            "Epoch 136: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5240 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.8777 - specificity_at_sensitivity_2: 0.8950 - recall_2: 0.6547 - precision_2: 0.7459 - auc_2: 0.8175 - val_loss: 0.4664 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9500 - val_specificity_at_sensitivity_2: 0.9750 - val_recall_2: 0.7875 - val_precision_2: 0.7500 - val_auc_2: 0.8669\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5151 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9051 - specificity_at_sensitivity_2: 0.9290 - recall_2: 0.7299 - precision_2: 0.7042 - auc_2: 0.8221\n",
            "Epoch 137: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5151 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9051 - specificity_at_sensitivity_2: 0.9290 - recall_2: 0.7299 - precision_2: 0.7042 - auc_2: 0.8221 - val_loss: 0.4446 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9375 - val_specificity_at_sensitivity_2: 0.9750 - val_recall_2: 0.7875 - val_precision_2: 0.8630 - val_auc_2: 0.8959\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.8947 - specificity_at_sensitivity_2: 0.9405 - recall_2: 0.7961 - precision_2: 0.7289 - auc_2: 0.8403\n",
            "Epoch 138: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5019 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.8947 - specificity_at_sensitivity_2: 0.9405 - recall_2: 0.7961 - precision_2: 0.7289 - auc_2: 0.8403 - val_loss: 0.5684 - val_accuracy: 0.7000 - val_sensitivity_at_specificity_2: 0.8690 - val_specificity_at_sensitivity_2: 0.8684 - val_recall_2: 0.6667 - val_precision_2: 0.7368 - val_auc_2: 0.7920\n",
            "Epoch 139/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5388 - accuracy: 0.7455 - sensitivity_at_specificity_2: 0.8692 - specificity_at_sensitivity_2: 0.9487 - recall_2: 0.6262 - precision_2: 0.7976 - auc_2: 0.8149\n",
            "Epoch 139: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5437 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.8684 - specificity_at_sensitivity_2: 0.9405 - recall_2: 0.6711 - precision_2: 0.7669 - auc_2: 0.8065 - val_loss: 0.5196 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.8941 - val_specificity_at_sensitivity_2: 0.9067 - val_recall_2: 0.8824 - val_precision_2: 0.7075 - val_auc_2: 0.8277\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4952 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9241 - specificity_at_sensitivity_2: 0.9259 - recall_2: 0.7911 - precision_2: 0.7310 - auc_2: 0.8455\n",
            "Epoch 140: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4952 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9241 - specificity_at_sensitivity_2: 0.9259 - recall_2: 0.7911 - precision_2: 0.7310 - auc_2: 0.8455 - val_loss: 0.4835 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9178 - val_specificity_at_sensitivity_2: 0.9425 - val_recall_2: 0.7671 - val_precision_2: 0.7568 - val_auc_2: 0.8556\n",
            "Epoch 141/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4890 - accuracy: 0.7891 - sensitivity_at_specificity_2: 0.9200 - specificity_at_sensitivity_2: 0.9423 - recall_2: 0.6800 - precision_2: 0.7556 - auc_2: 0.8364\n",
            "Epoch 141: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4894 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9254 - specificity_at_sensitivity_2: 0.9355 - recall_2: 0.6940 - precision_2: 0.7815 - auc_2: 0.8445 - val_loss: 0.5064 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9359 - val_specificity_at_sensitivity_2: 0.8902 - val_recall_2: 0.7051 - val_precision_2: 0.7639 - val_auc_2: 0.8336\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4633 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9357 - specificity_at_sensitivity_2: 0.9556 - recall_2: 0.8000 - precision_2: 0.7134 - auc_2: 0.8658\n",
            "Epoch 142: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4633 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9357 - specificity_at_sensitivity_2: 0.9556 - recall_2: 0.8000 - precision_2: 0.7134 - auc_2: 0.8658 - val_loss: 0.4322 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9296 - val_specificity_at_sensitivity_2: 0.9775 - val_recall_2: 0.8028 - val_precision_2: 0.7600 - val_auc_2: 0.8844\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4861 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9296 - specificity_at_sensitivity_2: 0.9326 - recall_2: 0.6690 - precision_2: 0.7917 - auc_2: 0.8501\n",
            "Epoch 143: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4861 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9296 - specificity_at_sensitivity_2: 0.9326 - recall_2: 0.6690 - precision_2: 0.7917 - auc_2: 0.8501 - val_loss: 0.4919 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 0.9367 - val_recall_2: 0.7037 - val_precision_2: 0.7600 - val_auc_2: 0.8436\n",
            "Epoch 144/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4898 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9292 - specificity_at_sensitivity_2: 0.9371 - recall_2: 0.7876 - precision_2: 0.7120 - auc_2: 0.8479\n",
            "Epoch 144: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5077 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9143 - specificity_at_sensitivity_2: 0.9111 - recall_2: 0.7571 - precision_2: 0.6928 - auc_2: 0.8319 - val_loss: 0.4550 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9268 - val_specificity_at_sensitivity_2: 0.9872 - val_recall_2: 0.7073 - val_precision_2: 0.9062 - val_auc_2: 0.8940\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9510 - specificity_at_sensitivity_2: 0.9831 - recall_2: 0.7343 - precision_2: 0.8077 - auc_2: 0.8827\n",
            "Epoch 145: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4400 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9510 - specificity_at_sensitivity_2: 0.9831 - recall_2: 0.7343 - precision_2: 0.8077 - auc_2: 0.8827 - val_loss: 0.4212 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.8272 - val_precision_2: 0.7976 - val_auc_2: 0.8977\n",
            "Epoch 146/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4579 - accuracy: 0.8008 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9688 - recall_2: 0.8750 - precision_2: 0.7619 - auc_2: 0.8764\n",
            "Epoch 146: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4516 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9346 - specificity_at_sensitivity_2: 0.9521 - recall_2: 0.8562 - precision_2: 0.7486 - auc_2: 0.8779 - val_loss: 0.5325 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.8784 - val_specificity_at_sensitivity_2: 0.9302 - val_recall_2: 0.6486 - val_precision_2: 0.8000 - val_auc_2: 0.8311\n",
            "Epoch 147/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4955 - accuracy: 0.7679 - sensitivity_at_specificity_2: 0.9314 - specificity_at_sensitivity_2: 0.9344 - recall_2: 0.6961 - precision_2: 0.7717 - auc_2: 0.8429\n",
            "Epoch 147: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4901 - accuracy: 0.7724 - sensitivity_at_specificity_2: 0.9470 - specificity_at_sensitivity_2: 0.9114 - recall_2: 0.7273 - precision_2: 0.7619 - auc_2: 0.8435 - val_loss: 0.4085 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9848 - val_specificity_at_sensitivity_2: 0.9787 - val_recall_2: 0.7576 - val_precision_2: 0.7937 - val_auc_2: 0.8964\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9371 - specificity_at_sensitivity_2: 0.9548 - recall_2: 0.7832 - precision_2: 0.7778 - auc_2: 0.8745\n",
            "Epoch 148: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4461 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9371 - specificity_at_sensitivity_2: 0.9548 - recall_2: 0.7832 - precision_2: 0.7778 - auc_2: 0.8745 - val_loss: 0.4804 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9351 - val_specificity_at_sensitivity_2: 0.9759 - val_recall_2: 0.6883 - val_precision_2: 0.8548 - val_auc_2: 0.8568\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4882 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9167 - specificity_at_sensitivity_2: 0.9205 - recall_2: 0.7153 - precision_2: 0.7863 - auc_2: 0.8456\n",
            "Epoch 149: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4882 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9167 - specificity_at_sensitivity_2: 0.9205 - recall_2: 0.7153 - precision_2: 0.7863 - auc_2: 0.8456 - val_loss: 0.4745 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.8961 - val_specificity_at_sensitivity_2: 0.9277 - val_recall_2: 0.7273 - val_precision_2: 0.7273 - val_auc_2: 0.8569\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4520 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9213 - specificity_at_sensitivity_2: 0.9793 - recall_2: 0.7559 - precision_2: 0.7934 - auc_2: 0.8613\n",
            "Epoch 150: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4520 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9213 - specificity_at_sensitivity_2: 0.9793 - recall_2: 0.7559 - precision_2: 0.7934 - auc_2: 0.8613 - val_loss: 0.4312 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9091 - val_specificity_at_sensitivity_2: 0.9759 - val_recall_2: 0.7403 - val_precision_2: 0.8507 - val_auc_2: 0.8893\n",
            "Epoch 151/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5217 - accuracy: 0.7773 - sensitivity_at_specificity_2: 0.8855 - specificity_at_sensitivity_2: 0.8800 - recall_2: 0.7481 - precision_2: 0.8033 - auc_2: 0.8265\n",
            "Epoch 151: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5169 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9045 - specificity_at_sensitivity_2: 0.8834 - recall_2: 0.7771 - precision_2: 0.7531 - auc_2: 0.8266 - val_loss: 0.4993 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.8987 - val_specificity_at_sensitivity_2: 0.9506 - val_recall_2: 0.8101 - val_precision_2: 0.7356 - val_auc_2: 0.8411\n",
            "Epoch 152/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4857 - accuracy: 0.8086 - sensitivity_at_specificity_2: 0.8641 - specificity_at_sensitivity_2: 0.9477 - recall_2: 0.6505 - precision_2: 0.8375 - auc_2: 0.8387\n",
            "Epoch 152: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5034 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.8605 - specificity_at_sensitivity_2: 0.9581 - recall_2: 0.6047 - precision_2: 0.8478 - auc_2: 0.8245 - val_loss: 0.4659 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9351 - val_specificity_at_sensitivity_2: 0.9398 - val_recall_2: 0.7532 - val_precision_2: 0.7532 - val_auc_2: 0.8618\n",
            "Epoch 153/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4697 - accuracy: 0.7773 - sensitivity_at_specificity_2: 0.9256 - specificity_at_sensitivity_2: 0.9630 - recall_2: 0.8512 - precision_2: 0.7254 - auc_2: 0.8669\n",
            "Epoch 153: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4804 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9241 - specificity_at_sensitivity_2: 0.9543 - recall_2: 0.8414 - precision_2: 0.7011 - auc_2: 0.8606 - val_loss: 0.4444 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9241 - val_specificity_at_sensitivity_2: 0.9753 - val_recall_2: 0.7468 - val_precision_2: 0.8310 - val_auc_2: 0.8899\n",
            "Epoch 154/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4766 - accuracy: 0.7578 - sensitivity_at_specificity_2: 0.9640 - specificity_at_sensitivity_2: 0.9379 - recall_2: 0.5946 - precision_2: 0.7952 - auc_2: 0.8662\n",
            "Epoch 154: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4831 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9510 - specificity_at_sensitivity_2: 0.9379 - recall_2: 0.6154 - precision_2: 0.8073 - auc_2: 0.8615 - val_loss: 0.5217 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.8980 - val_specificity_at_sensitivity_2: 0.9677 - val_recall_2: 0.6735 - val_precision_2: 0.8462 - val_auc_2: 0.8500\n",
            "Epoch 155/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4729 - accuracy: 0.7708 - sensitivity_at_specificity_2: 0.9632 - specificity_at_sensitivity_2: 0.9276 - recall_2: 0.8162 - precision_2: 0.7303 - auc_2: 0.8570\n",
            "Epoch 155: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4750 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9583 - specificity_at_sensitivity_2: 0.9489 - recall_2: 0.8264 - precision_2: 0.7126 - auc_2: 0.8589 - val_loss: 0.4498 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9157 - val_specificity_at_sensitivity_2: 0.9870 - val_recall_2: 0.7711 - val_precision_2: 0.8533 - val_auc_2: 0.8811\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5099 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9226 - specificity_at_sensitivity_2: 0.8909 - recall_2: 0.7613 - precision_2: 0.7662 - auc_2: 0.8323\n",
            "Epoch 156: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5099 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9226 - specificity_at_sensitivity_2: 0.8909 - recall_2: 0.7613 - precision_2: 0.7662 - auc_2: 0.8323 - val_loss: 0.4482 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9250 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9000 - val_precision_2: 0.7500 - val_auc_2: 0.8805\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4865 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9357 - specificity_at_sensitivity_2: 0.8778 - recall_2: 0.7714 - precision_2: 0.7248 - auc_2: 0.8404\n",
            "Epoch 157: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4865 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9357 - specificity_at_sensitivity_2: 0.8778 - recall_2: 0.7714 - precision_2: 0.7248 - auc_2: 0.8404 - val_loss: 0.4964 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9231 - val_specificity_at_sensitivity_2: 0.9390 - val_recall_2: 0.6667 - val_precision_2: 0.8125 - val_auc_2: 0.8476\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4996 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.8966 - specificity_at_sensitivity_2: 0.9314 - recall_2: 0.7310 - precision_2: 0.7465 - auc_2: 0.8404\n",
            "Epoch 158: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4996 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.8966 - specificity_at_sensitivity_2: 0.9314 - recall_2: 0.7310 - precision_2: 0.7465 - auc_2: 0.8404 - val_loss: 0.4486 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9474 - val_specificity_at_sensitivity_2: 0.9643 - val_recall_2: 0.8026 - val_precision_2: 0.7722 - val_auc_2: 0.8859\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8993 - specificity_at_sensitivity_2: 0.9006 - recall_2: 0.6978 - precision_2: 0.7185 - auc_2: 0.8256\n",
            "Epoch 159: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5087 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8993 - specificity_at_sensitivity_2: 0.9006 - recall_2: 0.6978 - precision_2: 0.7185 - auc_2: 0.8256 - val_loss: 0.4994 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.8732 - val_specificity_at_sensitivity_2: 0.9551 - val_recall_2: 0.5775 - val_precision_2: 0.8542 - val_auc_2: 0.8432\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5082 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.8810 - specificity_at_sensitivity_2: 0.9433 - recall_2: 0.6429 - precision_2: 0.7431 - auc_2: 0.8165\n",
            "Epoch 160: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5082 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.8810 - specificity_at_sensitivity_2: 0.9433 - recall_2: 0.6429 - precision_2: 0.7431 - auc_2: 0.8165 - val_loss: 0.4721 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9302 - val_specificity_at_sensitivity_2: 0.9865 - val_recall_2: 0.7907 - val_precision_2: 0.8500 - val_auc_2: 0.8746\n",
            "Epoch 161/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4889 - accuracy: 0.7773 - sensitivity_at_specificity_2: 0.9280 - specificity_at_sensitivity_2: 0.9084 - recall_2: 0.7920 - precision_2: 0.7615 - auc_2: 0.8485\n",
            "Epoch 161: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4996 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9125 - specificity_at_sensitivity_2: 0.9312 - recall_2: 0.7875 - precision_2: 0.7545 - auc_2: 0.8416 - val_loss: 0.4704 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 0.9747 - val_recall_2: 0.7407 - val_precision_2: 0.7792 - val_auc_2: 0.8685\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9560 - specificity_at_sensitivity_2: 0.9503 - recall_2: 0.8050 - precision_2: 0.7901 - auc_2: 0.8749\n",
            "Epoch 162: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4580 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9560 - specificity_at_sensitivity_2: 0.9503 - recall_2: 0.8050 - precision_2: 0.7901 - auc_2: 0.8749 - val_loss: 0.4358 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9268 - val_specificity_at_sensitivity_2: 0.9744 - val_recall_2: 0.8537 - val_precision_2: 0.8235 - val_auc_2: 0.8881\n",
            "Epoch 163/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4915 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8716 - specificity_at_sensitivity_2: 0.9388 - recall_2: 0.7064 - precision_2: 0.7064 - auc_2: 0.8345\n",
            "Epoch 163: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4962 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8750 - specificity_at_sensitivity_2: 0.9076 - recall_2: 0.6691 - precision_2: 0.7222 - auc_2: 0.8307 - val_loss: 0.5153 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9167 - val_specificity_at_sensitivity_2: 0.9342 - val_recall_2: 0.6429 - val_precision_2: 0.8308 - val_auc_2: 0.8468\n",
            "Epoch 164/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4829 - accuracy: 0.7723 - sensitivity_at_specificity_2: 0.9011 - specificity_at_sensitivity_2: 0.9173 - recall_2: 0.7253 - precision_2: 0.7174 - auc_2: 0.8419\n",
            "Epoch 164: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4893 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9015 - specificity_at_sensitivity_2: 0.9096 - recall_2: 0.7424 - precision_2: 0.7101 - auc_2: 0.8397 - val_loss: 0.4645 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9286 - val_specificity_at_sensitivity_2: 0.9556 - val_recall_2: 0.6714 - val_precision_2: 0.7833 - val_auc_2: 0.8644\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4619 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9259 - specificity_at_sensitivity_2: 0.9459 - recall_2: 0.6963 - precision_2: 0.7642 - auc_2: 0.8607\n",
            "Epoch 165: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4619 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9259 - specificity_at_sensitivity_2: 0.9459 - recall_2: 0.6963 - precision_2: 0.7642 - auc_2: 0.8607 - val_loss: 0.4320 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9351 - val_specificity_at_sensitivity_2: 0.9639 - val_recall_2: 0.7662 - val_precision_2: 0.8310 - val_auc_2: 0.8866\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5186 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.9162 - specificity_at_sensitivity_2: 0.9020 - recall_2: 0.7844 - precision_2: 0.7401 - auc_2: 0.8212\n",
            "Epoch 166: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5186 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.9162 - specificity_at_sensitivity_2: 0.9020 - recall_2: 0.7844 - precision_2: 0.7401 - auc_2: 0.8212 - val_loss: 0.4828 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9146 - val_specificity_at_sensitivity_2: 0.9872 - val_recall_2: 0.8293 - val_precision_2: 0.7312 - val_auc_2: 0.8571\n",
            "Epoch 167/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5140 - accuracy: 0.7455 - sensitivity_at_specificity_2: 0.8936 - specificity_at_sensitivity_2: 0.9154 - recall_2: 0.7553 - precision_2: 0.6762 - auc_2: 0.8202\n",
            "Epoch 167: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5440 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.8521 - specificity_at_sensitivity_2: 0.8876 - recall_2: 0.6690 - precision_2: 0.7143 - auc_2: 0.7963 - val_loss: 0.4904 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9296 - val_specificity_at_sensitivity_2: 0.9888 - val_recall_2: 0.5493 - val_precision_2: 0.9286 - val_auc_2: 0.8824\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9197 - specificity_at_sensitivity_2: 0.9508 - recall_2: 0.7445 - precision_2: 0.7391 - auc_2: 0.8510\n",
            "Epoch 168: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4800 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9197 - specificity_at_sensitivity_2: 0.9508 - recall_2: 0.7445 - precision_2: 0.7391 - auc_2: 0.8510 - val_loss: 0.4867 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9487 - val_specificity_at_sensitivity_2: 0.9390 - val_recall_2: 0.8590 - val_precision_2: 0.7128 - val_auc_2: 0.8555\n",
            "Epoch 169/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4153 - accuracy: 0.8259 - sensitivity_at_specificity_2: 0.9368 - specificity_at_sensitivity_2: 0.9690 - recall_2: 0.7789 - precision_2: 0.8043 - auc_2: 0.9017\n",
            "Epoch 169: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4126 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9308 - specificity_at_sensitivity_2: 0.9684 - recall_2: 0.7692 - precision_2: 0.8065 - auc_2: 0.8972 - val_loss: 0.4296 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9718 - val_specificity_at_sensitivity_2: 0.9775 - val_recall_2: 0.6901 - val_precision_2: 0.8596 - val_auc_2: 0.9008\n",
            "Epoch 170/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4610 - accuracy: 0.8047 - sensitivity_at_specificity_2: 0.9478 - specificity_at_sensitivity_2: 0.8936 - recall_2: 0.7826 - precision_2: 0.7826 - auc_2: 0.8626\n",
            "Epoch 170: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4691 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9034 - recall_2: 0.7917 - precision_2: 0.7651 - auc_2: 0.8581 - val_loss: 0.4806 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.8780 - val_specificity_at_sensitivity_2: 0.9744 - val_recall_2: 0.7805 - val_precision_2: 0.8101 - val_auc_2: 0.8616\n",
            "Epoch 171/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4236 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9292 - specificity_at_sensitivity_2: 0.9657 - recall_2: 0.7345 - precision_2: 0.7757 - auc_2: 0.8807\n",
            "Epoch 171: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4271 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9308 - specificity_at_sensitivity_2: 0.9526 - recall_2: 0.7308 - precision_2: 0.7851 - auc_2: 0.8810 - val_loss: 0.4877 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.8837 - val_specificity_at_sensitivity_2: 0.9595 - val_recall_2: 0.7558 - val_precision_2: 0.9155 - val_auc_2: 0.8724\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5016 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.8881 - specificity_at_sensitivity_2: 0.9322 - recall_2: 0.7622 - precision_2: 0.7365 - auc_2: 0.8366\n",
            "Epoch 172: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5016 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.8881 - specificity_at_sensitivity_2: 0.9322 - recall_2: 0.7622 - precision_2: 0.7365 - auc_2: 0.8366 - val_loss: 0.5423 - val_accuracy: 0.7188 - val_sensitivity_at_specificity_2: 0.8500 - val_specificity_at_sensitivity_2: 0.9500 - val_recall_2: 0.7875 - val_precision_2: 0.6923 - val_auc_2: 0.8159\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9021 - specificity_at_sensitivity_2: 0.9435 - recall_2: 0.6993 - precision_2: 0.7353 - auc_2: 0.8271\n",
            "Epoch 173: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5112 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9021 - specificity_at_sensitivity_2: 0.9435 - recall_2: 0.6993 - precision_2: 0.7353 - auc_2: 0.8271 - val_loss: 0.4151 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9444 - val_specificity_at_sensitivity_2: 0.9857 - val_recall_2: 0.8444 - val_precision_2: 0.8444 - val_auc_2: 0.9017\n",
            "Epoch 174/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4749 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9423 - specificity_at_sensitivity_2: 0.9211 - recall_2: 0.7308 - precision_2: 0.7037 - auc_2: 0.8495\n",
            "Epoch 174: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4941 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9242 - specificity_at_sensitivity_2: 0.8989 - recall_2: 0.6742 - precision_2: 0.7008 - auc_2: 0.8340 - val_loss: 0.4382 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9306 - val_specificity_at_sensitivity_2: 0.9659 - val_recall_2: 0.7222 - val_precision_2: 0.8125 - val_auc_2: 0.8853\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9467 - specificity_at_sensitivity_2: 0.8882 - recall_2: 0.8200 - precision_2: 0.7455 - auc_2: 0.8460\n",
            "Epoch 175: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4867 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9467 - specificity_at_sensitivity_2: 0.8882 - recall_2: 0.8200 - precision_2: 0.7455 - auc_2: 0.8460 - val_loss: 0.5152 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.8889 - val_specificity_at_sensitivity_2: 0.9114 - val_recall_2: 0.7778 - val_precision_2: 0.7683 - val_auc_2: 0.8270\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5444 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.9044 - specificity_at_sensitivity_2: 0.8804 - recall_2: 0.6250 - precision_2: 0.7083 - auc_2: 0.7993\n",
            "Epoch 176: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5444 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.9044 - specificity_at_sensitivity_2: 0.8804 - recall_2: 0.6250 - precision_2: 0.7083 - auc_2: 0.7993 - val_loss: 0.5625 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9438 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.5281 - val_precision_2: 0.9592 - val_auc_2: 0.8850\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5056 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9150 - specificity_at_sensitivity_2: 0.9281 - recall_2: 0.7778 - precision_2: 0.7256 - auc_2: 0.8332\n",
            "Epoch 177: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5056 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9150 - specificity_at_sensitivity_2: 0.9281 - recall_2: 0.7778 - precision_2: 0.7256 - auc_2: 0.8332 - val_loss: 0.4544 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9714 - val_specificity_at_sensitivity_2: 0.9778 - val_recall_2: 0.9000 - val_precision_2: 0.6702 - val_auc_2: 0.8992\n",
            "Epoch 178/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5282 - accuracy: 0.7383 - sensitivity_at_specificity_2: 0.8839 - specificity_at_sensitivity_2: 0.8750 - recall_2: 0.6607 - precision_2: 0.7184 - auc_2: 0.8090\n",
            "Epoch 178: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5342 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.8951 - specificity_at_sensitivity_2: 0.8814 - recall_2: 0.6294 - precision_2: 0.7438 - auc_2: 0.8092 - val_loss: 0.4450 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9718 - val_specificity_at_sensitivity_2: 0.8989 - val_recall_2: 0.6901 - val_precision_2: 0.8305 - val_auc_2: 0.8903\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9608 - specificity_at_sensitivity_2: 0.9521 - recall_2: 0.8301 - precision_2: 0.7175 - auc_2: 0.8560\n",
            "Epoch 179: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4826 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9608 - specificity_at_sensitivity_2: 0.9521 - recall_2: 0.8301 - precision_2: 0.7175 - auc_2: 0.8560 - val_loss: 0.5058 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.8767 - val_specificity_at_sensitivity_2: 0.9425 - val_recall_2: 0.7945 - val_precision_2: 0.7160 - val_auc_2: 0.8425\n",
            "Epoch 180/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4528 - accuracy: 0.8008 - sensitivity_at_specificity_2: 0.9533 - specificity_at_sensitivity_2: 0.9195 - recall_2: 0.7570 - precision_2: 0.7642 - auc_2: 0.8661\n",
            "Epoch 180: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4562 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9489 - specificity_at_sensitivity_2: 0.9290 - recall_2: 0.7299 - precision_2: 0.7874 - auc_2: 0.8664 - val_loss: 0.4992 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9091 - val_specificity_at_sensitivity_2: 0.9722 - val_recall_2: 0.7614 - val_precision_2: 0.8375 - val_auc_2: 0.8568\n",
            "Epoch 181/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4947 - accuracy: 0.7545 - sensitivity_at_specificity_2: 0.9083 - specificity_at_sensitivity_2: 0.9739 - recall_2: 0.7248 - precision_2: 0.7596 - auc_2: 0.8406\n",
            "Epoch 181: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4686 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9286 - specificity_at_sensitivity_2: 0.9759 - recall_2: 0.7922 - precision_2: 0.7531 - auc_2: 0.8627 - val_loss: 0.4423 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9420 - val_specificity_at_sensitivity_2: 0.9890 - val_recall_2: 0.8261 - val_precision_2: 0.6786 - val_auc_2: 0.8844\n",
            "Epoch 182/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5068 - accuracy: 0.7617 - sensitivity_at_specificity_2: 0.9018 - specificity_at_sensitivity_2: 0.9167 - recall_2: 0.7589 - precision_2: 0.7143 - auc_2: 0.8288\n",
            "Epoch 182: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5211 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8986 - specificity_at_sensitivity_2: 0.9066 - recall_2: 0.7029 - precision_2: 0.7029 - auc_2: 0.8158 - val_loss: 0.4601 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9444 - val_specificity_at_sensitivity_2: 0.9545 - val_recall_2: 0.6806 - val_precision_2: 0.8909 - val_auc_2: 0.8837\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4816 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9267 - specificity_at_sensitivity_2: 0.9529 - recall_2: 0.7067 - precision_2: 0.7518 - auc_2: 0.8516\n",
            "Epoch 183: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4816 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9267 - specificity_at_sensitivity_2: 0.9529 - recall_2: 0.7067 - precision_2: 0.7518 - auc_2: 0.8516 - val_loss: 0.4033 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9559 - val_specificity_at_sensitivity_2: 0.9674 - val_recall_2: 0.8382 - val_precision_2: 0.7808 - val_auc_2: 0.9008\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9456 - specificity_at_sensitivity_2: 0.9595 - recall_2: 0.7959 - precision_2: 0.7800 - auc_2: 0.8810\n",
            "Epoch 184: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4421 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9456 - specificity_at_sensitivity_2: 0.9595 - recall_2: 0.7959 - precision_2: 0.7800 - auc_2: 0.8810 - val_loss: 0.4399 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9540 - val_specificity_at_sensitivity_2: 0.9863 - val_recall_2: 0.7471 - val_precision_2: 0.8904 - val_auc_2: 0.8976\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8889 - specificity_at_sensitivity_2: 0.9432 - recall_2: 0.7083 - precision_2: 0.7286 - auc_2: 0.8247\n",
            "Epoch 185: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.5177 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8889 - specificity_at_sensitivity_2: 0.9432 - recall_2: 0.7083 - precision_2: 0.7286 - auc_2: 0.8247 - val_loss: 0.4529 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.8955 - val_specificity_at_sensitivity_2: 0.9355 - val_recall_2: 0.8060 - val_precision_2: 0.7297 - val_auc_2: 0.8693\n",
            "Epoch 186/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5075 - accuracy: 0.7411 - sensitivity_at_specificity_2: 0.8617 - specificity_at_sensitivity_2: 0.9692 - recall_2: 0.7234 - precision_2: 0.6800 - auc_2: 0.8268\n",
            "Epoch 186: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5063 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8714 - specificity_at_sensitivity_2: 0.9667 - recall_2: 0.6857 - precision_2: 0.7164 - auc_2: 0.8297 - val_loss: 0.4477 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9875 - val_specificity_at_sensitivity_2: 0.9500 - val_recall_2: 0.6750 - val_precision_2: 0.9000 - val_auc_2: 0.9109\n",
            "Epoch 187/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4620 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9412 - specificity_at_sensitivity_2: 0.9343 - recall_2: 0.7731 - precision_2: 0.7863 - auc_2: 0.8697\n",
            "Epoch 187: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4679 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9456 - specificity_at_sensitivity_2: 0.9306 - recall_2: 0.7823 - precision_2: 0.7667 - auc_2: 0.8629 - val_loss: 0.4473 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9487 - val_specificity_at_sensitivity_2: 0.9756 - val_recall_2: 0.8205 - val_precision_2: 0.7529 - val_auc_2: 0.8790\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9020 - specificity_at_sensitivity_2: 0.9461 - recall_2: 0.7908 - precision_2: 0.7961 - auc_2: 0.8672\n",
            "Epoch 188: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4601 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9020 - specificity_at_sensitivity_2: 0.9461 - recall_2: 0.7908 - precision_2: 0.7961 - auc_2: 0.8672 - val_loss: 0.4146 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9630 - val_specificity_at_sensitivity_2: 0.9747 - val_recall_2: 0.8148 - val_precision_2: 0.8250 - val_auc_2: 0.8988\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9565 - specificity_at_sensitivity_2: 0.9725 - recall_2: 0.7754 - precision_2: 0.7810 - auc_2: 0.8873\n",
            "Epoch 189: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4256 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9565 - specificity_at_sensitivity_2: 0.9725 - recall_2: 0.7754 - precision_2: 0.7810 - auc_2: 0.8873 - val_loss: 0.4412 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9634 - val_specificity_at_sensitivity_2: 0.9872 - val_recall_2: 0.7561 - val_precision_2: 0.8052 - val_auc_2: 0.8852\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4734 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9116 - specificity_at_sensitivity_2: 0.9653 - recall_2: 0.7279 - precision_2: 0.7810 - auc_2: 0.8584\n",
            "Epoch 190: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4734 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9116 - specificity_at_sensitivity_2: 0.9653 - recall_2: 0.7279 - precision_2: 0.7810 - auc_2: 0.8584 - val_loss: 0.4148 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9277 - val_specificity_at_sensitivity_2: 0.9870 - val_recall_2: 0.8313 - val_precision_2: 0.8415 - val_auc_2: 0.8981\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9225 - specificity_at_sensitivity_2: 0.9581 - recall_2: 0.7907 - precision_2: 0.7445 - auc_2: 0.8713\n",
            "Epoch 191: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4447 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9225 - specificity_at_sensitivity_2: 0.9581 - recall_2: 0.7907 - precision_2: 0.7445 - auc_2: 0.8713 - val_loss: 0.5196 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.8961 - val_specificity_at_sensitivity_2: 0.9398 - val_recall_2: 0.6623 - val_precision_2: 0.8500 - val_auc_2: 0.8399\n",
            "Epoch 192/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5189 - accuracy: 0.7723 - sensitivity_at_specificity_2: 0.8763 - specificity_at_sensitivity_2: 0.9213 - recall_2: 0.6598 - precision_2: 0.7805 - auc_2: 0.8224\n",
            "Epoch 192: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5225 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.8776 - specificity_at_sensitivity_2: 0.9075 - recall_2: 0.7007 - precision_2: 0.7803 - auc_2: 0.8216 - val_loss: 0.4447 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9268 - val_specificity_at_sensitivity_2: 0.9744 - val_recall_2: 0.7683 - val_precision_2: 0.7975 - val_auc_2: 0.8787\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9184 - specificity_at_sensitivity_2: 0.9133 - recall_2: 0.7347 - precision_2: 0.7770 - auc_2: 0.8347\n",
            "Epoch 193: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5034 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9184 - specificity_at_sensitivity_2: 0.9133 - recall_2: 0.7347 - precision_2: 0.7770 - auc_2: 0.8347 - val_loss: 0.5132 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.8767 - val_specificity_at_sensitivity_2: 0.9425 - val_recall_2: 0.7397 - val_precision_2: 0.7200 - val_auc_2: 0.8278\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9342 - specificity_at_sensitivity_2: 0.9167 - recall_2: 0.8224 - precision_2: 0.7396 - auc_2: 0.8609\n",
            "Epoch 194: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4688 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9342 - specificity_at_sensitivity_2: 0.9167 - recall_2: 0.8224 - precision_2: 0.7396 - auc_2: 0.8609 - val_loss: 0.4568 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9167 - val_specificity_at_sensitivity_2: 0.9737 - val_recall_2: 0.7619 - val_precision_2: 0.9143 - val_auc_2: 0.8911\n",
            "Epoch 195/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5098 - accuracy: 0.7455 - sensitivity_at_specificity_2: 0.9182 - specificity_at_sensitivity_2: 0.9561 - recall_2: 0.6545 - precision_2: 0.7912 - auc_2: 0.8381\n",
            "Epoch 195: val_accuracy improved from 0.85625 to 0.86250, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4946 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9276 - specificity_at_sensitivity_2: 0.9524 - recall_2: 0.7105 - precision_2: 0.7714 - auc_2: 0.8417 - val_loss: 0.4043 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9444 - val_specificity_at_sensitivity_2: 0.9857 - val_recall_2: 0.8889 - val_precision_2: 0.8696 - val_auc_2: 0.9045\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5233 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.8849 - specificity_at_sensitivity_2: 0.8840 - recall_2: 0.7266 - precision_2: 0.6779 - auc_2: 0.8135\n",
            "Epoch 196: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5233 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.8849 - specificity_at_sensitivity_2: 0.8840 - recall_2: 0.7266 - precision_2: 0.6779 - auc_2: 0.8135 - val_loss: 0.4496 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9467 - val_specificity_at_sensitivity_2: 0.9765 - val_recall_2: 0.6800 - val_precision_2: 0.8947 - val_auc_2: 0.8884\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4787 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9067 - specificity_at_sensitivity_2: 0.9471 - recall_2: 0.7333 - precision_2: 0.7801 - auc_2: 0.8544\n",
            "Epoch 197: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4787 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9067 - specificity_at_sensitivity_2: 0.9471 - recall_2: 0.7333 - precision_2: 0.7801 - auc_2: 0.8544 - val_loss: 0.4309 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9155 - val_specificity_at_sensitivity_2: 0.9888 - val_recall_2: 0.8028 - val_precision_2: 0.7500 - val_auc_2: 0.8827\n",
            "Epoch 198/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5073 - accuracy: 0.7361 - sensitivity_at_specificity_2: 0.9124 - specificity_at_sensitivity_2: 0.9205 - recall_2: 0.7445 - precision_2: 0.7133 - auc_2: 0.8317\n",
            "Epoch 198: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5145 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9032 - specificity_at_sensitivity_2: 0.9212 - recall_2: 0.7290 - precision_2: 0.7244 - auc_2: 0.8264 - val_loss: 0.4459 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9512 - val_specificity_at_sensitivity_2: 0.9615 - val_recall_2: 0.6585 - val_precision_2: 0.8571 - val_auc_2: 0.8917\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5191 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.8861 - specificity_at_sensitivity_2: 0.9198 - recall_2: 0.7342 - precision_2: 0.7484 - auc_2: 0.8223\n",
            "Epoch 199: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5191 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.8861 - specificity_at_sensitivity_2: 0.9198 - recall_2: 0.7342 - precision_2: 0.7484 - auc_2: 0.8223 - val_loss: 0.4521 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9390 - val_specificity_at_sensitivity_2: 0.9744 - val_recall_2: 0.7805 - val_precision_2: 0.7901 - val_auc_2: 0.8730\n",
            "Epoch 200/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5493 - accuracy: 0.7422 - sensitivity_at_specificity_2: 0.8584 - specificity_at_sensitivity_2: 0.8811 - recall_2: 0.6460 - precision_2: 0.7374 - auc_2: 0.7911\n",
            "Epoch 200: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5425 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.8500 - specificity_at_sensitivity_2: 0.9167 - recall_2: 0.6571 - precision_2: 0.7541 - auc_2: 0.7957 - val_loss: 0.4719 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9294 - val_specificity_at_sensitivity_2: 0.9867 - val_recall_2: 0.7882 - val_precision_2: 0.8816 - val_auc_2: 0.8755\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4930 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.8915 - specificity_at_sensitivity_2: 0.9424 - recall_2: 0.6977 - precision_2: 0.7759 - auc_2: 0.8339\n",
            "Epoch 201: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4930 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.8915 - specificity_at_sensitivity_2: 0.9424 - recall_2: 0.6977 - precision_2: 0.7759 - auc_2: 0.8339 - val_loss: 0.4316 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9143 - val_specificity_at_sensitivity_2: 0.9889 - val_recall_2: 0.7714 - val_precision_2: 0.8308 - val_auc_2: 0.8913\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4556 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9716 - recall_2: 0.7569 - precision_2: 0.7786 - auc_2: 0.8724\n",
            "Epoch 202: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4556 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9716 - recall_2: 0.7569 - precision_2: 0.7786 - auc_2: 0.8724 - val_loss: 0.4944 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9157 - val_specificity_at_sensitivity_2: 0.9481 - val_recall_2: 0.7229 - val_precision_2: 0.8571 - val_auc_2: 0.8568\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9167 - specificity_at_sensitivity_2: 0.9415 - recall_2: 0.6818 - precision_2: 0.7500 - auc_2: 0.8404\n",
            "Epoch 203: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4849 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9167 - specificity_at_sensitivity_2: 0.9415 - recall_2: 0.6818 - precision_2: 0.7500 - auc_2: 0.8404 - val_loss: 0.4455 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9425 - val_specificity_at_sensitivity_2: 0.9863 - val_recall_2: 0.7011 - val_precision_2: 0.8714 - val_auc_2: 0.8892\n",
            "Epoch 204/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4513 - accuracy: 0.7930 - sensitivity_at_specificity_2: 0.9256 - specificity_at_sensitivity_2: 0.9852 - recall_2: 0.8264 - precision_2: 0.7576 - auc_2: 0.8702\n",
            "Epoch 204: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.4472 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9342 - specificity_at_sensitivity_2: 0.9821 - recall_2: 0.8224 - precision_2: 0.7576 - auc_2: 0.8724 - val_loss: 0.3737 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7692 - val_precision_2: 0.8696 - val_auc_2: 0.9207\n",
            "Epoch 205/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4817 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9145 - specificity_at_sensitivity_2: 0.9568 - recall_2: 0.7179 - precision_2: 0.8155 - auc_2: 0.8466\n",
            "Epoch 205: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4758 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9272 - specificity_at_sensitivity_2: 0.9467 - recall_2: 0.7285 - precision_2: 0.8333 - auc_2: 0.8546 - val_loss: 0.4802 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9130 - val_specificity_at_sensitivity_2: 0.9341 - val_recall_2: 0.7681 - val_precision_2: 0.6883 - val_auc_2: 0.8486\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4907 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9226 - specificity_at_sensitivity_2: 0.9273 - recall_2: 0.7935 - precision_2: 0.7546 - auc_2: 0.8459\n",
            "Epoch 206: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4907 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9226 - specificity_at_sensitivity_2: 0.9273 - recall_2: 0.7935 - precision_2: 0.7546 - auc_2: 0.8459 - val_loss: 0.4594 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9375 - val_specificity_at_sensitivity_2: 0.9875 - val_recall_2: 0.7500 - val_precision_2: 0.7792 - val_auc_2: 0.8695\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4559 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9008 - specificity_at_sensitivity_2: 0.9447 - recall_2: 0.6942 - precision_2: 0.7434 - auc_2: 0.8561\n",
            "Epoch 207: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4559 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9008 - specificity_at_sensitivity_2: 0.9447 - recall_2: 0.6942 - precision_2: 0.7434 - auc_2: 0.8561 - val_loss: 0.5002 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9390 - val_specificity_at_sensitivity_2: 0.9615 - val_recall_2: 0.6341 - val_precision_2: 0.8966 - val_auc_2: 0.8809\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.8611 - specificity_at_sensitivity_2: 0.9432 - recall_2: 0.6389 - precision_2: 0.8214 - auc_2: 0.8388\n",
            "Epoch 208: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4990 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.8611 - specificity_at_sensitivity_2: 0.9432 - recall_2: 0.6389 - precision_2: 0.8214 - auc_2: 0.8388 - val_loss: 0.4226 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9419 - val_specificity_at_sensitivity_2: 0.9730 - val_recall_2: 0.8140 - val_precision_2: 0.7865 - val_auc_2: 0.8885\n",
            "Epoch 209/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4832 - accuracy: 0.7461 - sensitivity_at_specificity_2: 0.9160 - specificity_at_sensitivity_2: 0.9343 - recall_2: 0.8067 - precision_2: 0.6957 - auc_2: 0.8504\n",
            "Epoch 209: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4937 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9189 - specificity_at_sensitivity_2: 0.9186 - recall_2: 0.7703 - precision_2: 0.7081 - auc_2: 0.8403 - val_loss: 0.5004 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9059 - val_specificity_at_sensitivity_2: 0.9733 - val_recall_2: 0.7059 - val_precision_2: 0.8219 - val_auc_2: 0.8510\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9037 - specificity_at_sensitivity_2: 0.9405 - recall_2: 0.6889 - precision_2: 0.7750 - auc_2: 0.8507\n",
            "Epoch 210: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4730 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9037 - specificity_at_sensitivity_2: 0.9405 - recall_2: 0.6889 - precision_2: 0.7750 - auc_2: 0.8507 - val_loss: 0.4927 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.8989 - val_specificity_at_sensitivity_2: 0.9296 - val_recall_2: 0.7753 - val_precision_2: 0.8023 - val_auc_2: 0.8438\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9133 - specificity_at_sensitivity_2: 0.9941 - recall_2: 0.7933 - precision_2: 0.7778 - auc_2: 0.8791\n",
            "Epoch 211: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4371 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9133 - specificity_at_sensitivity_2: 0.9941 - recall_2: 0.7933 - precision_2: 0.7778 - auc_2: 0.8791 - val_loss: 0.4700 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9552 - val_specificity_at_sensitivity_2: 0.9570 - val_recall_2: 0.7313 - val_precision_2: 0.7206 - val_auc_2: 0.8520\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.8971 - specificity_at_sensitivity_2: 0.9239 - recall_2: 0.6912 - precision_2: 0.7176 - auc_2: 0.8239\n",
            "Epoch 212: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.5076 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.8971 - specificity_at_sensitivity_2: 0.9239 - recall_2: 0.6912 - precision_2: 0.7176 - auc_2: 0.8239 - val_loss: 0.4790 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9326 - val_specificity_at_sensitivity_2: 0.9718 - val_recall_2: 0.7079 - val_precision_2: 0.9130 - val_auc_2: 0.8778\n",
            "Epoch 213/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4080 - accuracy: 0.8605 - sensitivity_at_specificity_2: 0.9223 - specificity_at_sensitivity_2: 0.9806 - recall_2: 0.7379 - precision_2: 0.8941 - auc_2: 0.8981                  \n",
            "Epoch 213: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4215 - accuracy: 0.8517 - sensitivity_at_specificity_2: 0.9244 - specificity_at_sensitivity_2: 0.9708 - recall_2: 0.7395 - precision_2: 0.8800 - auc_2: 0.8908 - val_loss: 0.5082 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.8929 - val_specificity_at_sensitivity_2: 0.9474 - val_recall_2: 0.7024 - val_precision_2: 0.8429 - val_auc_2: 0.8477\n",
            "Epoch 214/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4499 - accuracy: 0.7891 - sensitivity_at_specificity_2: 0.9600 - specificity_at_sensitivity_2: 0.9389 - recall_2: 0.8480 - precision_2: 0.7518 - auc_2: 0.8744\n",
            "Epoch 214: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4498 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9542 - specificity_at_sensitivity_2: 0.9521 - recall_2: 0.8497 - precision_2: 0.7471 - auc_2: 0.8752 - val_loss: 0.4746 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9310 - val_specificity_at_sensitivity_2: 0.9863 - val_recall_2: 0.7241 - val_precision_2: 0.8400 - val_auc_2: 0.8636\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4566 - accuracy: 0.7862 - sensitivity_at_specificity_2: 0.9412 - specificity_at_sensitivity_2: 0.9474 - recall_2: 0.6555 - precision_2: 0.7879 - auc_2: 0.8666\n",
            "Epoch 215: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4566 - accuracy: 0.7862 - sensitivity_at_specificity_2: 0.9412 - specificity_at_sensitivity_2: 0.9474 - recall_2: 0.6555 - precision_2: 0.7879 - auc_2: 0.8666 - val_loss: 0.4705 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9770 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.6552 - val_precision_2: 0.8636 - val_auc_2: 0.8880\n",
            "Epoch 216/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4922 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.9455 - specificity_at_sensitivity_2: 0.9110 - recall_2: 0.7455 - precision_2: 0.6949 - auc_2: 0.8400\n",
            "Epoch 216: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5021 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.9220 - specificity_at_sensitivity_2: 0.9162 - recall_2: 0.7589 - precision_2: 0.6859 - auc_2: 0.8351 - val_loss: 0.4215 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 0.9747 - val_recall_2: 0.7531 - val_precision_2: 0.8592 - val_auc_2: 0.8951\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4847 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9097 - specificity_at_sensitivity_2: 0.9489 - recall_2: 0.7153 - precision_2: 0.7630 - auc_2: 0.8458\n",
            "Epoch 217: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4847 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9097 - specificity_at_sensitivity_2: 0.9489 - recall_2: 0.7153 - precision_2: 0.7630 - auc_2: 0.8458 - val_loss: 0.4223 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9620 - val_specificity_at_sensitivity_2: 0.9877 - val_recall_2: 0.7215 - val_precision_2: 0.8769 - val_auc_2: 0.9087\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4606 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9456 - specificity_at_sensitivity_2: 0.9306 - recall_2: 0.7415 - precision_2: 0.7676 - auc_2: 0.8657\n",
            "Epoch 218: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4606 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9456 - specificity_at_sensitivity_2: 0.9306 - recall_2: 0.7415 - precision_2: 0.7676 - auc_2: 0.8657 - val_loss: 0.4525 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9412 - val_specificity_at_sensitivity_2: 0.9783 - val_recall_2: 0.8971 - val_precision_2: 0.6354 - val_auc_2: 0.8886\n",
            "Epoch 219/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4605 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.8835 - specificity_at_sensitivity_2: 0.9804 - recall_2: 0.7184 - precision_2: 0.7629 - auc_2: 0.8517\n",
            "Epoch 219: val_accuracy did not improve from 0.86250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4542 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9389 - specificity_at_sensitivity_2: 0.9630 - recall_2: 0.7176 - precision_2: 0.7769 - auc_2: 0.8601 - val_loss: 0.4860 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9759 - val_specificity_at_sensitivity_2: 0.9870 - val_recall_2: 0.5783 - val_precision_2: 0.8889 - val_auc_2: 0.9078\n",
            "Epoch 220/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4998 - accuracy: 0.7461 - sensitivity_at_specificity_2: 0.9174 - specificity_at_sensitivity_2: 0.8844 - recall_2: 0.6606 - precision_2: 0.7200 - auc_2: 0.8347\n",
            "Epoch 220: val_accuracy improved from 0.86250 to 0.86875, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.4806 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9296 - specificity_at_sensitivity_2: 0.9382 - recall_2: 0.7113 - precision_2: 0.7426 - auc_2: 0.8500 - val_loss: 0.3706 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9157 - val_specificity_at_sensitivity_2: 0.9870 - val_recall_2: 0.8554 - val_precision_2: 0.8875 - val_auc_2: 0.9219\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4624 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9220 - specificity_at_sensitivity_2: 0.9385 - recall_2: 0.7589 - precision_2: 0.7810 - auc_2: 0.8614\n",
            "Epoch 221: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4624 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9220 - specificity_at_sensitivity_2: 0.9385 - recall_2: 0.7589 - precision_2: 0.7810 - auc_2: 0.8614 - val_loss: 0.4305 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9136 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.7531 - val_precision_2: 0.8472 - val_auc_2: 0.8926\n",
            "Epoch 222/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4517 - accuracy: 0.7617 - sensitivity_at_specificity_2: 0.9500 - specificity_at_sensitivity_2: 0.9744 - recall_2: 0.7200 - precision_2: 0.6857 - auc_2: 0.8600\n",
            "Epoch 222: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4613 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9385 - specificity_at_sensitivity_2: 0.9684 - recall_2: 0.7231 - precision_2: 0.7015 - auc_2: 0.8560 - val_loss: 0.4349 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9241 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.6709 - val_precision_2: 0.9464 - val_auc_2: 0.9019\n",
            "Epoch 223/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4714 - accuracy: 0.7852 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9385 - recall_2: 0.7222 - precision_2: 0.8198 - auc_2: 0.8613\n",
            "Epoch 223: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4897 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9301 - specificity_at_sensitivity_2: 0.9153 - recall_2: 0.7413 - precision_2: 0.7310 - auc_2: 0.8423 - val_loss: 0.3951 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9610 - val_specificity_at_sensitivity_2: 0.9880 - val_recall_2: 0.8312 - val_precision_2: 0.8205 - val_auc_2: 0.9132\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9139 - specificity_at_sensitivity_2: 0.9527 - recall_2: 0.6755 - precision_2: 0.8160 - auc_2: 0.8565\n",
            "Epoch 224: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4806 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9139 - specificity_at_sensitivity_2: 0.9527 - recall_2: 0.6755 - precision_2: 0.8160 - auc_2: 0.8565 - val_loss: 0.5300 - val_accuracy: 0.7188 - val_sensitivity_at_specificity_2: 0.8837 - val_specificity_at_sensitivity_2: 0.9054 - val_recall_2: 0.7674 - val_precision_2: 0.7253 - val_auc_2: 0.8162\n",
            "Epoch 225/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4879 - accuracy: 0.7655 - sensitivity_at_specificity_2: 0.9080 - specificity_at_sensitivity_2: 0.9281 - recall_2: 0.6897 - precision_2: 0.6977 - auc_2: 0.8311\n",
            "Epoch 225: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5094 - accuracy: 0.7621 - sensitivity_at_specificity_2: 0.8739 - specificity_at_sensitivity_2: 0.9274 - recall_2: 0.6126 - precision_2: 0.7234 - auc_2: 0.8099 - val_loss: 0.5024 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9610 - val_specificity_at_sensitivity_2: 0.9639 - val_recall_2: 0.5325 - val_precision_2: 0.9111 - val_auc_2: 0.9077\n",
            "Epoch 226/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4677 - accuracy: 0.7852 - sensitivity_at_specificity_2: 0.9115 - specificity_at_sensitivity_2: 0.9301 - recall_2: 0.6637 - precision_2: 0.8152 - auc_2: 0.8621\n",
            "Epoch 226: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4614 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9225 - specificity_at_sensitivity_2: 0.9494 - recall_2: 0.6831 - precision_2: 0.7951 - auc_2: 0.8636 - val_loss: 0.4539 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9518 - val_specificity_at_sensitivity_2: 0.9610 - val_recall_2: 0.8795 - val_precision_2: 0.7604 - val_auc_2: 0.8758\n",
            "Epoch 227/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5388 - accuracy: 0.7326 - sensitivity_at_specificity_2: 0.8772 - specificity_at_sensitivity_2: 0.8819 - recall_2: 0.7105 - precision_2: 0.6923 - auc_2: 0.8019\n",
            "Epoch 227: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5372 - accuracy: 0.7310 - sensitivity_at_specificity_2: 0.8769 - specificity_at_sensitivity_2: 0.8875 - recall_2: 0.6769 - precision_2: 0.7097 - auc_2: 0.8023 - val_loss: 0.4698 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9390 - val_specificity_at_sensitivity_2: 0.9872 - val_recall_2: 0.6707 - val_precision_2: 0.9483 - val_auc_2: 0.8963\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9026 - specificity_at_sensitivity_2: 0.9759 - recall_2: 0.6818 - precision_2: 0.8203 - auc_2: 0.8414\n",
            "Epoch 228: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4991 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9026 - specificity_at_sensitivity_2: 0.9759 - recall_2: 0.6818 - precision_2: 0.8203 - auc_2: 0.8414 - val_loss: 0.4844 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9241 - val_specificity_at_sensitivity_2: 0.9136 - val_recall_2: 0.7595 - val_precision_2: 0.7595 - val_auc_2: 0.8472\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.9122 - specificity_at_sensitivity_2: 0.9360 - recall_2: 0.8243 - precision_2: 0.7011 - auc_2: 0.8420\n",
            "Epoch 229: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5040 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.9122 - specificity_at_sensitivity_2: 0.9360 - recall_2: 0.8243 - precision_2: 0.7011 - auc_2: 0.8420 - val_loss: 0.4433 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.8987 - val_specificity_at_sensitivity_2: 0.9877 - val_recall_2: 0.6962 - val_precision_2: 0.8594 - val_auc_2: 0.8855\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4269 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9291 - specificity_at_sensitivity_2: 0.9888 - recall_2: 0.6879 - precision_2: 0.8818 - auc_2: 0.8906\n",
            "Epoch 230: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4269 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9291 - specificity_at_sensitivity_2: 0.9888 - recall_2: 0.6879 - precision_2: 0.8818 - auc_2: 0.8906 - val_loss: 0.5555 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.8444 - val_specificity_at_sensitivity_2: 0.9286 - val_recall_2: 0.6667 - val_precision_2: 0.9091 - val_auc_2: 0.8247\n",
            "Epoch 231/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4780 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9018 - specificity_at_sensitivity_2: 0.9444 - recall_2: 0.7946 - precision_2: 0.7542 - auc_2: 0.8521\n",
            "Epoch 231: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4616 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9078 - specificity_at_sensitivity_2: 0.9497 - recall_2: 0.8085 - precision_2: 0.7755 - auc_2: 0.8634 - val_loss: 0.4317 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9394 - val_specificity_at_sensitivity_2: 0.9787 - val_recall_2: 0.6667 - val_precision_2: 0.8980 - val_auc_2: 0.8774\n",
            "Epoch 232/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4406 - accuracy: 0.8214 - sensitivity_at_specificity_2: 0.9255 - specificity_at_sensitivity_2: 0.9615 - recall_2: 0.7021 - precision_2: 0.8462 - auc_2: 0.8771\n",
            "Epoch 232: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4438 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9173 - specificity_at_sensitivity_2: 0.9572 - recall_2: 0.6992 - precision_2: 0.8017 - auc_2: 0.8702 - val_loss: 0.4390 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9390 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7073 - val_precision_2: 0.8286 - val_auc_2: 0.8845\n",
            "Epoch 233/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4806 - accuracy: 0.7891 - sensitivity_at_specificity_2: 0.8909 - specificity_at_sensitivity_2: 0.9521 - recall_2: 0.7818 - precision_2: 0.7414 - auc_2: 0.8458\n",
            "Epoch 233: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4638 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9098 - specificity_at_sensitivity_2: 0.9412 - recall_2: 0.7895 - precision_2: 0.7500 - auc_2: 0.8557 - val_loss: 0.4536 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9630 - val_specificity_at_sensitivity_2: 0.9367 - val_recall_2: 0.6667 - val_precision_2: 0.8438 - val_auc_2: 0.8889\n",
            "Epoch 234/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4586 - accuracy: 0.7835 - sensitivity_at_specificity_2: 0.9512 - specificity_at_sensitivity_2: 0.9375 - recall_2: 0.6341 - precision_2: 0.8125 - auc_2: 0.8702\n",
            "Epoch 234: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4560 - accuracy: 0.7966 - sensitivity_at_specificity_2: 0.9496 - specificity_at_sensitivity_2: 0.9415 - recall_2: 0.6639 - precision_2: 0.8061 - auc_2: 0.8672 - val_loss: 0.4342 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9306 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7778 - val_precision_2: 0.7467 - val_auc_2: 0.8814\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4123 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9304 - specificity_at_sensitivity_2: 0.9877 - recall_2: 0.8101 - precision_2: 0.8153 - auc_2: 0.8976\n",
            "Epoch 235: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4123 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9304 - specificity_at_sensitivity_2: 0.9877 - recall_2: 0.8101 - precision_2: 0.8153 - auc_2: 0.8976 - val_loss: 0.4613 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9326 - val_specificity_at_sensitivity_2: 0.9718 - val_recall_2: 0.7753 - val_precision_2: 0.8214 - val_auc_2: 0.8665\n",
            "Epoch 236/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4716 - accuracy: 0.7723 - sensitivity_at_specificity_2: 0.9238 - specificity_at_sensitivity_2: 0.9496 - recall_2: 0.6857 - precision_2: 0.8000 - auc_2: 0.8593\n",
            "Epoch 236: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4750 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9172 - specificity_at_sensitivity_2: 0.9371 - recall_2: 0.7103 - precision_2: 0.7744 - auc_2: 0.8521 - val_loss: 0.4491 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9359 - val_specificity_at_sensitivity_2: 0.9512 - val_recall_2: 0.8205 - val_precision_2: 0.7619 - val_auc_2: 0.8727\n",
            "Epoch 237/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5113 - accuracy: 0.7455 - sensitivity_at_specificity_2: 0.9474 - specificity_at_sensitivity_2: 0.8605 - recall_2: 0.7158 - precision_2: 0.6939 - auc_2: 0.8268\n",
            "Epoch 237: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4870 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9429 - specificity_at_sensitivity_2: 0.8944 - recall_2: 0.7071 - precision_2: 0.7500 - auc_2: 0.8453 - val_loss: 0.4889 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9529 - val_specificity_at_sensitivity_2: 0.9333 - val_recall_2: 0.7059 - val_precision_2: 0.8000 - val_auc_2: 0.8676\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9247 - specificity_at_sensitivity_2: 0.9540 - recall_2: 0.7808 - precision_2: 0.7500 - auc_2: 0.8682\n",
            "Epoch 238: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4532 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9247 - specificity_at_sensitivity_2: 0.9540 - recall_2: 0.7808 - precision_2: 0.7500 - auc_2: 0.8682 - val_loss: 0.4247 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9186 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7907 - val_precision_2: 0.7907 - val_auc_2: 0.8876\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9023 - specificity_at_sensitivity_2: 0.9519 - recall_2: 0.6842 - precision_2: 0.7459 - auc_2: 0.8326\n",
            "Epoch 239: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4968 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9023 - specificity_at_sensitivity_2: 0.9519 - recall_2: 0.6842 - precision_2: 0.7459 - auc_2: 0.8326 - val_loss: 0.3853 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.7654 - val_precision_2: 0.9394 - val_auc_2: 0.9304\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4641 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.8971 - specificity_at_sensitivity_2: 0.9511 - recall_2: 0.7794 - precision_2: 0.7413 - auc_2: 0.8575\n",
            "Epoch 240: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4641 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.8971 - specificity_at_sensitivity_2: 0.9511 - recall_2: 0.7794 - precision_2: 0.7413 - auc_2: 0.8575 - val_loss: 0.4240 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9639 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8072 - val_precision_2: 0.7882 - val_auc_2: 0.8918\n",
            "Epoch 241/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4972 - accuracy: 0.7679 - sensitivity_at_specificity_2: 0.9339 - specificity_at_sensitivity_2: 0.9320 - recall_2: 0.7107 - precision_2: 0.8350 - auc_2: 0.8509\n",
            "Epoch 241: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5234 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.9068 - specificity_at_sensitivity_2: 0.8868 - recall_2: 0.7143 - precision_2: 0.7616 - auc_2: 0.8196 - val_loss: 0.4281 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9278 - val_specificity_at_sensitivity_2: 0.9683 - val_recall_2: 0.8351 - val_precision_2: 0.8617 - val_auc_2: 0.8873\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9341 - specificity_at_sensitivity_2: 0.9346 - recall_2: 0.8084 - precision_2: 0.7584 - auc_2: 0.8517\n",
            "Epoch 242: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4834 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9341 - specificity_at_sensitivity_2: 0.9346 - recall_2: 0.8084 - precision_2: 0.7584 - auc_2: 0.8517 - val_loss: 0.4237 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9250 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7750 - val_precision_2: 0.8267 - val_auc_2: 0.8938\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4807 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9213 - specificity_at_sensitivity_2: 0.9326 - recall_2: 0.5906 - precision_2: 0.7653 - auc_2: 0.8469\n",
            "Epoch 243: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4807 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9213 - specificity_at_sensitivity_2: 0.9326 - recall_2: 0.5906 - precision_2: 0.7653 - auc_2: 0.8469 - val_loss: 0.3858 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9639 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8193 - val_precision_2: 0.8395 - val_auc_2: 0.9187\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.9718 - recall_2: 0.8601 - precision_2: 0.7410 - auc_2: 0.8794\n",
            "Epoch 244: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4515 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.9718 - recall_2: 0.8601 - precision_2: 0.7410 - auc_2: 0.8794 - val_loss: 0.4296 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9620 - val_specificity_at_sensitivity_2: 0.9630 - val_recall_2: 0.7722 - val_precision_2: 0.8133 - val_auc_2: 0.8896\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.9539 - specificity_at_sensitivity_2: 0.9405 - recall_2: 0.6711 - precision_2: 0.7846 - auc_2: 0.8594\n",
            "Epoch 245: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4738 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.9539 - specificity_at_sensitivity_2: 0.9405 - recall_2: 0.6711 - precision_2: 0.7846 - auc_2: 0.8594 - val_loss: 0.4347 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9318 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7841 - val_precision_2: 0.8313 - val_auc_2: 0.8864\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5465 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8701 - specificity_at_sensitivity_2: 0.9277 - recall_2: 0.7338 - precision_2: 0.7063 - auc_2: 0.8050\n",
            "Epoch 246: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.5465 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8701 - specificity_at_sensitivity_2: 0.9277 - recall_2: 0.7338 - precision_2: 0.7063 - auc_2: 0.8050 - val_loss: 0.4424 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9425 - val_specificity_at_sensitivity_2: 0.9452 - val_recall_2: 0.7931 - val_precision_2: 0.8313 - val_auc_2: 0.8891\n",
            "Epoch 247/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4312 - accuracy: 0.8477 - sensitivity_at_specificity_2: 0.9369 - specificity_at_sensitivity_2: 0.9586 - recall_2: 0.7838 - precision_2: 0.8529 - auc_2: 0.8927\n",
            "Epoch 247: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4327 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9348 - specificity_at_sensitivity_2: 0.9670 - recall_2: 0.7826 - precision_2: 0.8372 - auc_2: 0.8898 - val_loss: 0.4435 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9398 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7108 - val_precision_2: 0.8429 - val_auc_2: 0.8896\n",
            "Epoch 248/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4498 - accuracy: 0.7634 - sensitivity_at_specificity_2: 0.9434 - specificity_at_sensitivity_2: 0.9576 - recall_2: 0.6604 - precision_2: 0.8046 - auc_2: 0.8772\n",
            "Epoch 248: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4767 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9306 - specificity_at_sensitivity_2: 0.9261 - recall_2: 0.6944 - precision_2: 0.7407 - auc_2: 0.8511 - val_loss: 0.4381 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9390 - val_specificity_at_sensitivity_2: 0.9744 - val_recall_2: 0.8171 - val_precision_2: 0.7976 - val_auc_2: 0.8824\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4755 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9116 - specificity_at_sensitivity_2: 0.9364 - recall_2: 0.7551 - precision_2: 0.7762 - auc_2: 0.8546\n",
            "Epoch 249: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4755 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9116 - specificity_at_sensitivity_2: 0.9364 - recall_2: 0.7551 - precision_2: 0.7762 - auc_2: 0.8546 - val_loss: 0.4805 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.8732 - val_specificity_at_sensitivity_2: 0.9663 - val_recall_2: 0.6901 - val_precision_2: 0.8448 - val_auc_2: 0.8421\n",
            "Epoch 250/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4737 - accuracy: 0.7857 - sensitivity_at_specificity_2: 0.9126 - specificity_at_sensitivity_2: 0.9587 - recall_2: 0.6602 - precision_2: 0.8395 - auc_2: 0.8584\n",
            "Epoch 250: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4669 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9172 - specificity_at_sensitivity_2: 0.9714 - recall_2: 0.7172 - precision_2: 0.7879 - auc_2: 0.8581 - val_loss: 0.4693 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9286 - val_specificity_at_sensitivity_2: 0.9474 - val_recall_2: 0.8571 - val_precision_2: 0.7423 - val_auc_2: 0.8658\n",
            "Epoch 251/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5248 - accuracy: 0.7422 - sensitivity_at_specificity_2: 0.8899 - specificity_at_sensitivity_2: 0.8776 - recall_2: 0.6972 - precision_2: 0.6972 - auc_2: 0.8082\n",
            "Epoch 251: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5054 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.8966 - specificity_at_sensitivity_2: 0.9029 - recall_2: 0.7034 - precision_2: 0.7445 - auc_2: 0.8302 - val_loss: 0.3967 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9474 - val_specificity_at_sensitivity_2: 0.9881 - val_recall_2: 0.7500 - val_precision_2: 0.9344 - val_auc_2: 0.9214\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9041 - specificity_at_sensitivity_2: 0.9598 - recall_2: 0.8014 - precision_2: 0.7178 - auc_2: 0.8556\n",
            "Epoch 252: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4799 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9041 - specificity_at_sensitivity_2: 0.9598 - recall_2: 0.8014 - precision_2: 0.7178 - auc_2: 0.8556 - val_loss: 0.3721 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9848 - val_specificity_at_sensitivity_2: 0.9894 - val_recall_2: 0.8333 - val_precision_2: 0.7857 - val_auc_2: 0.9259\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9231 - specificity_at_sensitivity_2: 0.9548 - recall_2: 0.6853 - precision_2: 0.7903 - auc_2: 0.8619\n",
            "Epoch 253: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4639 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9231 - specificity_at_sensitivity_2: 0.9548 - recall_2: 0.6853 - precision_2: 0.7903 - auc_2: 0.8619 - val_loss: 0.4857 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.8974 - val_specificity_at_sensitivity_2: 0.9390 - val_recall_2: 0.7436 - val_precision_2: 0.7945 - val_auc_2: 0.8457\n",
            "Epoch 254/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4699 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.8750 - specificity_at_sensitivity_2: 0.9671 - recall_2: 0.6923 - precision_2: 0.7500 - auc_2: 0.8458\n",
            "Epoch 254: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4722 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.8889 - specificity_at_sensitivity_2: 0.9514 - recall_2: 0.6815 - precision_2: 0.7667 - auc_2: 0.8485 - val_loss: 0.4036 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9545 - val_specificity_at_sensitivity_2: 0.9583 - val_recall_2: 0.8523 - val_precision_2: 0.8333 - val_auc_2: 0.8985\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.7862 - sensitivity_at_specificity_2: 0.9237 - specificity_at_sensitivity_2: 0.9686 - recall_2: 0.8015 - precision_2: 0.7447 - auc_2: 0.8675\n",
            "Epoch 255: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4604 - accuracy: 0.7862 - sensitivity_at_specificity_2: 0.9237 - specificity_at_sensitivity_2: 0.9686 - recall_2: 0.8015 - precision_2: 0.7447 - auc_2: 0.8675 - val_loss: 0.4343 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9242 - val_specificity_at_sensitivity_2: 0.9787 - val_recall_2: 0.7121 - val_precision_2: 0.8393 - val_auc_2: 0.8815\n",
            "Epoch 256/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4707 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9515 - specificity_at_sensitivity_2: 0.9421 - recall_2: 0.6505 - precision_2: 0.8375 - auc_2: 0.8643\n",
            "Epoch 256: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4471 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9404 - specificity_at_sensitivity_2: 0.9704 - recall_2: 0.7219 - precision_2: 0.8450 - auc_2: 0.8752 - val_loss: 0.4910 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9383 - val_specificity_at_sensitivity_2: 0.9367 - val_recall_2: 0.7901 - val_precision_2: 0.7442 - val_auc_2: 0.8444\n",
            "Epoch 257/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4808 - accuracy: 0.7773 - sensitivity_at_specificity_2: 0.9076 - specificity_at_sensitivity_2: 0.9635 - recall_2: 0.7395 - precision_2: 0.7719 - auc_2: 0.8511\n",
            "Epoch 257: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4906 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9007 - specificity_at_sensitivity_2: 0.9645 - recall_2: 0.7219 - precision_2: 0.7786 - auc_2: 0.8439 - val_loss: 0.4324 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9747 - val_specificity_at_sensitivity_2: 0.9630 - val_recall_2: 0.8228 - val_precision_2: 0.7738 - val_auc_2: 0.8855\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4814 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9200 - specificity_at_sensitivity_2: 0.9059 - recall_2: 0.8267 - precision_2: 0.7251 - auc_2: 0.8515\n",
            "Epoch 258: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4814 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9200 - specificity_at_sensitivity_2: 0.9059 - recall_2: 0.8267 - precision_2: 0.7251 - auc_2: 0.8515 - val_loss: 0.4296 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9595 - val_specificity_at_sensitivity_2: 0.9651 - val_recall_2: 0.7027 - val_precision_2: 0.8387 - val_auc_2: 0.8909\n",
            "Epoch 259/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4705 - accuracy: 0.8242 - sensitivity_at_specificity_2: 0.8654 - specificity_at_sensitivity_2: 0.9671 - recall_2: 0.6731 - precision_2: 0.8642 - auc_2: 0.8459\n",
            "Epoch 259: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4721 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.8824 - specificity_at_sensitivity_2: 0.9620 - recall_2: 0.6838 - precision_2: 0.8774 - auc_2: 0.8515 - val_loss: 0.4102 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9767 - val_specificity_at_sensitivity_2: 0.9595 - val_recall_2: 0.8256 - val_precision_2: 0.8256 - val_auc_2: 0.8962\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5039 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.9071 - specificity_at_sensitivity_2: 0.9278 - recall_2: 0.7286 - precision_2: 0.6892 - auc_2: 0.8333\n",
            "Epoch 260: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5039 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.9071 - specificity_at_sensitivity_2: 0.9278 - recall_2: 0.7286 - precision_2: 0.6892 - auc_2: 0.8333 - val_loss: 0.3592 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9605 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8684 - val_precision_2: 0.8462 - val_auc_2: 0.9356\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4725 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9141 - specificity_at_sensitivity_2: 0.9479 - recall_2: 0.6094 - precision_2: 0.7800 - auc_2: 0.8487\n",
            "Epoch 261: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4725 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9141 - specificity_at_sensitivity_2: 0.9479 - recall_2: 0.6094 - precision_2: 0.7800 - auc_2: 0.8487 - val_loss: 0.4048 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9726 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7534 - val_precision_2: 0.8462 - val_auc_2: 0.9164\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5063 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9184 - specificity_at_sensitivity_2: 0.9075 - recall_2: 0.8095 - precision_2: 0.7169 - auc_2: 0.8331\n",
            "Epoch 262: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5063 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9184 - specificity_at_sensitivity_2: 0.9075 - recall_2: 0.8095 - precision_2: 0.7169 - auc_2: 0.8331 - val_loss: 0.4276 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9759 - val_specificity_at_sensitivity_2: 0.9610 - val_recall_2: 0.8313 - val_precision_2: 0.7667 - val_auc_2: 0.8916\n",
            "Epoch 263/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4467 - accuracy: 0.7891 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9462 - recall_2: 0.7778 - precision_2: 0.7903 - auc_2: 0.8764\n",
            "Epoch 263: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4688 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9103 - specificity_at_sensitivity_2: 0.9451 - recall_2: 0.7500 - precision_2: 0.7905 - auc_2: 0.8603 - val_loss: 0.4362 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9211 - val_specificity_at_sensitivity_2: 0.9762 - val_recall_2: 0.7895 - val_precision_2: 0.8108 - val_auc_2: 0.8817\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4614 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9098 - specificity_at_sensitivity_2: 0.9358 - recall_2: 0.8271 - precision_2: 0.7534 - auc_2: 0.8610\n",
            "Epoch 264: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4614 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9098 - specificity_at_sensitivity_2: 0.9358 - recall_2: 0.8271 - precision_2: 0.7534 - auc_2: 0.8610 - val_loss: 0.4282 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9667 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7333 - val_precision_2: 0.9167 - val_auc_2: 0.9161\n",
            "Epoch 265/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4376 - accuracy: 0.7991 - sensitivity_at_specificity_2: 0.9592 - specificity_at_sensitivity_2: 0.9762 - recall_2: 0.7143 - precision_2: 0.8046 - auc_2: 0.8852\n",
            "Epoch 265: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4497 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9589 - specificity_at_sensitivity_2: 0.9598 - recall_2: 0.7329 - precision_2: 0.8231 - auc_2: 0.8810 - val_loss: 0.4416 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9155 - val_specificity_at_sensitivity_2: 0.9663 - val_recall_2: 0.7183 - val_precision_2: 0.8793 - val_auc_2: 0.8759\n",
            "Epoch 266/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5107 - accuracy: 0.7539 - sensitivity_at_specificity_2: 0.8981 - specificity_at_sensitivity_2: 0.9054 - recall_2: 0.7685 - precision_2: 0.6860 - auc_2: 0.8285\n",
            "Epoch 266: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4921 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9241 - specificity_at_sensitivity_2: 0.9200 - recall_2: 0.7655 - precision_2: 0.7255 - auc_2: 0.8433 - val_loss: 0.4637 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9200 - val_specificity_at_sensitivity_2: 0.9412 - val_recall_2: 0.7333 - val_precision_2: 0.7639 - val_auc_2: 0.8641\n",
            "Epoch 267/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4677 - accuracy: 0.7857 - sensitivity_at_specificity_2: 0.9451 - specificity_at_sensitivity_2: 0.8947 - recall_2: 0.7143 - precision_2: 0.7471 - auc_2: 0.8548\n",
            "Epoch 267: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4835 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9179 - specificity_at_sensitivity_2: 0.9194 - recall_2: 0.7090 - precision_2: 0.7422 - auc_2: 0.8429 - val_loss: 0.4651 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.8989 - val_specificity_at_sensitivity_2: 0.9859 - val_recall_2: 0.7640 - val_precision_2: 0.8831 - val_auc_2: 0.8721\n",
            "Epoch 268/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4871 - accuracy: 0.7852 - sensitivity_at_specificity_2: 0.9250 - specificity_at_sensitivity_2: 0.9632 - recall_2: 0.7417 - precision_2: 0.7876 - auc_2: 0.8470\n",
            "Epoch 268: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5015 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9060 - specificity_at_sensitivity_2: 0.9532 - recall_2: 0.7248 - precision_2: 0.7552 - auc_2: 0.8353 - val_loss: 0.4771 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9241 - val_specificity_at_sensitivity_2: 0.9506 - val_recall_2: 0.7468 - val_precision_2: 0.7662 - val_auc_2: 0.8538\n",
            "Epoch 269/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4748 - accuracy: 0.7946 - sensitivity_at_specificity_2: 0.9510 - specificity_at_sensitivity_2: 0.9098 - recall_2: 0.7353 - precision_2: 0.7979 - auc_2: 0.8543\n",
            "Epoch 269: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4746 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9571 - specificity_at_sensitivity_2: 0.9111 - recall_2: 0.6929 - precision_2: 0.7886 - auc_2: 0.8546 - val_loss: 0.4311 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9250 - val_specificity_at_sensitivity_2: 0.9875 - val_recall_2: 0.7500 - val_precision_2: 0.8955 - val_auc_2: 0.8916\n",
            "Epoch 270/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4143 - accuracy: 0.8320 - sensitivity_at_specificity_2: 0.9633 - specificity_at_sensitivity_2: 0.9796 - recall_2: 0.7706 - precision_2: 0.8235 - auc_2: 0.8969\n",
            "Epoch 270: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4173 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9574 - specificity_at_sensitivity_2: 0.9777 - recall_2: 0.7447 - precision_2: 0.8400 - auc_2: 0.8955 - val_loss: 0.3799 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9419 - val_specificity_at_sensitivity_2: 0.9865 - val_recall_2: 0.8488 - val_precision_2: 0.8588 - val_auc_2: 0.9175\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9200 - specificity_at_sensitivity_2: 0.9706 - recall_2: 0.7933 - precision_2: 0.7484 - auc_2: 0.8726\n",
            "Epoch 271: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4505 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9200 - specificity_at_sensitivity_2: 0.9706 - recall_2: 0.7933 - precision_2: 0.7484 - auc_2: 0.8726 - val_loss: 0.4083 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9342 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7500 - val_precision_2: 0.8769 - val_auc_2: 0.8985\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4469 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9110 - specificity_at_sensitivity_2: 0.9540 - recall_2: 0.7808 - precision_2: 0.7862 - auc_2: 0.8713\n",
            "Epoch 272: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4469 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9110 - specificity_at_sensitivity_2: 0.9540 - recall_2: 0.7808 - precision_2: 0.7862 - auc_2: 0.8713 - val_loss: 0.4440 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9412 - val_specificity_at_sensitivity_2: 0.9733 - val_recall_2: 0.8235 - val_precision_2: 0.8046 - val_auc_2: 0.8755\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9320 - specificity_at_sensitivity_2: 0.9595 - recall_2: 0.7755 - precision_2: 0.7917 - auc_2: 0.8721\n",
            "Epoch 273: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4449 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9320 - specificity_at_sensitivity_2: 0.9595 - recall_2: 0.7755 - precision_2: 0.7917 - auc_2: 0.8721 - val_loss: 0.4422 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.8961 - val_specificity_at_sensitivity_2: 0.9398 - val_recall_2: 0.7532 - val_precision_2: 0.8529 - val_auc_2: 0.8743\n",
            "Epoch 274/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4344 - accuracy: 0.8203 - sensitivity_at_specificity_2: 0.9402 - specificity_at_sensitivity_2: 0.9496 - recall_2: 0.7778 - precision_2: 0.8198 - auc_2: 0.8806\n",
            "Epoch 274: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4434 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9226 - specificity_at_sensitivity_2: 0.9576 - recall_2: 0.7613 - precision_2: 0.8369 - auc_2: 0.8772 - val_loss: 0.3845 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9481 - val_specificity_at_sensitivity_2: 0.9759 - val_recall_2: 0.8701 - val_precision_2: 0.7701 - val_auc_2: 0.9150\n",
            "Epoch 275/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4762 - accuracy: 0.7891 - sensitivity_at_specificity_2: 0.9211 - specificity_at_sensitivity_2: 0.9366 - recall_2: 0.8070 - precision_2: 0.7419 - auc_2: 0.8568\n",
            "Epoch 275: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4824 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9362 - specificity_at_sensitivity_2: 0.9218 - recall_2: 0.7943 - precision_2: 0.7417 - auc_2: 0.8524 - val_loss: 0.4936 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9333 - val_specificity_at_sensitivity_2: 0.9571 - val_recall_2: 0.6889 - val_precision_2: 0.9118 - val_auc_2: 0.8876\n",
            "Epoch 276/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5082 - accuracy: 0.7768 - sensitivity_at_specificity_2: 0.8922 - specificity_at_sensitivity_2: 0.9590 - recall_2: 0.6667 - precision_2: 0.8095 - auc_2: 0.8356\n",
            "Epoch 276: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4779 - accuracy: 0.7793 - sensitivity_at_specificity_2: 0.9000 - specificity_at_sensitivity_2: 0.9688 - recall_2: 0.6923 - precision_2: 0.7895 - auc_2: 0.8519 - val_loss: 0.3559 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9868 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8816 - val_precision_2: 0.8171 - val_auc_2: 0.9382\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4198 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9530 - specificity_at_sensitivity_2: 0.9825 - recall_2: 0.8054 - precision_2: 0.7792 - auc_2: 0.8969\n",
            "Epoch 277: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4198 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9530 - specificity_at_sensitivity_2: 0.9825 - recall_2: 0.8054 - precision_2: 0.7792 - auc_2: 0.8969 - val_loss: 0.3833 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 0.9756 - val_recall_2: 0.8205 - val_precision_2: 0.8649 - val_auc_2: 0.9145\n",
            "Epoch 278/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4512 - accuracy: 0.7930 - sensitivity_at_specificity_2: 0.9429 - specificity_at_sensitivity_2: 0.9404 - recall_2: 0.7048 - precision_2: 0.7708 - auc_2: 0.8622\n",
            "Epoch 278: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4293 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9466 - specificity_at_sensitivity_2: 0.9524 - recall_2: 0.7099 - precision_2: 0.8087 - auc_2: 0.8790 - val_loss: 0.4262 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9452 - val_specificity_at_sensitivity_2: 0.9540 - val_recall_2: 0.7534 - val_precision_2: 0.8730 - val_auc_2: 0.8868\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9549 - specificity_at_sensitivity_2: 0.9679 - recall_2: 0.8346 - precision_2: 0.7208 - auc_2: 0.8890\n",
            "Epoch 279: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4225 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9549 - specificity_at_sensitivity_2: 0.9679 - recall_2: 0.8346 - precision_2: 0.7208 - auc_2: 0.8890 - val_loss: 0.4194 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9315 - val_specificity_at_sensitivity_2: 0.9770 - val_recall_2: 0.7397 - val_precision_2: 0.8571 - val_auc_2: 0.8964\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9701 - specificity_at_sensitivity_2: 0.9731 - recall_2: 0.6791 - precision_2: 0.9100 - auc_2: 0.9133\n",
            "Epoch 280: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3952 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9701 - specificity_at_sensitivity_2: 0.9731 - recall_2: 0.6791 - precision_2: 0.9100 - auc_2: 0.9133 - val_loss: 0.4779 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.8795 - val_specificity_at_sensitivity_2: 0.9870 - val_recall_2: 0.7831 - val_precision_2: 0.7738 - val_auc_2: 0.8522\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4789 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9167 - specificity_at_sensitivity_2: 0.9521 - recall_2: 0.7652 - precision_2: 0.7063 - auc_2: 0.8519\n",
            "Epoch 281: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4789 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9167 - specificity_at_sensitivity_2: 0.9521 - recall_2: 0.7652 - precision_2: 0.7063 - auc_2: 0.8519 - val_loss: 0.4987 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9259 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.6173 - val_precision_2: 0.9434 - val_auc_2: 0.8812\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4769 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9565 - specificity_at_sensitivity_2: 0.9341 - recall_2: 0.6739 - precision_2: 0.7561 - auc_2: 0.8506\n",
            "Epoch 282: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4769 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9565 - specificity_at_sensitivity_2: 0.9341 - recall_2: 0.6739 - precision_2: 0.7561 - auc_2: 0.8506 - val_loss: 0.4588 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.8784 - val_specificity_at_sensitivity_2: 0.9767 - val_recall_2: 0.7568 - val_precision_2: 0.7671 - val_auc_2: 0.8586\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4197 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9507 - specificity_at_sensitivity_2: 0.9607 - recall_2: 0.7958 - precision_2: 0.7793 - auc_2: 0.8875\n",
            "Epoch 283: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4197 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9507 - specificity_at_sensitivity_2: 0.9607 - recall_2: 0.7958 - precision_2: 0.7793 - auc_2: 0.8875 - val_loss: 0.4402 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9277 - val_specificity_at_sensitivity_2: 0.9610 - val_recall_2: 0.7711 - val_precision_2: 0.8421 - val_auc_2: 0.8826\n",
            "Epoch 284/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4402 - accuracy: 0.7902 - sensitivity_at_specificity_2: 0.9231 - specificity_at_sensitivity_2: 0.9624 - recall_2: 0.6923 - precision_2: 0.7683 - auc_2: 0.8684\n",
            "Epoch 284: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4206 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9453 - specificity_at_sensitivity_2: 0.9740 - recall_2: 0.6953 - precision_2: 0.7946 - auc_2: 0.8815 - val_loss: 0.5085 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9000 - val_specificity_at_sensitivity_2: 0.9500 - val_recall_2: 0.6875 - val_precision_2: 0.8333 - val_auc_2: 0.8480\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9602 - recall_2: 0.7847 - precision_2: 0.7635 - auc_2: 0.8688\n",
            "Epoch 285: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4518 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9602 - recall_2: 0.7847 - precision_2: 0.7635 - auc_2: 0.8688 - val_loss: 0.3837 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9737 - val_specificity_at_sensitivity_2: 0.9762 - val_recall_2: 0.7895 - val_precision_2: 0.8108 - val_auc_2: 0.9147\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4767 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9434 - specificity_at_sensitivity_2: 0.9565 - recall_2: 0.7484 - precision_2: 0.7677 - auc_2: 0.8543\n",
            "Epoch 286: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4767 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9434 - specificity_at_sensitivity_2: 0.9565 - recall_2: 0.7484 - precision_2: 0.7677 - auc_2: 0.8543 - val_loss: 0.5065 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.8854 - val_specificity_at_sensitivity_2: 0.9844 - val_recall_2: 0.7708 - val_precision_2: 0.7957 - val_auc_2: 0.8474\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9392 - specificity_at_sensitivity_2: 0.9651 - recall_2: 0.7905 - precision_2: 0.7597 - auc_2: 0.8773\n",
            "Epoch 287: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4419 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9392 - specificity_at_sensitivity_2: 0.9651 - recall_2: 0.7905 - precision_2: 0.7597 - auc_2: 0.8773 - val_loss: 0.4825 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.8831 - val_specificity_at_sensitivity_2: 0.9639 - val_recall_2: 0.6753 - val_precision_2: 0.8000 - val_auc_2: 0.8524\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4852 - accuracy: 0.7828 - sensitivity_at_specificity_2: 0.9113 - specificity_at_sensitivity_2: 0.9458 - recall_2: 0.6694 - precision_2: 0.7905 - auc_2: 0.8430\n",
            "Epoch 288: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4852 - accuracy: 0.7828 - sensitivity_at_specificity_2: 0.9113 - specificity_at_sensitivity_2: 0.9458 - recall_2: 0.6694 - precision_2: 0.7905 - auc_2: 0.8430 - val_loss: 0.3643 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9740 - val_specificity_at_sensitivity_2: 0.9759 - val_recall_2: 0.8442 - val_precision_2: 0.8553 - val_auc_2: 0.9295\n",
            "Epoch 289/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5053 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8972 - specificity_at_sensitivity_2: 0.9573 - recall_2: 0.7383 - precision_2: 0.7383 - auc_2: 0.8338\n",
            "Epoch 289: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5173 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8968 - specificity_at_sensitivity_2: 0.9455 - recall_2: 0.7419 - precision_2: 0.7325 - auc_2: 0.8271 - val_loss: 0.4641 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9059 - val_specificity_at_sensitivity_2: 0.9733 - val_recall_2: 0.7294 - val_precision_2: 0.8378 - val_auc_2: 0.8696\n",
            "Epoch 290/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5180 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8830 - specificity_at_sensitivity_2: 0.9077 - recall_2: 0.6809 - precision_2: 0.7111 - auc_2: 0.8106\n",
            "Epoch 290: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4991 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.8881 - specificity_at_sensitivity_2: 0.9409 - recall_2: 0.7015 - precision_2: 0.7287 - auc_2: 0.8272 - val_loss: 0.4906 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.8916 - val_specificity_at_sensitivity_2: 0.9740 - val_recall_2: 0.7470 - val_precision_2: 0.8732 - val_auc_2: 0.8602\n",
            "Epoch 291/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4480 - accuracy: 0.7986 - sensitivity_at_specificity_2: 0.9429 - specificity_at_sensitivity_2: 0.9459 - recall_2: 0.7571 - precision_2: 0.8154 - auc_2: 0.8799\n",
            "Epoch 291: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4632 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9272 - specificity_at_sensitivity_2: 0.9290 - recall_2: 0.7483 - precision_2: 0.7958 - auc_2: 0.8664 - val_loss: 0.4143 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.8590 - val_precision_2: 0.7701 - val_auc_2: 0.9015\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4588 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9104 - specificity_at_sensitivity_2: 0.9624 - recall_2: 0.6940 - precision_2: 0.7323 - auc_2: 0.8575\n",
            "Epoch 292: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4588 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9104 - specificity_at_sensitivity_2: 0.9624 - recall_2: 0.6940 - precision_2: 0.7323 - auc_2: 0.8575 - val_loss: 0.4319 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9571 - val_specificity_at_sensitivity_2: 0.9556 - val_recall_2: 0.8000 - val_precision_2: 0.7887 - val_auc_2: 0.8839\n",
            "Epoch 293/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4738 - accuracy: 0.7679 - sensitivity_at_specificity_2: 0.9252 - specificity_at_sensitivity_2: 0.9573 - recall_2: 0.6822 - precision_2: 0.8022 - auc_2: 0.8551\n",
            "Epoch 293: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4645 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9054 - specificity_at_sensitivity_2: 0.9709 - recall_2: 0.6959 - precision_2: 0.7744 - auc_2: 0.8565 - val_loss: 0.4012 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 0.9877 - val_recall_2: 0.8101 - val_precision_2: 0.8421 - val_auc_2: 0.9093\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5110 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9026 - specificity_at_sensitivity_2: 0.9157 - recall_2: 0.6623 - precision_2: 0.8160 - auc_2: 0.8323\n",
            "Epoch 294: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5110 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9026 - specificity_at_sensitivity_2: 0.9157 - recall_2: 0.6623 - precision_2: 0.8160 - auc_2: 0.8323 - val_loss: 0.4300 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 0.9605 - val_recall_2: 0.7857 - val_precision_2: 0.8148 - val_auc_2: 0.8855\n",
            "Epoch 295/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4792 - accuracy: 0.7773 - sensitivity_at_specificity_2: 0.9153 - specificity_at_sensitivity_2: 0.9638 - recall_2: 0.8136 - precision_2: 0.7328 - auc_2: 0.8595\n",
            "Epoch 295: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4607 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9659 - recall_2: 0.8194 - precision_2: 0.7421 - auc_2: 0.8704 - val_loss: 0.4392 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.8784 - val_specificity_at_sensitivity_2: 0.9767 - val_recall_2: 0.7297 - val_precision_2: 0.8571 - val_auc_2: 0.8788\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9286 - specificity_at_sensitivity_2: 0.9611 - recall_2: 0.6286 - precision_2: 0.8381 - auc_2: 0.8661\n",
            "Epoch 296: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4551 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9286 - specificity_at_sensitivity_2: 0.9611 - recall_2: 0.6286 - precision_2: 0.8381 - auc_2: 0.8661 - val_loss: 0.3733 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9516 - val_specificity_at_sensitivity_2: 0.9898 - val_recall_2: 0.7258 - val_precision_2: 0.9000 - val_auc_2: 0.9064\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9704 - specificity_at_sensitivity_2: 0.9514 - recall_2: 0.7778 - precision_2: 0.7721 - auc_2: 0.8807\n",
            "Epoch 297: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4321 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9704 - specificity_at_sensitivity_2: 0.9514 - recall_2: 0.7778 - precision_2: 0.7721 - auc_2: 0.8807 - val_loss: 0.4182 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9012 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.8148 - val_precision_2: 0.8354 - val_auc_2: 0.8895\n",
            "Epoch 298/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4063 - accuracy: 0.8080 - sensitivity_at_specificity_2: 0.9479 - specificity_at_sensitivity_2: 0.9844 - recall_2: 0.7188 - precision_2: 0.8118 - auc_2: 0.8927\n",
            "Epoch 298: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4206 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9407 - specificity_at_sensitivity_2: 0.9892 - recall_2: 0.7259 - precision_2: 0.7717 - auc_2: 0.8825 - val_loss: 0.4440 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9114 - val_specificity_at_sensitivity_2: 0.9753 - val_recall_2: 0.7215 - val_precision_2: 0.8382 - val_auc_2: 0.8744\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.8790 - specificity_at_sensitivity_2: 0.9509 - recall_2: 0.7134 - precision_2: 0.7943 - auc_2: 0.8372\n",
            "Epoch 299: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5001 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.8790 - specificity_at_sensitivity_2: 0.9509 - recall_2: 0.7134 - precision_2: 0.7943 - auc_2: 0.8372 - val_loss: 0.4190 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9259 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8395 - val_precision_2: 0.7727 - val_auc_2: 0.8937\n",
            "Epoch 300/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4436 - accuracy: 0.7891 - sensitivity_at_specificity_2: 0.9434 - specificity_at_sensitivity_2: 0.9533 - recall_2: 0.7547 - precision_2: 0.7407 - auc_2: 0.8742\n",
            "Epoch 300: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4381 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9500 - specificity_at_sensitivity_2: 0.9500 - recall_2: 0.7429 - precision_2: 0.7761 - auc_2: 0.8787 - val_loss: 0.3989 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9342 - val_specificity_at_sensitivity_2: 0.9881 - val_recall_2: 0.7500 - val_precision_2: 0.8507 - val_auc_2: 0.9021\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9071 - specificity_at_sensitivity_2: 0.9500 - recall_2: 0.7429 - precision_2: 0.8189 - auc_2: 0.8585\n",
            "Epoch 301: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4605 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9071 - specificity_at_sensitivity_2: 0.9500 - recall_2: 0.7429 - precision_2: 0.8189 - auc_2: 0.8585 - val_loss: 0.3381 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9733 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7733 - val_precision_2: 0.8788 - val_auc_2: 0.9429\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9690 - specificity_at_sensitivity_2: 0.9738 - recall_2: 0.8140 - precision_2: 0.7554 - auc_2: 0.8937\n",
            "Epoch 302: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4086 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9690 - specificity_at_sensitivity_2: 0.9738 - recall_2: 0.8140 - precision_2: 0.7554 - auc_2: 0.8937 - val_loss: 0.4344 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9155 - val_specificity_at_sensitivity_2: 0.9888 - val_recall_2: 0.7042 - val_precision_2: 0.8929 - val_auc_2: 0.8778\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9119 - specificity_at_sensitivity_2: 0.9441 - recall_2: 0.7799 - precision_2: 0.8212 - auc_2: 0.8672\n",
            "Epoch 303: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4568 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9119 - specificity_at_sensitivity_2: 0.9441 - recall_2: 0.7799 - precision_2: 0.8212 - auc_2: 0.8672 - val_loss: 0.4514 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9383 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.8519 - val_precision_2: 0.7188 - val_auc_2: 0.8894\n",
            "Epoch 304/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5152 - accuracy: 0.7569 - sensitivity_at_specificity_2: 0.8897 - specificity_at_sensitivity_2: 0.9441 - recall_2: 0.7586 - precision_2: 0.7586 - auc_2: 0.8275\n",
            "Epoch 304: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.5217 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.8957 - specificity_at_sensitivity_2: 0.9363 - recall_2: 0.7239 - precision_2: 0.7662 - auc_2: 0.8222 - val_loss: 0.4153 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9487 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.7564 - val_precision_2: 0.9077 - val_auc_2: 0.9058\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9244 - specificity_at_sensitivity_2: 0.9453 - recall_2: 0.6975 - precision_2: 0.7545 - auc_2: 0.8530\n",
            "Epoch 305: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4562 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9244 - specificity_at_sensitivity_2: 0.9453 - recall_2: 0.6975 - precision_2: 0.7545 - auc_2: 0.8530 - val_loss: 0.4219 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.6667 - val_precision_2: 0.9811 - val_auc_2: 0.9221\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9494 - recall_2: 0.7963 - precision_2: 0.8113 - auc_2: 0.8812\n",
            "Epoch 306: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4398 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9494 - recall_2: 0.7963 - precision_2: 0.8113 - auc_2: 0.8812 - val_loss: 0.4709 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.8941 - val_specificity_at_sensitivity_2: 0.9733 - val_recall_2: 0.7647 - val_precision_2: 0.8025 - val_auc_2: 0.8656\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4793 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9338 - specificity_at_sensitivity_2: 0.9408 - recall_2: 0.7285 - precision_2: 0.7432 - auc_2: 0.8524\n",
            "Epoch 307: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4793 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9338 - specificity_at_sensitivity_2: 0.9408 - recall_2: 0.7285 - precision_2: 0.7432 - auc_2: 0.8524 - val_loss: 0.4322 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9722 - val_specificity_at_sensitivity_2: 0.9545 - val_recall_2: 0.7361 - val_precision_2: 0.8548 - val_auc_2: 0.8837\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4734 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.8944 - specificity_at_sensitivity_2: 0.9551 - recall_2: 0.7606 - precision_2: 0.7552 - auc_2: 0.8525\n",
            "Epoch 308: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.4734 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.8944 - specificity_at_sensitivity_2: 0.9551 - recall_2: 0.7606 - precision_2: 0.7552 - auc_2: 0.8525 - val_loss: 0.4581 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9241 - val_specificity_at_sensitivity_2: 0.9506 - val_recall_2: 0.7468 - val_precision_2: 0.8310 - val_auc_2: 0.8699\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4117 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9448 - specificity_at_sensitivity_2: 0.9600 - recall_2: 0.7793 - precision_2: 0.7902 - auc_2: 0.8951\n",
            "Epoch 309: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4117 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9448 - specificity_at_sensitivity_2: 0.9600 - recall_2: 0.7793 - precision_2: 0.7902 - auc_2: 0.8951 - val_loss: 0.3354 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9722 - val_specificity_at_sensitivity_2: 0.9886 - val_recall_2: 0.8472 - val_precision_2: 0.8356 - val_auc_2: 0.9436\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9632 - specificity_at_sensitivity_2: 0.9565 - recall_2: 0.7206 - precision_2: 0.7840 - auc_2: 0.8875\n",
            "Epoch 310: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.4229 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9632 - specificity_at_sensitivity_2: 0.9565 - recall_2: 0.7206 - precision_2: 0.7840 - auc_2: 0.8875 - val_loss: 0.3962 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9730 - val_specificity_at_sensitivity_2: 0.9767 - val_recall_2: 0.7973 - val_precision_2: 0.7662 - val_auc_2: 0.9035\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4046 - accuracy: 0.8310 - sensitivity_at_specificity_2: 0.9489 - specificity_at_sensitivity_2: 0.9673 - recall_2: 0.8248 - precision_2: 0.8188 - auc_2: 0.8975\n",
            "Epoch 311: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4046 - accuracy: 0.8310 - sensitivity_at_specificity_2: 0.9489 - specificity_at_sensitivity_2: 0.9673 - recall_2: 0.8248 - precision_2: 0.8188 - auc_2: 0.8975 - val_loss: 0.4021 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9474 - val_specificity_at_sensitivity_2: 0.9881 - val_recall_2: 0.7368 - val_precision_2: 0.8358 - val_auc_2: 0.8965\n",
            "Epoch 312/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4924 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.8889 - specificity_at_sensitivity_2: 0.9231 - recall_2: 0.7857 - precision_2: 0.7984 - auc_2: 0.8491\n",
            "Epoch 312: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4653 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9013 - specificity_at_sensitivity_2: 0.9405 - recall_2: 0.7895 - precision_2: 0.8163 - auc_2: 0.8624 - val_loss: 0.3850 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9459 - val_specificity_at_sensitivity_2: 0.9884 - val_recall_2: 0.7568 - val_precision_2: 0.9180 - val_auc_2: 0.9117\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4382 - accuracy: 0.8138 - sensitivity_at_specificity_2: 0.9180 - specificity_at_sensitivity_2: 0.9643 - recall_2: 0.7049 - precision_2: 0.8269 - auc_2: 0.8682\n",
            "Epoch 313: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4382 - accuracy: 0.8138 - sensitivity_at_specificity_2: 0.9180 - specificity_at_sensitivity_2: 0.9643 - recall_2: 0.7049 - precision_2: 0.8269 - auc_2: 0.8682 - val_loss: 0.4616 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.8953 - val_specificity_at_sensitivity_2: 0.9730 - val_recall_2: 0.7907 - val_precision_2: 0.8193 - val_auc_2: 0.8641\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4187 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9716 - specificity_at_sensitivity_2: 0.9553 - recall_2: 0.7943 - precision_2: 0.7778 - auc_2: 0.8923\n",
            "Epoch 314: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4187 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9716 - specificity_at_sensitivity_2: 0.9553 - recall_2: 0.7943 - precision_2: 0.7778 - auc_2: 0.8923 - val_loss: 0.4496 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9663 - val_specificity_at_sensitivity_2: 0.9859 - val_recall_2: 0.7416 - val_precision_2: 0.8919 - val_auc_2: 0.8981\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9568 - specificity_at_sensitivity_2: 0.9557 - recall_2: 0.7840 - precision_2: 0.8089 - auc_2: 0.8893\n",
            "Epoch 315: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4210 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9568 - specificity_at_sensitivity_2: 0.9557 - recall_2: 0.7840 - precision_2: 0.8089 - auc_2: 0.8893 - val_loss: 0.4589 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9186 - val_specificity_at_sensitivity_2: 0.9865 - val_recall_2: 0.8372 - val_precision_2: 0.7579 - val_auc_2: 0.8784\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9638 - specificity_at_sensitivity_2: 0.9835 - recall_2: 0.7536 - precision_2: 0.8000 - auc_2: 0.9020\n",
            "Epoch 316: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.3927 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9638 - specificity_at_sensitivity_2: 0.9835 - recall_2: 0.7536 - precision_2: 0.8000 - auc_2: 0.9020 - val_loss: 0.3501 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9859 - val_specificity_at_sensitivity_2: 0.9775 - val_recall_2: 0.8592 - val_precision_2: 0.7922 - val_auc_2: 0.9346\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4379 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9592 - specificity_at_sensitivity_2: 0.9422 - recall_2: 0.8231 - precision_2: 0.7707 - auc_2: 0.8824\n",
            "Epoch 317: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4379 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9592 - specificity_at_sensitivity_2: 0.9422 - recall_2: 0.8231 - precision_2: 0.7707 - auc_2: 0.8824 - val_loss: 0.4958 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.8209 - val_specificity_at_sensitivity_2: 0.9892 - val_recall_2: 0.6866 - val_precision_2: 0.7188 - val_auc_2: 0.8271\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4485 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9366 - specificity_at_sensitivity_2: 0.9663 - recall_2: 0.7183 - precision_2: 0.7612 - auc_2: 0.8701\n",
            "Epoch 318: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4485 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9366 - specificity_at_sensitivity_2: 0.9663 - recall_2: 0.7183 - precision_2: 0.7612 - auc_2: 0.8701 - val_loss: 0.4524 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9101 - val_specificity_at_sensitivity_2: 0.9859 - val_recall_2: 0.7528 - val_precision_2: 0.9306 - val_auc_2: 0.8843\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4215 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9589 - specificity_at_sensitivity_2: 0.9885 - recall_2: 0.8425 - precision_2: 0.7235 - auc_2: 0.8977\n",
            "Epoch 319: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4215 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9589 - specificity_at_sensitivity_2: 0.9885 - recall_2: 0.8425 - precision_2: 0.7235 - auc_2: 0.8977 - val_loss: 0.3714 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 0.9877 - val_recall_2: 0.7089 - val_precision_2: 0.9492 - val_auc_2: 0.9415\n",
            "Epoch 320/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4927 - accuracy: 0.7708 - sensitivity_at_specificity_2: 0.9113 - specificity_at_sensitivity_2: 0.9634 - recall_2: 0.5484 - precision_2: 0.8718 - auc_2: 0.8551\n",
            "Epoch 320: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4773 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9160 - specificity_at_sensitivity_2: 0.9418 - recall_2: 0.5725 - precision_2: 0.8333 - auc_2: 0.8528 - val_loss: 0.4773 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9701 - val_specificity_at_sensitivity_2: 0.9892 - val_recall_2: 0.9254 - val_precision_2: 0.6458 - val_auc_2: 0.8875\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4907 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9114 - specificity_at_sensitivity_2: 0.9383 - recall_2: 0.8165 - precision_2: 0.7127 - auc_2: 0.8462\n",
            "Epoch 321: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4907 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9114 - specificity_at_sensitivity_2: 0.9383 - recall_2: 0.8165 - precision_2: 0.7127 - auc_2: 0.8462 - val_loss: 0.4486 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.8875 - val_specificity_at_sensitivity_2: 0.9875 - val_recall_2: 0.8000 - val_precision_2: 0.8767 - val_auc_2: 0.8747\n",
            "Epoch 322/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4451 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.8969 - specificity_at_sensitivity_2: 0.9685 - recall_2: 0.6907 - precision_2: 0.8481 - auc_2: 0.8714\n",
            "Epoch 322: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4356 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9191 - specificity_at_sensitivity_2: 0.9783 - recall_2: 0.6912 - precision_2: 0.8319 - auc_2: 0.8775 - val_loss: 0.3959 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 1.0000 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.7821 - val_precision_2: 0.8356 - val_auc_2: 0.9172\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9310 - specificity_at_sensitivity_2: 0.9486 - recall_2: 0.7793 - precision_2: 0.8071 - auc_2: 0.8765\n",
            "Epoch 323: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4418 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9310 - specificity_at_sensitivity_2: 0.9486 - recall_2: 0.7793 - precision_2: 0.8071 - auc_2: 0.8765 - val_loss: 0.4660 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9250 - val_specificity_at_sensitivity_2: 0.9750 - val_recall_2: 0.7125 - val_precision_2: 0.8769 - val_auc_2: 0.8721\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.8906 - specificity_at_sensitivity_2: 0.9531 - recall_2: 0.7422 - precision_2: 0.7983 - auc_2: 0.8601\n",
            "Epoch 324: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4452 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.8906 - specificity_at_sensitivity_2: 0.9531 - recall_2: 0.7422 - precision_2: 0.7983 - auc_2: 0.8601 - val_loss: 0.4715 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.8806 - val_specificity_at_sensitivity_2: 0.9677 - val_recall_2: 0.7015 - val_precision_2: 0.7705 - val_auc_2: 0.8441\n",
            "Epoch 325/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4487 - accuracy: 0.8164 - sensitivity_at_specificity_2: 0.9040 - specificity_at_sensitivity_2: 0.9771 - recall_2: 0.7520 - precision_2: 0.8545 - auc_2: 0.8711\n",
            "Epoch 325: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4276 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9221 - specificity_at_sensitivity_2: 0.9759 - recall_2: 0.7597 - precision_2: 0.8540 - auc_2: 0.8849 - val_loss: 0.4132 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9565 - val_specificity_at_sensitivity_2: 0.9780 - val_recall_2: 0.8551 - val_precision_2: 0.7284 - val_auc_2: 0.9031\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9141 - specificity_at_sensitivity_2: 0.9583 - recall_2: 0.7109 - precision_2: 0.7583 - auc_2: 0.8616\n",
            "Epoch 326: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4495 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9141 - specificity_at_sensitivity_2: 0.9583 - recall_2: 0.7109 - precision_2: 0.7583 - auc_2: 0.8616 - val_loss: 0.4757 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.8947 - val_specificity_at_sensitivity_2: 0.9762 - val_recall_2: 0.6842 - val_precision_2: 0.8000 - val_auc_2: 0.8542\n",
            "Epoch 327/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4235 - accuracy: 0.8359 - sensitivity_at_specificity_2: 0.9355 - specificity_at_sensitivity_2: 0.9621 - recall_2: 0.8387 - precision_2: 0.8254 - auc_2: 0.8880\n",
            "Epoch 327: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4313 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9430 - specificity_at_sensitivity_2: 0.9568 - recall_2: 0.8354 - precision_2: 0.8098 - auc_2: 0.8849 - val_loss: 0.4407 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.8974 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.8077 - val_precision_2: 0.7875 - val_auc_2: 0.8830\n",
            "Epoch 328/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4940 - accuracy: 0.7734 - sensitivity_at_specificity_2: 0.9231 - specificity_at_sensitivity_2: 0.9496 - recall_2: 0.7179 - precision_2: 0.7706 - auc_2: 0.8418\n",
            "Epoch 328: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4804 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9320 - specificity_at_sensitivity_2: 0.9480 - recall_2: 0.7415 - precision_2: 0.7676 - auc_2: 0.8519 - val_loss: 0.4559 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9634 - val_specificity_at_sensitivity_2: 0.9872 - val_recall_2: 0.6951 - val_precision_2: 0.9048 - val_auc_2: 0.8956\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.8846 - specificity_at_sensitivity_2: 0.9579 - recall_2: 0.6000 - precision_2: 0.8211 - auc_2: 0.8470\n",
            "Epoch 329: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4733 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.8846 - specificity_at_sensitivity_2: 0.9579 - recall_2: 0.6000 - precision_2: 0.8211 - auc_2: 0.8470 - val_loss: 0.3937 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9756 - val_specificity_at_sensitivity_2: 0.9487 - val_recall_2: 0.8049 - val_precision_2: 0.8462 - val_auc_2: 0.9112\n",
            "Epoch 330/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4080 - accuracy: 0.8214 - sensitivity_at_specificity_2: 0.9457 - specificity_at_sensitivity_2: 0.9848 - recall_2: 0.7609 - precision_2: 0.7955 - auc_2: 0.8913\n",
            "Epoch 330: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4284 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9504 - specificity_at_sensitivity_2: 0.9777 - recall_2: 0.7163 - precision_2: 0.8016 - auc_2: 0.8803 - val_loss: 0.4090 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9189 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8108 - val_precision_2: 0.8219 - val_auc_2: 0.8976\n",
            "Epoch 331/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4621 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.9758 - recall_2: 0.8182 - precision_2: 0.7500 - auc_2: 0.8709\n",
            "Epoch 331: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4534 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9477 - specificity_at_sensitivity_2: 0.9701 - recall_2: 0.8235 - precision_2: 0.7456 - auc_2: 0.8793 - val_loss: 0.4051 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9425 - val_specificity_at_sensitivity_2: 0.9863 - val_recall_2: 0.7701 - val_precision_2: 0.9571 - val_auc_2: 0.9173\n",
            "Epoch 332/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4768 - accuracy: 0.7852 - sensitivity_at_specificity_2: 0.9381 - specificity_at_sensitivity_2: 0.9231 - recall_2: 0.6372 - precision_2: 0.8372 - auc_2: 0.8637\n",
            "Epoch 332: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4509 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9441 - specificity_at_sensitivity_2: 0.9322 - recall_2: 0.6923 - precision_2: 0.8534 - auc_2: 0.8754 - val_loss: 0.4792 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9294 - val_specificity_at_sensitivity_2: 0.9733 - val_recall_2: 0.6588 - val_precision_2: 0.8750 - val_auc_2: 0.8596\n",
            "Epoch 333/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4155 - accuracy: 0.8259 - sensitivity_at_specificity_2: 0.9684 - specificity_at_sensitivity_2: 0.9767 - recall_2: 0.8211 - precision_2: 0.7800 - auc_2: 0.8939\n",
            "Epoch 333: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4087 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9766 - specificity_at_sensitivity_2: 0.9792 - recall_2: 0.8125 - precision_2: 0.7647 - auc_2: 0.8983 - val_loss: 0.4106 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9667 - val_specificity_at_sensitivity_2: 0.9714 - val_recall_2: 0.7889 - val_precision_2: 0.9342 - val_auc_2: 0.9125\n",
            "Epoch 334/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4576 - accuracy: 0.7891 - sensitivity_at_specificity_2: 0.9426 - specificity_at_sensitivity_2: 0.9627 - recall_2: 0.6721 - precision_2: 0.8542 - auc_2: 0.8760\n",
            "Epoch 334: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4533 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9474 - specificity_at_sensitivity_2: 0.9464 - recall_2: 0.7171 - precision_2: 0.8134 - auc_2: 0.8706 - val_loss: 0.4654 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9189 - val_specificity_at_sensitivity_2: 0.9767 - val_recall_2: 0.9054 - val_precision_2: 0.6700 - val_auc_2: 0.8969\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4465 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9320 - specificity_at_sensitivity_2: 0.9595 - recall_2: 0.8163 - precision_2: 0.7895 - auc_2: 0.8750\n",
            "Epoch 335: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4465 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9320 - specificity_at_sensitivity_2: 0.9595 - recall_2: 0.8163 - precision_2: 0.7895 - auc_2: 0.8750 - val_loss: 0.4013 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9714 - val_specificity_at_sensitivity_2: 0.9778 - val_recall_2: 0.6571 - val_precision_2: 0.8846 - val_auc_2: 0.9198\n",
            "Epoch 336/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4335 - accuracy: 0.7634 - sensitivity_at_specificity_2: 0.9706 - specificity_at_sensitivity_2: 0.9426 - recall_2: 0.6863 - precision_2: 0.7692 - auc_2: 0.8824\n",
            "Epoch 336: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3980 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9790 - specificity_at_sensitivity_2: 0.9605 - recall_2: 0.7483 - precision_2: 0.7926 - auc_2: 0.9045 - val_loss: 0.4350 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.8987 - val_specificity_at_sensitivity_2: 0.9753 - val_recall_2: 0.7342 - val_precision_2: 0.8406 - val_auc_2: 0.8859\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4201 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9392 - specificity_at_sensitivity_2: 0.9651 - recall_2: 0.8446 - precision_2: 0.8170 - auc_2: 0.8922\n",
            "Epoch 337: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4201 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9392 - specificity_at_sensitivity_2: 0.9651 - recall_2: 0.8446 - precision_2: 0.8170 - auc_2: 0.8922 - val_loss: 0.4164 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9620 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7215 - val_precision_2: 0.8769 - val_auc_2: 0.9037\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9324 - specificity_at_sensitivity_2: 0.9884 - recall_2: 0.7432 - precision_2: 0.8148 - auc_2: 0.8750\n",
            "Epoch 338: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4506 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9324 - specificity_at_sensitivity_2: 0.9884 - recall_2: 0.7432 - precision_2: 0.8148 - auc_2: 0.8750 - val_loss: 0.3804 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9765 - val_specificity_at_sensitivity_2: 0.9733 - val_recall_2: 0.8235 - val_precision_2: 0.8333 - val_auc_2: 0.9165\n",
            "Epoch 339/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4957 - accuracy: 0.7539 - sensitivity_at_specificity_2: 0.8983 - specificity_at_sensitivity_2: 0.9493 - recall_2: 0.7034 - precision_2: 0.7477 - auc_2: 0.8407\n",
            "Epoch 339: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5077 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8926 - specificity_at_sensitivity_2: 0.9298 - recall_2: 0.6846 - precision_2: 0.7556 - auc_2: 0.8325 - val_loss: 0.4343 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9277 - val_specificity_at_sensitivity_2: 0.9870 - val_recall_2: 0.7831 - val_precision_2: 0.9155 - val_auc_2: 0.8848\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9530 - specificity_at_sensitivity_2: 0.9649 - recall_2: 0.8255 - precision_2: 0.7365 - auc_2: 0.8937\n",
            "Epoch 340: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4256 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9530 - specificity_at_sensitivity_2: 0.9649 - recall_2: 0.8255 - precision_2: 0.7365 - auc_2: 0.8937 - val_loss: 0.3696 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9268 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8415 - val_precision_2: 0.8734 - val_auc_2: 0.9183\n",
            "Epoch 341/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5091 - accuracy: 0.7634 - sensitivity_at_specificity_2: 0.8621 - specificity_at_sensitivity_2: 0.8978 - recall_2: 0.5747 - precision_2: 0.7576 - auc_2: 0.8164\n",
            "Epoch 341: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4955 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9111 - specificity_at_sensitivity_2: 0.9297 - recall_2: 0.6074 - precision_2: 0.8283 - auc_2: 0.8450 - val_loss: 0.3939 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9868 - val_specificity_at_sensitivity_2: 0.9762 - val_recall_2: 0.7895 - val_precision_2: 0.8824 - val_auc_2: 0.9156\n",
            "Epoch 342/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5063 - accuracy: 0.7569 - sensitivity_at_specificity_2: 0.8855 - specificity_at_sensitivity_2: 0.9618 - recall_2: 0.8168 - precision_2: 0.6993 - auc_2: 0.8435\n",
            "Epoch 342: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5134 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8699 - specificity_at_sensitivity_2: 0.9483 - recall_2: 0.8082 - precision_2: 0.6941 - auc_2: 0.8367 - val_loss: 0.4442 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9467 - val_specificity_at_sensitivity_2: 0.9647 - val_recall_2: 0.8000 - val_precision_2: 0.7895 - val_auc_2: 0.8866\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4684 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9320 - specificity_at_sensitivity_2: 0.9827 - recall_2: 0.6259 - precision_2: 0.8846 - auc_2: 0.8716\n",
            "Epoch 343: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4684 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9320 - specificity_at_sensitivity_2: 0.9827 - recall_2: 0.6259 - precision_2: 0.8846 - auc_2: 0.8716 - val_loss: 0.4102 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9452 - val_specificity_at_sensitivity_2: 0.9770 - val_recall_2: 0.7671 - val_precision_2: 0.8358 - val_auc_2: 0.9012\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4740 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9456 - specificity_at_sensitivity_2: 0.9364 - recall_2: 0.7687 - precision_2: 0.7533 - auc_2: 0.8561\n",
            "Epoch 344: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4740 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9456 - specificity_at_sensitivity_2: 0.9364 - recall_2: 0.7687 - precision_2: 0.7533 - auc_2: 0.8561 - val_loss: 0.4431 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9630 - val_specificity_at_sensitivity_2: 0.9367 - val_recall_2: 0.8395 - val_precision_2: 0.7816 - val_auc_2: 0.8784\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9067 - specificity_at_sensitivity_2: 0.9529 - recall_2: 0.7467 - precision_2: 0.8000 - auc_2: 0.8672\n",
            "Epoch 345: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4510 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9067 - specificity_at_sensitivity_2: 0.9529 - recall_2: 0.7467 - precision_2: 0.8000 - auc_2: 0.8672 - val_loss: 0.4042 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9390 - val_specificity_at_sensitivity_2: 0.9615 - val_recall_2: 0.7805 - val_precision_2: 0.8533 - val_auc_2: 0.9024\n",
            "Epoch 346/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.3865 - accuracy: 0.8348 - sensitivity_at_specificity_2: 0.9495 - specificity_at_sensitivity_2: 0.9920 - recall_2: 0.7879 - precision_2: 0.8298 - auc_2: 0.9105\n",
            "Epoch 346: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4001 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9493 - specificity_at_sensitivity_2: 0.9780 - recall_2: 0.7826 - precision_2: 0.8120 - auc_2: 0.8987 - val_loss: 0.3964 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9286 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8095 - val_precision_2: 0.8395 - val_auc_2: 0.9008\n",
            "Epoch 347/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4707 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9561 - specificity_at_sensitivity_2: 0.9577 - recall_2: 0.7982 - precision_2: 0.7339 - auc_2: 0.8595\n",
            "Epoch 347: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4742 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9424 - specificity_at_sensitivity_2: 0.9558 - recall_2: 0.7698 - precision_2: 0.7431 - auc_2: 0.8536 - val_loss: 0.3634 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9710 - val_specificity_at_sensitivity_2: 0.9890 - val_recall_2: 0.6522 - val_precision_2: 0.9184 - val_auc_2: 0.9405\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4798 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.8790 - specificity_at_sensitivity_2: 0.9877 - recall_2: 0.7389 - precision_2: 0.8227 - auc_2: 0.8519\n",
            "Epoch 348: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4798 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.8790 - specificity_at_sensitivity_2: 0.9877 - recall_2: 0.7389 - precision_2: 0.8227 - auc_2: 0.8519 - val_loss: 0.4582 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9241 - val_precision_2: 0.7374 - val_auc_2: 0.8979\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5222 - accuracy: 0.7276 - sensitivity_at_specificity_2: 0.8800 - specificity_at_sensitivity_2: 0.9394 - recall_2: 0.7040 - precision_2: 0.6769 - auc_2: 0.8128\n",
            "Epoch 349: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5222 - accuracy: 0.7276 - sensitivity_at_specificity_2: 0.8800 - specificity_at_sensitivity_2: 0.9394 - recall_2: 0.7040 - precision_2: 0.6769 - auc_2: 0.8128 - val_loss: 0.4597 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9571 - val_specificity_at_sensitivity_2: 0.9889 - val_recall_2: 0.5429 - val_precision_2: 0.9744 - val_auc_2: 0.9049\n",
            "Epoch 350/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5055 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.9592 - specificity_at_sensitivity_2: 0.9365 - recall_2: 0.5102 - precision_2: 0.8621 - auc_2: 0.8678\n",
            "Epoch 350: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4858 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9493 - specificity_at_sensitivity_2: 0.9396 - recall_2: 0.5580 - precision_2: 0.8556 - auc_2: 0.8695 - val_loss: 0.4158 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9211 - val_specificity_at_sensitivity_2: 0.9762 - val_recall_2: 0.8421 - val_precision_2: 0.8421 - val_auc_2: 0.8925\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4550 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9167 - specificity_at_sensitivity_2: 0.9415 - recall_2: 0.8258 - precision_2: 0.7517 - auc_2: 0.8697\n",
            "Epoch 351: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4550 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9167 - specificity_at_sensitivity_2: 0.9415 - recall_2: 0.8258 - precision_2: 0.7517 - auc_2: 0.8697 - val_loss: 0.4614 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9011 - val_specificity_at_sensitivity_2: 0.9855 - val_recall_2: 0.7143 - val_precision_2: 0.9420 - val_auc_2: 0.8943\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4025 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9353 - specificity_at_sensitivity_2: 0.9890 - recall_2: 0.7626 - precision_2: 0.8346 - auc_2: 0.8980\n",
            "Epoch 352: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4025 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9353 - specificity_at_sensitivity_2: 0.9890 - recall_2: 0.7626 - precision_2: 0.8346 - auc_2: 0.8980 - val_loss: 0.5195 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.8734 - val_specificity_at_sensitivity_2: 0.9383 - val_recall_2: 0.6582 - val_precision_2: 0.8254 - val_auc_2: 0.8304\n",
            "Epoch 353/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4194 - accuracy: 0.8229 - sensitivity_at_specificity_2: 0.9512 - specificity_at_sensitivity_2: 0.9758 - recall_2: 0.7561 - precision_2: 0.8158 - auc_2: 0.8876\n",
            "Epoch 353: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4067 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9538 - specificity_at_sensitivity_2: 0.9789 - recall_2: 0.7538 - precision_2: 0.8099 - auc_2: 0.8933 - val_loss: 0.3689 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9872 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.8077 - val_precision_2: 0.8400 - val_auc_2: 0.9230\n",
            "Epoch 354/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4736 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9255 - specificity_at_sensitivity_2: 0.9462 - recall_2: 0.7021 - precision_2: 0.7586 - auc_2: 0.8509\n",
            "Epoch 354: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4426 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9416 - specificity_at_sensitivity_2: 0.9672 - recall_2: 0.7299 - precision_2: 0.7812 - auc_2: 0.8717 - val_loss: 0.4514 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9012 - val_specificity_at_sensitivity_2: 0.9747 - val_recall_2: 0.7901 - val_precision_2: 0.8101 - val_auc_2: 0.8679\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4322 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9500 - specificity_at_sensitivity_2: 0.9556 - recall_2: 0.7857 - precision_2: 0.7857 - auc_2: 0.8798\n",
            "Epoch 355: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4322 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9500 - specificity_at_sensitivity_2: 0.9556 - recall_2: 0.7857 - precision_2: 0.7857 - auc_2: 0.8798 - val_loss: 0.3756 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9643 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7976 - val_precision_2: 0.9054 - val_auc_2: 0.9267\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3921 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9496 - specificity_at_sensitivity_2: 0.9724 - recall_2: 0.7914 - precision_2: 0.8527 - auc_2: 0.9035\n",
            "Epoch 356: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.3921 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9496 - specificity_at_sensitivity_2: 0.9724 - recall_2: 0.7914 - precision_2: 0.8527 - auc_2: 0.9035 - val_loss: 0.4100 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9545 - val_specificity_at_sensitivity_2: 0.9894 - val_recall_2: 0.7727 - val_precision_2: 0.7083 - val_auc_2: 0.8910\n",
            "Epoch 357/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4247 - accuracy: 0.8359 - sensitivity_at_specificity_2: 0.9074 - specificity_at_sensitivity_2: 0.9865 - recall_2: 0.8056 - precision_2: 0.8056 - auc_2: 0.8839\n",
            "Epoch 357: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4341 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9071 - specificity_at_sensitivity_2: 0.9833 - recall_2: 0.7857 - precision_2: 0.8209 - auc_2: 0.8761 - val_loss: 0.3966 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9770 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7471 - val_precision_2: 0.9028 - val_auc_2: 0.9148\n",
            "Epoch 358/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4609 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9174 - specificity_at_sensitivity_2: 0.9456 - recall_2: 0.6972 - precision_2: 0.7677 - auc_2: 0.8566\n",
            "Epoch 358: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4444 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9097 - specificity_at_sensitivity_2: 0.9602 - recall_2: 0.7361 - precision_2: 0.7852 - auc_2: 0.8702 - val_loss: 0.4437 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 0.9630 - val_recall_2: 0.8101 - val_precision_2: 0.7529 - val_auc_2: 0.8775\n",
            "Epoch 359/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4798 - accuracy: 0.7695 - sensitivity_at_specificity_2: 0.8760 - specificity_at_sensitivity_2: 0.9704 - recall_2: 0.7190 - precision_2: 0.7768 - auc_2: 0.8429\n",
            "Epoch 359: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4744 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9079 - specificity_at_sensitivity_2: 0.9464 - recall_2: 0.7171 - precision_2: 0.7899 - auc_2: 0.8495 - val_loss: 0.4605 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9136 - val_specificity_at_sensitivity_2: 0.9494 - val_recall_2: 0.7778 - val_precision_2: 0.8400 - val_auc_2: 0.8634\n",
            "Epoch 360/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4575 - accuracy: 0.7852 - sensitivity_at_specificity_2: 0.9304 - specificity_at_sensitivity_2: 0.9504 - recall_2: 0.6957 - precision_2: 0.8000 - auc_2: 0.8634\n",
            "Epoch 360: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4479 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9301 - specificity_at_sensitivity_2: 0.9774 - recall_2: 0.7133 - precision_2: 0.8160 - auc_2: 0.8680 - val_loss: 0.3849 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9487 - val_specificity_at_sensitivity_2: 0.9634 - val_recall_2: 0.8205 - val_precision_2: 0.8533 - val_auc_2: 0.9141\n",
            "Epoch 361/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4641 - accuracy: 0.7930 - sensitivity_at_specificity_2: 0.9204 - specificity_at_sensitivity_2: 0.9231 - recall_2: 0.7345 - precision_2: 0.7830 - auc_2: 0.8572\n",
            "Epoch 361: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4475 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9296 - specificity_at_sensitivity_2: 0.9270 - recall_2: 0.7465 - precision_2: 0.7910 - auc_2: 0.8687 - val_loss: 0.4137 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9041 - val_specificity_at_sensitivity_2: 0.9770 - val_recall_2: 0.8219 - val_precision_2: 0.8000 - val_auc_2: 0.8864\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4228 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9773 - recall_2: 0.7431 - precision_2: 0.8045 - auc_2: 0.8821\n",
            "Epoch 362: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4228 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9773 - recall_2: 0.7431 - precision_2: 0.8045 - auc_2: 0.8821 - val_loss: 0.4880 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9130 - val_specificity_at_sensitivity_2: 0.9853 - val_recall_2: 0.6739 - val_precision_2: 0.8986 - val_auc_2: 0.8720\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9571 - specificity_at_sensitivity_2: 0.9556 - recall_2: 0.7429 - precision_2: 0.7879 - auc_2: 0.8772\n",
            "Epoch 363: val_accuracy did not improve from 0.86875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4360 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9571 - specificity_at_sensitivity_2: 0.9556 - recall_2: 0.7429 - precision_2: 0.7879 - auc_2: 0.8772 - val_loss: 0.3999 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9342 - val_specificity_at_sensitivity_2: 0.9643 - val_recall_2: 0.8421 - val_precision_2: 0.8101 - val_auc_2: 0.9005\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9343 - specificity_at_sensitivity_2: 0.9617 - recall_2: 0.8321 - precision_2: 0.8028 - auc_2: 0.8970\n",
            "Epoch 364: val_accuracy improved from 0.86875 to 0.87500, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4011 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9343 - specificity_at_sensitivity_2: 0.9617 - recall_2: 0.8321 - precision_2: 0.8028 - auc_2: 0.8970 - val_loss: 0.3468 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9870 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7662 - val_precision_2: 0.9672 - val_auc_2: 0.9391\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4703 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.8933 - specificity_at_sensitivity_2: 0.9647 - recall_2: 0.7200 - precision_2: 0.8000 - auc_2: 0.8534\n",
            "Epoch 365: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4703 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.8933 - specificity_at_sensitivity_2: 0.9647 - recall_2: 0.7200 - precision_2: 0.8000 - auc_2: 0.8534 - val_loss: 0.3801 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.7436 - val_precision_2: 0.9062 - val_auc_2: 0.9210\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9306 - specificity_at_sensitivity_2: 0.9659 - recall_2: 0.7639 - precision_2: 0.8527 - auc_2: 0.8749\n",
            "Epoch 366: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4434 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9306 - specificity_at_sensitivity_2: 0.9659 - recall_2: 0.7639 - precision_2: 0.8527 - auc_2: 0.8749 - val_loss: 0.4510 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.8816 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.6579 - val_precision_2: 0.8772 - val_auc_2: 0.8712\n",
            "Epoch 367/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4532 - accuracy: 0.7930 - sensitivity_at_specificity_2: 0.9154 - specificity_at_sensitivity_2: 0.9603 - recall_2: 0.7846 - precision_2: 0.8031 - auc_2: 0.8696\n",
            "Epoch 367: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4536 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9114 - specificity_at_sensitivity_2: 0.9630 - recall_2: 0.7722 - precision_2: 0.7922 - auc_2: 0.8684 - val_loss: 0.4106 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9059 - val_specificity_at_sensitivity_2: 0.9733 - val_recall_2: 0.8471 - val_precision_2: 0.8372 - val_auc_2: 0.8955\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9205 - specificity_at_sensitivity_2: 0.9704 - recall_2: 0.7351 - precision_2: 0.8810 - auc_2: 0.8864\n",
            "Epoch 368: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4232 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9205 - specificity_at_sensitivity_2: 0.9704 - recall_2: 0.7351 - precision_2: 0.8810 - auc_2: 0.8864 - val_loss: 0.4692 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9487 - val_specificity_at_sensitivity_2: 0.9390 - val_recall_2: 0.7308 - val_precision_2: 0.7808 - val_auc_2: 0.8583\n",
            "Epoch 369/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4200 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9350 - specificity_at_sensitivity_2: 0.9624 - recall_2: 0.8293 - precision_2: 0.7669 - auc_2: 0.8944\n",
            "Epoch 369: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4183 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9474 - specificity_at_sensitivity_2: 0.9702 - recall_2: 0.8224 - precision_2: 0.7622 - auc_2: 0.8971 - val_loss: 0.4110 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9512 - val_specificity_at_sensitivity_2: 0.9872 - val_recall_2: 0.7317 - val_precision_2: 0.8451 - val_auc_2: 0.9000\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4126 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9412 - specificity_at_sensitivity_2: 0.9674 - recall_2: 0.7059 - precision_2: 0.8571 - auc_2: 0.8933\n",
            "Epoch 370: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4126 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9412 - specificity_at_sensitivity_2: 0.9674 - recall_2: 0.7059 - precision_2: 0.8571 - auc_2: 0.8933 - val_loss: 0.3886 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9877 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.7901 - val_precision_2: 0.8533 - val_auc_2: 0.9139\n",
            "Epoch 371/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4533 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9298 - specificity_at_sensitivity_2: 0.9507 - recall_2: 0.8333 - precision_2: 0.7661 - auc_2: 0.8741\n",
            "Epoch 371: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4404 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9236 - specificity_at_sensitivity_2: 0.9602 - recall_2: 0.8264 - precision_2: 0.7727 - auc_2: 0.8788 - val_loss: 0.4084 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9753 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.7160 - val_precision_2: 0.8788 - val_auc_2: 0.9189\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.8926 - specificity_at_sensitivity_2: 0.9357 - recall_2: 0.7114 - precision_2: 0.8154 - auc_2: 0.8559\n",
            "Epoch 372: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4746 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.8926 - specificity_at_sensitivity_2: 0.9357 - recall_2: 0.7114 - precision_2: 0.8154 - auc_2: 0.8559 - val_loss: 0.3924 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9221 - val_specificity_at_sensitivity_2: 0.9518 - val_recall_2: 0.8182 - val_precision_2: 0.8400 - val_auc_2: 0.9018\n",
            "Epoch 373/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3997 - accuracy: 0.8359 - sensitivity_at_specificity_2: 0.9658 - specificity_at_sensitivity_2: 0.9856 - recall_2: 0.8803 - precision_2: 0.7863 - auc_2: 0.9084\n",
            "Epoch 373: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4117 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9580 - specificity_at_sensitivity_2: 0.9774 - recall_2: 0.8671 - precision_2: 0.7750 - auc_2: 0.8991 - val_loss: 0.3834 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9359 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.7564 - val_precision_2: 0.9365 - val_auc_2: 0.9223\n",
            "Epoch 374/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4224 - accuracy: 0.8348 - sensitivity_at_specificity_2: 0.9636 - specificity_at_sensitivity_2: 0.9649 - recall_2: 0.7636 - precision_2: 0.8842 - auc_2: 0.9019\n",
            "Epoch 374: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4259 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9610 - specificity_at_sensitivity_2: 0.9578 - recall_2: 0.7597 - precision_2: 0.8603 - auc_2: 0.8954 - val_loss: 0.3226 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9770 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9080 - val_precision_2: 0.8495 - val_auc_2: 0.9449\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9051 - specificity_at_sensitivity_2: 0.9672 - recall_2: 0.8029 - precision_2: 0.7801 - auc_2: 0.8689\n",
            "Epoch 375: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4428 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9051 - specificity_at_sensitivity_2: 0.9672 - recall_2: 0.8029 - precision_2: 0.7801 - auc_2: 0.8689 - val_loss: 0.4178 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9296 - val_specificity_at_sensitivity_2: 0.9663 - val_recall_2: 0.7606 - val_precision_2: 0.8571 - val_auc_2: 0.8899\n",
            "Epoch 376/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4537 - accuracy: 0.7930 - sensitivity_at_specificity_2: 0.9360 - specificity_at_sensitivity_2: 0.9466 - recall_2: 0.7520 - precision_2: 0.8103 - auc_2: 0.8692\n",
            "Epoch 376: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4365 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9490 - specificity_at_sensitivity_2: 0.9693 - recall_2: 0.7643 - precision_2: 0.8000 - auc_2: 0.8794 - val_loss: 0.3521 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9750 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8875 - val_precision_2: 0.8161 - val_auc_2: 0.9351\n",
            "Epoch 377/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4625 - accuracy: 0.7991 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.9118 - recall_2: 0.7500 - precision_2: 0.7416 - auc_2: 0.8526\n",
            "Epoch 377: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4283 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9259 - specificity_at_sensitivity_2: 0.9351 - recall_2: 0.7926 - precision_2: 0.8045 - auc_2: 0.8784 - val_loss: 0.4287 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9265 - val_specificity_at_sensitivity_2: 0.9891 - val_recall_2: 0.6471 - val_precision_2: 0.9167 - val_auc_2: 0.8932\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4554 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9504 - specificity_at_sensitivity_2: 0.9609 - recall_2: 0.6950 - precision_2: 0.7717 - auc_2: 0.8664\n",
            "Epoch 378: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4554 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9504 - specificity_at_sensitivity_2: 0.9609 - recall_2: 0.6950 - precision_2: 0.7717 - auc_2: 0.8664 - val_loss: 0.4201 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9241 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7722 - val_precision_2: 0.8243 - val_auc_2: 0.8902\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9562 - specificity_at_sensitivity_2: 0.9727 - recall_2: 0.8102 - precision_2: 0.8043 - auc_2: 0.9105\n",
            "Epoch 379: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.3798 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9562 - specificity_at_sensitivity_2: 0.9727 - recall_2: 0.8102 - precision_2: 0.8043 - auc_2: 0.9105 - val_loss: 0.3836 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9600 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8267 - val_precision_2: 0.8158 - val_auc_2: 0.9075\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9448 - specificity_at_sensitivity_2: 0.9771 - recall_2: 0.7241 - precision_2: 0.7955 - auc_2: 0.8769\n",
            "Epoch 380: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4386 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9448 - specificity_at_sensitivity_2: 0.9771 - recall_2: 0.7241 - precision_2: 0.7955 - auc_2: 0.8769 - val_loss: 0.4797 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9048 - val_specificity_at_sensitivity_2: 0.9474 - val_recall_2: 0.7857 - val_precision_2: 0.7586 - val_auc_2: 0.8561\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9551 - specificity_at_sensitivity_2: 0.9695 - recall_2: 0.8205 - precision_2: 0.8000 - auc_2: 0.8977\n",
            "Epoch 381: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4083 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9551 - specificity_at_sensitivity_2: 0.9695 - recall_2: 0.8205 - precision_2: 0.8000 - auc_2: 0.8977 - val_loss: 0.3705 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8452 - val_precision_2: 0.8659 - val_auc_2: 0.9200\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4677 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.8873 - specificity_at_sensitivity_2: 0.9775 - recall_2: 0.6831 - precision_2: 0.7886 - auc_2: 0.8494\n",
            "Epoch 382: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4677 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.8873 - specificity_at_sensitivity_2: 0.9775 - recall_2: 0.6831 - precision_2: 0.7886 - auc_2: 0.8494 - val_loss: 0.3610 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9880 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8434 - val_precision_2: 0.8642 - val_auc_2: 0.9300\n",
            "Epoch 383/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4257 - accuracy: 0.8214 - sensitivity_at_specificity_2: 0.9451 - specificity_at_sensitivity_2: 0.9624 - recall_2: 0.8022 - precision_2: 0.7684 - auc_2: 0.8871\n",
            "Epoch 383: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4358 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9403 - specificity_at_sensitivity_2: 0.9516 - recall_2: 0.7388 - precision_2: 0.7920 - auc_2: 0.8752 - val_loss: 0.3427 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 1.0000 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8488 - val_precision_2: 0.8795 - val_auc_2: 0.9463\n",
            "Epoch 384/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4465 - accuracy: 0.7891 - sensitivity_at_specificity_2: 0.9421 - specificity_at_sensitivity_2: 0.9556 - recall_2: 0.7521 - precision_2: 0.7913 - auc_2: 0.8747\n",
            "Epoch 384: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4252 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9667 - specificity_at_sensitivity_2: 0.9706 - recall_2: 0.7667 - precision_2: 0.8042 - auc_2: 0.8895 - val_loss: 0.4828 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.8462 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7436 - val_precision_2: 0.7945 - val_auc_2: 0.8442\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9371 - specificity_at_sensitivity_2: 0.9718 - recall_2: 0.7133 - precision_2: 0.8226 - auc_2: 0.8807\n",
            "Epoch 385: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4297 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9371 - specificity_at_sensitivity_2: 0.9718 - recall_2: 0.7133 - precision_2: 0.8226 - auc_2: 0.8807 - val_loss: 0.4144 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9176 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8235 - val_precision_2: 0.8046 - val_auc_2: 0.8944\n",
            "Epoch 386/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4004 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9649 - specificity_at_sensitivity_2: 0.9577 - recall_2: 0.8246 - precision_2: 0.7966 - auc_2: 0.9025\n",
            "Epoch 386: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4274 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9632 - specificity_at_sensitivity_2: 0.9402 - recall_2: 0.7941 - precision_2: 0.7714 - auc_2: 0.8850 - val_loss: 0.4547 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.8961 - val_specificity_at_sensitivity_2: 0.9880 - val_recall_2: 0.7403 - val_precision_2: 0.8143 - val_auc_2: 0.8626\n",
            "Epoch 387/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4177 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9307 - specificity_at_sensitivity_2: 0.9919 - recall_2: 0.7228 - precision_2: 0.8391 - auc_2: 0.8851\n",
            "Epoch 387: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4304 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9137 - specificity_at_sensitivity_2: 0.9724 - recall_2: 0.7194 - precision_2: 0.8403 - auc_2: 0.8754 - val_loss: 0.3852 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9655 - val_specificity_at_sensitivity_2: 0.9863 - val_recall_2: 0.7816 - val_precision_2: 0.9067 - val_auc_2: 0.9240\n",
            "Epoch 388/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3974 - accuracy: 0.8320 - sensitivity_at_specificity_2: 0.9478 - specificity_at_sensitivity_2: 0.9716 - recall_2: 0.7739 - precision_2: 0.8396 - auc_2: 0.8977\n",
            "Epoch 388: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3903 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9586 - specificity_at_sensitivity_2: 0.9943 - recall_2: 0.7793 - precision_2: 0.8248 - auc_2: 0.9031 - val_loss: 0.3974 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9036 - val_specificity_at_sensitivity_2: 0.9870 - val_recall_2: 0.8193 - val_precision_2: 0.8293 - val_auc_2: 0.9000\n",
            "Epoch 389/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4546 - accuracy: 0.7891 - sensitivity_at_specificity_2: 0.9182 - specificity_at_sensitivity_2: 0.9658 - recall_2: 0.7000 - precision_2: 0.7857 - auc_2: 0.8643\n",
            "Epoch 389: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4369 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9481 - specificity_at_sensitivity_2: 0.9568 - recall_2: 0.7185 - precision_2: 0.7951 - auc_2: 0.8760 - val_loss: 0.4032 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8025 - val_precision_2: 0.8667 - val_auc_2: 0.9030\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4597 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9295 - specificity_at_sensitivity_2: 0.9634 - recall_2: 0.7436 - precision_2: 0.8467 - auc_2: 0.8644\n",
            "Epoch 390: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4597 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9295 - specificity_at_sensitivity_2: 0.9634 - recall_2: 0.7436 - precision_2: 0.8467 - auc_2: 0.8644 - val_loss: 0.3962 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9286 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8333 - val_precision_2: 0.8235 - val_auc_2: 0.9017\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4332 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9507 - specificity_at_sensitivity_2: 0.9831 - recall_2: 0.7394 - precision_2: 0.7343 - auc_2: 0.8770\n",
            "Epoch 391: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4332 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9507 - specificity_at_sensitivity_2: 0.9831 - recall_2: 0.7394 - precision_2: 0.7343 - auc_2: 0.8770 - val_loss: 0.4226 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9114 - val_specificity_at_sensitivity_2: 0.9877 - val_recall_2: 0.7215 - val_precision_2: 0.8769 - val_auc_2: 0.8929\n",
            "Epoch 392/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4060 - accuracy: 0.8398 - sensitivity_at_specificity_2: 0.9244 - specificity_at_sensitivity_2: 0.9708 - recall_2: 0.7563 - precision_2: 0.8824 - auc_2: 0.8968\n",
            "Epoch 392: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4200 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9306 - specificity_at_sensitivity_2: 0.9545 - recall_2: 0.7847 - precision_2: 0.8309 - auc_2: 0.8867 - val_loss: 0.4659 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9136 - val_specificity_at_sensitivity_2: 0.9747 - val_recall_2: 0.7778 - val_precision_2: 0.7412 - val_auc_2: 0.8620\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9173 - specificity_at_sensitivity_2: 0.9786 - recall_2: 0.7068 - precision_2: 0.7966 - auc_2: 0.8681\n",
            "Epoch 393: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4384 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9173 - specificity_at_sensitivity_2: 0.9786 - recall_2: 0.7068 - precision_2: 0.7966 - auc_2: 0.8681 - val_loss: 0.4393 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9452 - val_specificity_at_sensitivity_2: 0.9655 - val_recall_2: 0.6027 - val_precision_2: 0.8980 - val_auc_2: 0.8963\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4448 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9536 - specificity_at_sensitivity_2: 0.9586 - recall_2: 0.8146 - precision_2: 0.7688 - auc_2: 0.8753\n",
            "Epoch 394: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4448 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9536 - specificity_at_sensitivity_2: 0.9586 - recall_2: 0.8146 - precision_2: 0.7688 - auc_2: 0.8753 - val_loss: 0.3670 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9570 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8280 - val_precision_2: 0.8851 - val_auc_2: 0.9242\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4194 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9241 - specificity_at_sensitivity_2: 0.9886 - recall_2: 0.6759 - precision_2: 0.8909 - auc_2: 0.8951\n",
            "Epoch 395: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4194 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9241 - specificity_at_sensitivity_2: 0.9886 - recall_2: 0.6759 - precision_2: 0.8909 - auc_2: 0.8951 - val_loss: 0.4247 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9551 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7191 - val_precision_2: 0.9275 - val_auc_2: 0.9149\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4171 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9571 - specificity_at_sensitivity_2: 0.9667 - recall_2: 0.8357 - precision_2: 0.7647 - auc_2: 0.8928\n",
            "Epoch 396: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4171 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9571 - specificity_at_sensitivity_2: 0.9667 - recall_2: 0.8357 - precision_2: 0.7647 - auc_2: 0.8928 - val_loss: 0.4294 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9324 - val_specificity_at_sensitivity_2: 0.9651 - val_recall_2: 0.8243 - val_precision_2: 0.7625 - val_auc_2: 0.8843\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4228 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9079 - specificity_at_sensitivity_2: 0.9881 - recall_2: 0.7171 - precision_2: 0.9008 - auc_2: 0.8913\n",
            "Epoch 397: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4228 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9079 - specificity_at_sensitivity_2: 0.9881 - recall_2: 0.7171 - precision_2: 0.9008 - auc_2: 0.8913 - val_loss: 0.4373 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9351 - val_specificity_at_sensitivity_2: 0.9518 - val_recall_2: 0.8052 - val_precision_2: 0.7848 - val_auc_2: 0.8831\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.8955 - specificity_at_sensitivity_2: 0.9462 - recall_2: 0.7537 - precision_2: 0.7163 - auc_2: 0.8335\n",
            "Epoch 398: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5045 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.8955 - specificity_at_sensitivity_2: 0.9462 - recall_2: 0.7537 - precision_2: 0.7163 - auc_2: 0.8335 - val_loss: 0.4602 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9294 - val_specificity_at_sensitivity_2: 0.9733 - val_recall_2: 0.6941 - val_precision_2: 0.9219 - val_auc_2: 0.8931\n",
            "Epoch 399/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4272 - accuracy: 0.8242 - sensitivity_at_specificity_2: 0.9439 - specificity_at_sensitivity_2: 0.9933 - recall_2: 0.6822 - precision_2: 0.8690 - auc_2: 0.8852\n",
            "Epoch 399: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4264 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9416 - specificity_at_sensitivity_2: 0.9945 - recall_2: 0.6934 - precision_2: 0.8636 - auc_2: 0.8869 - val_loss: 0.4001 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9310 - val_specificity_at_sensitivity_2: 0.9863 - val_recall_2: 0.8046 - val_precision_2: 0.9333 - val_auc_2: 0.9087\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9388 - specificity_at_sensitivity_2: 0.9711 - recall_2: 0.8299 - precision_2: 0.7821 - auc_2: 0.8963\n",
            "Epoch 400: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4085 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9388 - specificity_at_sensitivity_2: 0.9711 - recall_2: 0.8299 - precision_2: 0.7821 - auc_2: 0.8963 - val_loss: 0.3767 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9620 - val_specificity_at_sensitivity_2: 0.9877 - val_recall_2: 0.8228 - val_precision_2: 0.8553 - val_auc_2: 0.9182\n",
            "Epoch 401/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4031 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9516 - specificity_at_sensitivity_2: 0.9924 - recall_2: 0.7258 - precision_2: 0.8654 - auc_2: 0.9059\n",
            "Epoch 401: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.3939 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9675 - specificity_at_sensitivity_2: 0.9880 - recall_2: 0.7662 - precision_2: 0.8551 - auc_2: 0.9095 - val_loss: 0.3516 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9870 - val_specificity_at_sensitivity_2: 0.9880 - val_recall_2: 0.9091 - val_precision_2: 0.7692 - val_auc_2: 0.9384\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9577 - specificity_at_sensitivity_2: 0.9663 - recall_2: 0.7817 - precision_2: 0.7817 - auc_2: 0.8895\n",
            "Epoch 402: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4135 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9577 - specificity_at_sensitivity_2: 0.9663 - recall_2: 0.7817 - precision_2: 0.7817 - auc_2: 0.8895 - val_loss: 0.4326 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 0.9630 - val_recall_2: 0.6835 - val_precision_2: 0.8571 - val_auc_2: 0.8934\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9104 - specificity_at_sensitivity_2: 0.9731 - recall_2: 0.7388 - precision_2: 0.7920 - auc_2: 0.8823\n",
            "Epoch 403: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4205 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9104 - specificity_at_sensitivity_2: 0.9731 - recall_2: 0.7388 - precision_2: 0.7920 - auc_2: 0.8823 - val_loss: 0.4375 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9383 - val_specificity_at_sensitivity_2: 0.9747 - val_recall_2: 0.8272 - val_precision_2: 0.7444 - val_auc_2: 0.8811\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.8976 - specificity_at_sensitivity_2: 0.9378 - recall_2: 0.7165 - precision_2: 0.7712 - auc_2: 0.8483\n",
            "Epoch 404: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4639 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.8976 - specificity_at_sensitivity_2: 0.9378 - recall_2: 0.7165 - precision_2: 0.7712 - auc_2: 0.8483 - val_loss: 0.4249 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9529 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7529 - val_precision_2: 0.8889 - val_auc_2: 0.9008\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3723 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9800 - specificity_at_sensitivity_2: 0.9765 - recall_2: 0.8667 - precision_2: 0.7975 - auc_2: 0.9235\n",
            "Epoch 405: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.3723 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9800 - specificity_at_sensitivity_2: 0.9765 - recall_2: 0.8667 - precision_2: 0.7975 - auc_2: 0.9235 - val_loss: 0.3821 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9535 - val_specificity_at_sensitivity_2: 0.9865 - val_recall_2: 0.8488 - val_precision_2: 0.8588 - val_auc_2: 0.9164\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3909 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9388 - specificity_at_sensitivity_2: 0.9884 - recall_2: 0.7619 - precision_2: 0.8819 - auc_2: 0.9077\n",
            "Epoch 406: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3909 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9388 - specificity_at_sensitivity_2: 0.9884 - recall_2: 0.7619 - precision_2: 0.8819 - auc_2: 0.9077 - val_loss: 0.3644 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9750 - val_specificity_at_sensitivity_2: 0.9875 - val_recall_2: 0.8125 - val_precision_2: 0.8442 - val_auc_2: 0.9195\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4488 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9038 - specificity_at_sensitivity_2: 0.9634 - recall_2: 0.7756 - precision_2: 0.7857 - auc_2: 0.8691\n",
            "Epoch 407: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4488 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9038 - specificity_at_sensitivity_2: 0.9634 - recall_2: 0.7756 - precision_2: 0.7857 - auc_2: 0.8691 - val_loss: 0.3914 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9419 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8721 - val_precision_2: 0.7979 - val_auc_2: 0.9085\n",
            "Epoch 408/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4618 - accuracy: 0.8008 - sensitivity_at_specificity_2: 0.9074 - specificity_at_sensitivity_2: 0.9459 - recall_2: 0.7407 - precision_2: 0.7767 - auc_2: 0.8619\n",
            "Epoch 408: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4596 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9259 - specificity_at_sensitivity_2: 0.9459 - recall_2: 0.7333 - precision_2: 0.7795 - auc_2: 0.8628 - val_loss: 0.4026 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9529 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7412 - val_precision_2: 0.9545 - val_auc_2: 0.9211\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9310 - specificity_at_sensitivity_2: 0.9829 - recall_2: 0.7172 - precision_2: 0.8254 - auc_2: 0.8836\n",
            "Epoch 409: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4298 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9310 - specificity_at_sensitivity_2: 0.9829 - recall_2: 0.7172 - precision_2: 0.8254 - auc_2: 0.8836 - val_loss: 0.3867 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9518 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8313 - val_precision_2: 0.8118 - val_auc_2: 0.9101\n",
            "Epoch 410/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4214 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9697 - specificity_at_sensitivity_2: 0.9920 - recall_2: 0.7475 - precision_2: 0.7551 - auc_2: 0.8903\n",
            "Epoch 410: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4239 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9728 - specificity_at_sensitivity_2: 0.9711 - recall_2: 0.7279 - precision_2: 0.7868 - auc_2: 0.8905 - val_loss: 0.3976 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9651 - val_specificity_at_sensitivity_2: 0.9865 - val_recall_2: 0.7558 - val_precision_2: 0.8553 - val_auc_2: 0.9073\n",
            "Epoch 411/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4184 - accuracy: 0.8160 - sensitivity_at_specificity_2: 0.9416 - specificity_at_sensitivity_2: 0.9801 - recall_2: 0.8759 - precision_2: 0.7692 - auc_2: 0.8973\n",
            "Epoch 411: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4080 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9524 - specificity_at_sensitivity_2: 0.9769 - recall_2: 0.8776 - precision_2: 0.7725 - auc_2: 0.9041 - val_loss: 0.3906 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9375 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.6875 - val_precision_2: 1.0000 - val_auc_2: 0.9327\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4307 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9507 - specificity_at_sensitivity_2: 0.9775 - recall_2: 0.5915 - precision_2: 0.8842 - auc_2: 0.8894\n",
            "Epoch 412: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4307 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9507 - specificity_at_sensitivity_2: 0.9775 - recall_2: 0.5915 - precision_2: 0.8842 - auc_2: 0.8894 - val_loss: 0.4358 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9091 - val_specificity_at_sensitivity_2: 0.9861 - val_recall_2: 0.7386 - val_precision_2: 0.8784 - val_auc_2: 0.8849\n",
            "Epoch 413/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4268 - accuracy: 0.7857 - sensitivity_at_specificity_2: 0.9608 - specificity_at_sensitivity_2: 0.9672 - recall_2: 0.8039 - precision_2: 0.7455 - auc_2: 0.8899\n",
            "Epoch 413: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4367 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9433 - specificity_at_sensitivity_2: 0.9721 - recall_2: 0.8014 - precision_2: 0.7244 - auc_2: 0.8831 - val_loss: 0.3843 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9306 - val_specificity_at_sensitivity_2: 0.9886 - val_recall_2: 0.7639 - val_precision_2: 0.9016 - val_auc_2: 0.9115\n",
            "Epoch 414/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4633 - accuracy: 0.7857 - sensitivity_at_specificity_2: 0.9358 - specificity_at_sensitivity_2: 0.9652 - recall_2: 0.6239 - precision_2: 0.9067 - auc_2: 0.8890\n",
            "Epoch 414: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4651 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9371 - specificity_at_sensitivity_2: 0.9441 - recall_2: 0.6792 - precision_2: 0.8640 - auc_2: 0.8773 - val_loss: 0.3915 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9136 - val_precision_2: 0.7872 - val_auc_2: 0.9254\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4441 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9304 - specificity_at_sensitivity_2: 0.9630 - recall_2: 0.8544 - precision_2: 0.7714 - auc_2: 0.8807\n",
            "Epoch 415: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4441 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9304 - specificity_at_sensitivity_2: 0.9630 - recall_2: 0.8544 - precision_2: 0.7714 - auc_2: 0.8807 - val_loss: 0.4033 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9647 - val_specificity_at_sensitivity_2: 0.9867 - val_recall_2: 0.7647 - val_precision_2: 0.9028 - val_auc_2: 0.9080\n",
            "Epoch 416/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4427 - accuracy: 0.7917 - sensitivity_at_specificity_2: 0.9590 - specificity_at_sensitivity_2: 0.9398 - recall_2: 0.6639 - precision_2: 0.8100 - auc_2: 0.8802\n",
            "Epoch 416: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4451 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9552 - specificity_at_sensitivity_2: 0.9355 - recall_2: 0.6493 - precision_2: 0.7909 - auc_2: 0.8763 - val_loss: 0.4099 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9367 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7848 - val_precision_2: 0.8732 - val_auc_2: 0.9023\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4080 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9420 - specificity_at_sensitivity_2: 0.9670 - recall_2: 0.8188 - precision_2: 0.7793 - auc_2: 0.8969\n",
            "Epoch 417: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4080 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9420 - specificity_at_sensitivity_2: 0.9670 - recall_2: 0.8188 - precision_2: 0.7793 - auc_2: 0.8969 - val_loss: 0.3695 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9306 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8472 - val_precision_2: 0.8356 - val_auc_2: 0.9170\n",
            "Epoch 418/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4093 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9271 - specificity_at_sensitivity_2: 0.9500 - recall_2: 0.7188 - precision_2: 0.8415 - auc_2: 0.8827\n",
            "Epoch 418: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4179 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9453 - specificity_at_sensitivity_2: 0.9375 - recall_2: 0.7109 - precision_2: 0.8349 - auc_2: 0.8840 - val_loss: 0.3957 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7500 - val_precision_2: 0.9000 - val_auc_2: 0.9197\n",
            "Epoch 419/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4246 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9492 - specificity_at_sensitivity_2: 0.9710 - recall_2: 0.8136 - precision_2: 0.7619 - auc_2: 0.8884\n",
            "Epoch 419: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4251 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9438 - specificity_at_sensitivity_2: 0.9563 - recall_2: 0.8313 - precision_2: 0.7733 - auc_2: 0.8889 - val_loss: 0.3823 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9268 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8902 - val_precision_2: 0.7935 - val_auc_2: 0.9153\n",
            "Epoch 420/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4171 - accuracy: 0.8348 - sensitivity_at_specificity_2: 0.8876 - specificity_at_sensitivity_2: 0.9630 - recall_2: 0.7416 - precision_2: 0.8250 - auc_2: 0.8769\n",
            "Epoch 420: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4320 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9231 - specificity_at_sensitivity_2: 0.9737 - recall_2: 0.7154 - precision_2: 0.8158 - auc_2: 0.8760 - val_loss: 0.4772 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9545 - val_specificity_at_sensitivity_2: 0.9861 - val_recall_2: 0.6932 - val_precision_2: 0.9385 - val_auc_2: 0.9061\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9467 - specificity_at_sensitivity_2: 0.9706 - recall_2: 0.7800 - precision_2: 0.7905 - auc_2: 0.8831\n",
            "Epoch 421: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4283 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9467 - specificity_at_sensitivity_2: 0.9706 - recall_2: 0.7800 - precision_2: 0.7905 - auc_2: 0.8831 - val_loss: 0.3950 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9861 - val_specificity_at_sensitivity_2: 0.9886 - val_recall_2: 0.9444 - val_precision_2: 0.7391 - val_auc_2: 0.9306\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9506 - specificity_at_sensitivity_2: 0.9241 - recall_2: 0.7778 - precision_2: 0.8129 - auc_2: 0.8744\n",
            "Epoch 422: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4487 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9506 - specificity_at_sensitivity_2: 0.9241 - recall_2: 0.7778 - precision_2: 0.8129 - auc_2: 0.8744 - val_loss: 0.3865 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9545 - val_specificity_at_sensitivity_2: 0.9722 - val_recall_2: 0.8295 - val_precision_2: 0.8690 - val_auc_2: 0.9163\n",
            "Epoch 423/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.3829 - accuracy: 0.8527 - sensitivity_at_specificity_2: 0.9697 - specificity_at_sensitivity_2: 0.9680 - recall_2: 0.8485 - precision_2: 0.8235 - auc_2: 0.9175\n",
            "Epoch 423: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3988 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9660 - specificity_at_sensitivity_2: 0.9711 - recall_2: 0.8095 - precision_2: 0.8207 - auc_2: 0.9067 - val_loss: 0.3508 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9467 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8267 - val_precision_2: 0.8732 - val_auc_2: 0.9247\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4596 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9301 - specificity_at_sensitivity_2: 0.9379 - recall_2: 0.7063 - precision_2: 0.7769 - auc_2: 0.8618\n",
            "Epoch 424: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4596 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9301 - specificity_at_sensitivity_2: 0.9379 - recall_2: 0.7063 - precision_2: 0.7769 - auc_2: 0.8618 - val_loss: 0.4030 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9639 - val_specificity_at_sensitivity_2: 0.9740 - val_recall_2: 0.7711 - val_precision_2: 0.8767 - val_auc_2: 0.9096\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3544 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9853 - specificity_at_sensitivity_2: 0.9891 - recall_2: 0.8162 - precision_2: 0.8473 - auc_2: 0.9294\n",
            "Epoch 425: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3544 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9853 - specificity_at_sensitivity_2: 0.9891 - recall_2: 0.8162 - precision_2: 0.8473 - auc_2: 0.9294 - val_loss: 0.4779 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9036 - val_specificity_at_sensitivity_2: 0.9740 - val_recall_2: 0.7349 - val_precision_2: 0.8472 - val_auc_2: 0.8648\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9366 - specificity_at_sensitivity_2: 0.9775 - recall_2: 0.7535 - precision_2: 0.7926 - auc_2: 0.8922\n",
            "Epoch 426: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4113 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9366 - specificity_at_sensitivity_2: 0.9775 - recall_2: 0.7535 - precision_2: 0.7926 - auc_2: 0.8922 - val_loss: 0.4244 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9103 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.7949 - val_precision_2: 0.8052 - val_auc_2: 0.8885\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4087 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9313 - specificity_at_sensitivity_2: 0.9788 - recall_2: 0.7557 - precision_2: 0.7674 - auc_2: 0.8882\n",
            "Epoch 427: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4087 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9313 - specificity_at_sensitivity_2: 0.9788 - recall_2: 0.7557 - precision_2: 0.7674 - auc_2: 0.8882 - val_loss: 0.4497 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9479 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7500 - val_precision_2: 0.9600 - val_auc_2: 0.9092\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4035 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9677 - specificity_at_sensitivity_2: 0.9636 - recall_2: 0.8129 - precision_2: 0.8235 - auc_2: 0.8993\n",
            "Epoch 428: val_accuracy did not improve from 0.87500\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4035 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9677 - specificity_at_sensitivity_2: 0.9636 - recall_2: 0.8129 - precision_2: 0.8235 - auc_2: 0.8993 - val_loss: 0.3391 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9610 - val_specificity_at_sensitivity_2: 0.9880 - val_recall_2: 0.9091 - val_precision_2: 0.7778 - val_auc_2: 0.9437\n",
            "Epoch 429/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4294 - accuracy: 0.8056 - sensitivity_at_specificity_2: 0.9024 - specificity_at_sensitivity_2: 0.9758 - recall_2: 0.7073 - precision_2: 0.8131 - auc_2: 0.8785\n",
            "Epoch 429: val_accuracy improved from 0.87500 to 0.89375, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.4212 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9203 - specificity_at_sensitivity_2: 0.9725 - recall_2: 0.7101 - precision_2: 0.8235 - auc_2: 0.8872 - val_loss: 0.2992 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_2: 1.0000 - val_specificity_at_sensitivity_2: 0.9868 - val_recall_2: 0.8810 - val_precision_2: 0.9136 - val_auc_2: 0.9605\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4245 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9470 - specificity_at_sensitivity_2: 0.9882 - recall_2: 0.8278 - precision_2: 0.7716 - auc_2: 0.8899\n",
            "Epoch 430: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4245 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9470 - specificity_at_sensitivity_2: 0.9882 - recall_2: 0.8278 - precision_2: 0.7716 - auc_2: 0.8899 - val_loss: 0.3960 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9091 - val_specificity_at_sensitivity_2: 0.9759 - val_recall_2: 0.8182 - val_precision_2: 0.8630 - val_auc_2: 0.8985\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9323 - specificity_at_sensitivity_2: 0.9893 - recall_2: 0.6992 - precision_2: 0.8692 - auc_2: 0.8912\n",
            "Epoch 431: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4071 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9323 - specificity_at_sensitivity_2: 0.9893 - recall_2: 0.6992 - precision_2: 0.8692 - auc_2: 0.8912 - val_loss: 0.3435 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9189 - val_specificity_at_sensitivity_2: 0.9767 - val_recall_2: 0.8108 - val_precision_2: 0.9231 - val_auc_2: 0.9271\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9571 - specificity_at_sensitivity_2: 0.9611 - recall_2: 0.7929 - precision_2: 0.7872 - auc_2: 0.8889\n",
            "Epoch 432: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4221 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9571 - specificity_at_sensitivity_2: 0.9611 - recall_2: 0.7929 - precision_2: 0.7872 - auc_2: 0.8889 - val_loss: 0.4348 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9241 - val_specificity_at_sensitivity_2: 0.9753 - val_recall_2: 0.7215 - val_precision_2: 0.8261 - val_auc_2: 0.8820\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4004 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9740 - recall_2: 0.7188 - precision_2: 0.8519 - auc_2: 0.8980\n",
            "Epoch 433: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4004 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9740 - recall_2: 0.7188 - precision_2: 0.8519 - auc_2: 0.8980 - val_loss: 0.3499 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9452 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7671 - val_precision_2: 0.9655 - val_auc_2: 0.9270\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9673 - specificity_at_sensitivity_2: 0.9701 - recall_2: 0.8562 - precision_2: 0.7844 - auc_2: 0.9019\n",
            "Epoch 434: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4041 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9673 - specificity_at_sensitivity_2: 0.9701 - recall_2: 0.8562 - precision_2: 0.7844 - auc_2: 0.9019 - val_loss: 0.4046 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9405 - val_specificity_at_sensitivity_2: 0.9737 - val_recall_2: 0.7857 - val_precision_2: 0.8462 - val_auc_2: 0.8976\n",
            "Epoch 435/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3928 - accuracy: 0.8477 - sensitivity_at_specificity_2: 0.9683 - specificity_at_sensitivity_2: 0.9769 - recall_2: 0.8095 - precision_2: 0.8718 - auc_2: 0.9074\n",
            "Epoch 435: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.3914 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9737 - specificity_at_sensitivity_2: 0.9702 - recall_2: 0.8092 - precision_2: 0.8662 - auc_2: 0.9079 - val_loss: 0.4042 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9444 - val_specificity_at_sensitivity_2: 0.9886 - val_recall_2: 0.7361 - val_precision_2: 0.9298 - val_auc_2: 0.8969\n",
            "Epoch 436/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4049 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9569 - specificity_at_sensitivity_2: 0.9714 - recall_2: 0.7672 - precision_2: 0.8396 - auc_2: 0.8951\n",
            "Epoch 436: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4101 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9773 - recall_2: 0.7708 - precision_2: 0.8222 - auc_2: 0.8903 - val_loss: 0.4624 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9762 - val_specificity_at_sensitivity_2: 0.9474 - val_recall_2: 0.8333 - val_precision_2: 0.7609 - val_auc_2: 0.8690\n",
            "Epoch 437/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4463 - accuracy: 0.8047 - sensitivity_at_specificity_2: 0.9027 - specificity_at_sensitivity_2: 0.9790 - recall_2: 0.7699 - precision_2: 0.7838 - auc_2: 0.8678\n",
            "Epoch 437: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4471 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9051 - specificity_at_sensitivity_2: 0.9836 - recall_2: 0.7518 - precision_2: 0.7863 - auc_2: 0.8644 - val_loss: 0.4015 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9634 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7927 - val_precision_2: 0.8553 - val_auc_2: 0.9079\n",
            "Epoch 438/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4157 - accuracy: 0.8214 - sensitivity_at_specificity_2: 0.9175 - specificity_at_sensitivity_2: 0.9921 - recall_2: 0.6907 - precision_2: 0.8701 - auc_2: 0.8911\n",
            "Epoch 438: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4063 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9179 - specificity_at_sensitivity_2: 0.9892 - recall_2: 0.7015 - precision_2: 0.8393 - auc_2: 0.8919 - val_loss: 0.3365 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9474 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8421 - val_precision_2: 0.8649 - val_auc_2: 0.9314\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4320 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9333 - specificity_at_sensitivity_2: 0.9676 - recall_2: 0.7778 - precision_2: 0.7778 - auc_2: 0.8789\n",
            "Epoch 439: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4320 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9333 - specificity_at_sensitivity_2: 0.9676 - recall_2: 0.7778 - precision_2: 0.7778 - auc_2: 0.8789 - val_loss: 0.3970 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9556 - val_specificity_at_sensitivity_2: 0.9857 - val_recall_2: 0.7667 - val_precision_2: 0.8846 - val_auc_2: 0.9135\n",
            "Epoch 440/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4549 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9268 - specificity_at_sensitivity_2: 0.9699 - recall_2: 0.6911 - precision_2: 0.8252 - auc_2: 0.8707\n",
            "Epoch 440: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4329 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9257 - specificity_at_sensitivity_2: 0.9709 - recall_2: 0.7297 - precision_2: 0.8060 - auc_2: 0.8814 - val_loss: 0.3995 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9333 - val_specificity_at_sensitivity_2: 0.9765 - val_recall_2: 0.7600 - val_precision_2: 0.8507 - val_auc_2: 0.8989\n",
            "Epoch 441/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3828 - accuracy: 0.8359 - sensitivity_at_specificity_2: 0.9675 - specificity_at_sensitivity_2: 0.9549 - recall_2: 0.7967 - precision_2: 0.8522 - auc_2: 0.9129\n",
            "Epoch 441: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.4021 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9603 - specificity_at_sensitivity_2: 0.9527 - recall_2: 0.7947 - precision_2: 0.8054 - auc_2: 0.9014 - val_loss: 0.4000 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9176 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8118 - val_precision_2: 0.8846 - val_auc_2: 0.9019\n",
            "Epoch 442/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4376 - accuracy: 0.8047 - sensitivity_at_specificity_2: 0.9440 - specificity_at_sensitivity_2: 0.9771 - recall_2: 0.7760 - precision_2: 0.8151 - auc_2: 0.8779\n",
            "Epoch 442: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4567 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9487 - specificity_at_sensitivity_2: 0.9512 - recall_2: 0.7500 - precision_2: 0.7959 - auc_2: 0.8694 - val_loss: 0.4021 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9079 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7632 - val_precision_2: 0.7733 - val_auc_2: 0.8961\n",
            "Epoch 443/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4105 - accuracy: 0.8359 - sensitivity_at_specificity_2: 0.9573 - specificity_at_sensitivity_2: 0.9640 - recall_2: 0.8462 - precision_2: 0.8049 - auc_2: 0.8968\n",
            "Epoch 443: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4080 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9514 - specificity_at_sensitivity_2: 0.9659 - recall_2: 0.8403 - precision_2: 0.8013 - auc_2: 0.8983 - val_loss: 0.4518 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.8800 - val_specificity_at_sensitivity_2: 0.9765 - val_recall_2: 0.7867 - val_precision_2: 0.8082 - val_auc_2: 0.8708\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9517 - specificity_at_sensitivity_2: 0.9600 - recall_2: 0.7310 - precision_2: 0.8833 - auc_2: 0.8966\n",
            "Epoch 444: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4190 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9517 - specificity_at_sensitivity_2: 0.9600 - recall_2: 0.7310 - precision_2: 0.8833 - auc_2: 0.8966 - val_loss: 0.3983 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9324 - val_specificity_at_sensitivity_2: 0.9419 - val_recall_2: 0.7973 - val_precision_2: 0.8429 - val_auc_2: 0.8954\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9624 - specificity_at_sensitivity_2: 0.9733 - recall_2: 0.8647 - precision_2: 0.7667 - auc_2: 0.9181\n",
            "Epoch 445: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3790 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9624 - specificity_at_sensitivity_2: 0.9733 - recall_2: 0.8647 - precision_2: 0.7667 - auc_2: 0.9181 - val_loss: 0.4032 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9211 - val_specificity_at_sensitivity_2: 0.9881 - val_recall_2: 0.7632 - val_precision_2: 0.8056 - val_auc_2: 0.8954\n",
            "Epoch 446/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4380 - accuracy: 0.8160 - sensitivity_at_specificity_2: 0.9338 - specificity_at_sensitivity_2: 0.9474 - recall_2: 0.7279 - precision_2: 0.8609 - auc_2: 0.8829\n",
            "Epoch 446: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4355 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9315 - specificity_at_sensitivity_2: 0.9368 - recall_2: 0.7397 - precision_2: 0.8438 - auc_2: 0.8809 - val_loss: 0.3861 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9481 - val_specificity_at_sensitivity_2: 0.9880 - val_recall_2: 0.8831 - val_precision_2: 0.7473 - val_auc_2: 0.9242\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9545 - specificity_at_sensitivity_2: 0.9894 - recall_2: 0.7652 - precision_2: 0.7594 - auc_2: 0.9017\n",
            "Epoch 447: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.3922 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9545 - specificity_at_sensitivity_2: 0.9894 - recall_2: 0.7652 - precision_2: 0.7594 - auc_2: 0.9017 - val_loss: 0.3805 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9762 - val_specificity_at_sensitivity_2: 0.9868 - val_recall_2: 0.7738 - val_precision_2: 0.9286 - val_auc_2: 0.9281\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9363 - specificity_at_sensitivity_2: 0.9693 - recall_2: 0.8153 - precision_2: 0.7619 - auc_2: 0.8738\n",
            "Epoch 448: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4490 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9363 - specificity_at_sensitivity_2: 0.9693 - recall_2: 0.8153 - precision_2: 0.7619 - auc_2: 0.8738 - val_loss: 0.4038 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9306 - val_specificity_at_sensitivity_2: 0.9773 - val_recall_2: 0.8889 - val_precision_2: 0.7356 - val_auc_2: 0.9149\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4185 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9556 - specificity_at_sensitivity_2: 0.9784 - recall_2: 0.7185 - precision_2: 0.8220 - auc_2: 0.8872\n",
            "Epoch 449: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4185 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9556 - specificity_at_sensitivity_2: 0.9784 - recall_2: 0.7185 - precision_2: 0.8220 - auc_2: 0.8872 - val_loss: 0.3576 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9759 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7952 - val_precision_2: 0.9706 - val_auc_2: 0.9452\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9394 - specificity_at_sensitivity_2: 0.9628 - recall_2: 0.7955 - precision_2: 0.8400 - auc_2: 0.8933\n",
            "Epoch 450: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4150 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9394 - specificity_at_sensitivity_2: 0.9628 - recall_2: 0.7955 - precision_2: 0.8400 - auc_2: 0.8933 - val_loss: 0.3961 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9250 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8250 - val_precision_2: 0.8148 - val_auc_2: 0.8980\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9514 - specificity_at_sensitivity_2: 0.9830 - recall_2: 0.8056 - precision_2: 0.8345 - auc_2: 0.9135\n",
            "Epoch 451: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3707 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9514 - specificity_at_sensitivity_2: 0.9830 - recall_2: 0.8056 - precision_2: 0.8345 - auc_2: 0.9135 - val_loss: 0.3820 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9487 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8077 - val_precision_2: 0.9130 - val_auc_2: 0.9100\n",
            "Epoch 452/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3509 - accuracy: 0.8633 - sensitivity_at_specificity_2: 0.9554 - specificity_at_sensitivity_2: 0.9931 - recall_2: 0.8214 - precision_2: 0.8598 - auc_2: 0.9202\n",
            "Epoch 452: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3619 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9485 - specificity_at_sensitivity_2: 0.9946 - recall_2: 0.8309 - precision_2: 0.8309 - auc_2: 0.9141 - val_loss: 0.3498 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9189 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7838 - val_precision_2: 0.9355 - val_auc_2: 0.9205\n",
            "Epoch 453/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4170 - accuracy: 0.8214 - sensitivity_at_specificity_2: 0.9592 - specificity_at_sensitivity_2: 0.9683 - recall_2: 0.7041 - precision_2: 0.8625 - auc_2: 0.8925\n",
            "Epoch 453: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4182 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9214 - specificity_at_sensitivity_2: 0.9778 - recall_2: 0.7286 - precision_2: 0.8571 - auc_2: 0.8840 - val_loss: 0.3717 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9710 - val_specificity_at_sensitivity_2: 0.9890 - val_recall_2: 0.8551 - val_precision_2: 0.7867 - val_auc_2: 0.9208\n",
            "Epoch 454/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4295 - accuracy: 0.7847 - sensitivity_at_specificity_2: 0.9559 - specificity_at_sensitivity_2: 0.9803 - recall_2: 0.7868 - precision_2: 0.7643 - auc_2: 0.8849\n",
            "Epoch 454: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4196 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9589 - specificity_at_sensitivity_2: 0.9828 - recall_2: 0.7945 - precision_2: 0.7733 - auc_2: 0.8911 - val_loss: 0.4261 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 0.9737 - val_recall_2: 0.7262 - val_precision_2: 0.9242 - val_auc_2: 0.8967\n",
            "Epoch 455/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3885 - accuracy: 0.8203 - sensitivity_at_specificity_2: 0.9661 - specificity_at_sensitivity_2: 0.9855 - recall_2: 0.7373 - precision_2: 0.8529 - auc_2: 0.9146\n",
            "Epoch 455: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.3854 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9603 - specificity_at_sensitivity_2: 0.9822 - recall_2: 0.7550 - precision_2: 0.8769 - auc_2: 0.9186 - val_loss: 0.3870 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9412 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8118 - val_precision_2: 0.8519 - val_auc_2: 0.9065\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3976 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9396 - specificity_at_sensitivity_2: 0.9649 - recall_2: 0.8188 - precision_2: 0.8414 - auc_2: 0.8989\n",
            "Epoch 456: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3976 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9396 - specificity_at_sensitivity_2: 0.9649 - recall_2: 0.8188 - precision_2: 0.8414 - auc_2: 0.8989 - val_loss: 0.3553 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9651 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8023 - val_precision_2: 0.9079 - val_auc_2: 0.9310\n",
            "Epoch 457/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4253 - accuracy: 0.8090 - sensitivity_at_specificity_2: 0.9343 - specificity_at_sensitivity_2: 0.9669 - recall_2: 0.7518 - precision_2: 0.8306 - auc_2: 0.8872\n",
            "Epoch 457: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4242 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9404 - specificity_at_sensitivity_2: 0.9586 - recall_2: 0.7682 - precision_2: 0.8169 - auc_2: 0.8867 - val_loss: 0.4360 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.8974 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.8205 - val_precision_2: 0.7711 - val_auc_2: 0.8806\n",
            "Epoch 458/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4394 - accuracy: 0.8333 - sensitivity_at_specificity_2: 0.9185 - specificity_at_sensitivity_2: 0.9608 - recall_2: 0.8148 - precision_2: 0.8271 - auc_2: 0.8802\n",
            "Epoch 458: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4490 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9079 - specificity_at_sensitivity_2: 0.9643 - recall_2: 0.7961 - precision_2: 0.8345 - auc_2: 0.8730 - val_loss: 0.3340 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9559 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7941 - val_precision_2: 0.8852 - val_auc_2: 0.9330\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9536 - specificity_at_sensitivity_2: 0.9527 - recall_2: 0.8079 - precision_2: 0.7871 - auc_2: 0.8818\n",
            "Epoch 459: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4365 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9536 - specificity_at_sensitivity_2: 0.9527 - recall_2: 0.8079 - precision_2: 0.7871 - auc_2: 0.8818 - val_loss: 0.3774 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8205 - val_precision_2: 0.8649 - val_auc_2: 0.9259\n",
            "Epoch 460/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.3917 - accuracy: 0.8348 - sensitivity_at_specificity_2: 0.9565 - specificity_at_sensitivity_2: 0.9773 - recall_2: 0.7609 - precision_2: 0.8235 - auc_2: 0.9077\n",
            "Epoch 460: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4084 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9496 - specificity_at_sensitivity_2: 0.9779 - recall_2: 0.7410 - precision_2: 0.8175 - auc_2: 0.8974 - val_loss: 0.3830 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9605 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7763 - val_precision_2: 0.8551 - val_auc_2: 0.9129\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4168 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9348 - specificity_at_sensitivity_2: 0.9890 - recall_2: 0.7174 - precision_2: 0.7920 - auc_2: 0.8860\n",
            "Epoch 461: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4168 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9348 - specificity_at_sensitivity_2: 0.9890 - recall_2: 0.7174 - precision_2: 0.7920 - auc_2: 0.8860 - val_loss: 0.3335 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9722 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7778 - val_precision_2: 0.8889 - val_auc_2: 0.9411\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3577 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9704 - specificity_at_sensitivity_2: 0.9730 - recall_2: 0.8074 - precision_2: 0.8450 - auc_2: 0.9231\n",
            "Epoch 462: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.3577 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9704 - specificity_at_sensitivity_2: 0.9730 - recall_2: 0.8074 - precision_2: 0.8450 - auc_2: 0.9231 - val_loss: 0.3527 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9756 - val_specificity_at_sensitivity_2: 0.9744 - val_recall_2: 0.8780 - val_precision_2: 0.8675 - val_auc_2: 0.9229\n",
            "Epoch 463/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3841 - accuracy: 0.8320 - sensitivity_at_specificity_2: 0.9333 - specificity_at_sensitivity_2: 0.9934 - recall_2: 0.8476 - precision_2: 0.7672 - auc_2: 0.9075\n",
            "Epoch 463: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.3887 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9389 - specificity_at_sensitivity_2: 0.9788 - recall_2: 0.8015 - precision_2: 0.7895 - auc_2: 0.9002 - val_loss: 0.4471 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9211 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.6711 - val_precision_2: 0.9273 - val_auc_2: 0.8993\n",
            "Epoch 464/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4175 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9435 - specificity_at_sensitivity_2: 0.9545 - recall_2: 0.8065 - precision_2: 0.8333 - auc_2: 0.8895\n",
            "Epoch 464: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4038 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9497 - specificity_at_sensitivity_2: 0.9565 - recall_2: 0.8302 - precision_2: 0.8462 - auc_2: 0.8969 - val_loss: 0.3379 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9753 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.9383 - val_precision_2: 0.8000 - val_auc_2: 0.9457\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9816 - specificity_at_sensitivity_2: 0.9745 - recall_2: 0.8221 - precision_2: 0.8535 - auc_2: 0.9209\n",
            "Epoch 465: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3633 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9816 - specificity_at_sensitivity_2: 0.9745 - recall_2: 0.8221 - precision_2: 0.8535 - auc_2: 0.9209 - val_loss: 0.4079 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9342 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7895 - val_precision_2: 0.8219 - val_auc_2: 0.8915\n",
            "Epoch 466/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4213 - accuracy: 0.8023 - sensitivity_at_specificity_2: 0.9630 - specificity_at_sensitivity_2: 0.9600 - recall_2: 0.7778 - precision_2: 0.7568 - auc_2: 0.8870\n",
            "Epoch 466: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4198 - accuracy: 0.8069 - sensitivity_at_specificity_2: 0.9412 - specificity_at_sensitivity_2: 0.9591 - recall_2: 0.7563 - precision_2: 0.7692 - auc_2: 0.8843 - val_loss: 0.3668 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9398 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8434 - val_precision_2: 0.9091 - val_auc_2: 0.9218\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9470 - specificity_at_sensitivity_2: 0.9681 - recall_2: 0.7500 - precision_2: 0.7920 - auc_2: 0.8905\n",
            "Epoch 467: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4071 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9470 - specificity_at_sensitivity_2: 0.9681 - recall_2: 0.7500 - precision_2: 0.7920 - auc_2: 0.8905 - val_loss: 0.4019 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9189 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7568 - val_precision_2: 0.8000 - val_auc_2: 0.8942\n",
            "Epoch 468/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.3963 - accuracy: 0.8393 - sensitivity_at_specificity_2: 0.9346 - specificity_at_sensitivity_2: 0.9915 - recall_2: 0.7664 - precision_2: 0.8817 - auc_2: 0.8989\n",
            "Epoch 468: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4052 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9286 - specificity_at_sensitivity_2: 0.9778 - recall_2: 0.7500 - precision_2: 0.8537 - auc_2: 0.8892 - val_loss: 0.3838 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9750 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7250 - val_precision_2: 0.8923 - val_auc_2: 0.9244\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9632 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.7868 - precision_2: 0.8231 - auc_2: 0.9217\n",
            "Epoch 469: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.3633 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9632 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.7868 - precision_2: 0.8231 - auc_2: 0.9217 - val_loss: 0.3636 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9390 - val_specificity_at_sensitivity_2: 0.9872 - val_recall_2: 0.7805 - val_precision_2: 0.9697 - val_auc_2: 0.9283\n",
            "Epoch 470/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4046 - accuracy: 0.7986 - sensitivity_at_specificity_2: 0.9531 - specificity_at_sensitivity_2: 0.9750 - recall_2: 0.7656 - precision_2: 0.7778 - auc_2: 0.8963\n",
            "Epoch 470: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4139 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9459 - specificity_at_sensitivity_2: 0.9767 - recall_2: 0.7703 - precision_2: 0.7972 - auc_2: 0.8915 - val_loss: 0.4307 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.8701 - val_specificity_at_sensitivity_2: 0.9880 - val_recall_2: 0.7403 - val_precision_2: 0.8906 - val_auc_2: 0.8780\n",
            "Epoch 471/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4223 - accuracy: 0.7991 - sensitivity_at_specificity_2: 0.9505 - specificity_at_sensitivity_2: 0.9837 - recall_2: 0.7129 - precision_2: 0.8182 - auc_2: 0.8904\n",
            "Epoch 471: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4147 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9568 - specificity_at_sensitivity_2: 0.9669 - recall_2: 0.7554 - precision_2: 0.7836 - auc_2: 0.8900 - val_loss: 0.4490 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9205 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7273 - val_precision_2: 0.8767 - val_auc_2: 0.8736\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9635 - specificity_at_sensitivity_2: 0.9836 - recall_2: 0.7372 - precision_2: 0.8783 - auc_2: 0.9094\n",
            "Epoch 472: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.3785 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9635 - specificity_at_sensitivity_2: 0.9836 - recall_2: 0.7372 - precision_2: 0.8783 - auc_2: 0.9094 - val_loss: 0.3216 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 1.0000 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8429 - val_precision_2: 0.8939 - val_auc_2: 0.9429\n",
            "Epoch 473/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4322 - accuracy: 0.7991 - sensitivity_at_specificity_2: 0.9231 - specificity_at_sensitivity_2: 0.9917 - recall_2: 0.7308 - precision_2: 0.8172 - auc_2: 0.8736\n",
            "Epoch 473: val_accuracy did not improve from 0.89375\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4142 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9310 - specificity_at_sensitivity_2: 0.9943 - recall_2: 0.7517 - precision_2: 0.8195 - auc_2: 0.8849 - val_loss: 0.3613 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9412 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8000 - val_precision_2: 0.8947 - val_auc_2: 0.9260\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9496 - specificity_at_sensitivity_2: 0.9834 - recall_2: 0.7194 - precision_2: 0.8621 - auc_2: 0.9091\n",
            "Epoch 474: val_accuracy improved from 0.89375 to 0.91250, saving model to ECG_Model_Lead_0.h5\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.3804 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9496 - specificity_at_sensitivity_2: 0.9834 - recall_2: 0.7194 - precision_2: 0.8621 - auc_2: 0.9091 - val_loss: 0.2929 - val_accuracy: 0.9125 - val_sensitivity_at_specificity_2: 0.9759 - val_specificity_at_sensitivity_2: 0.9740 - val_recall_2: 0.9157 - val_precision_2: 0.9157 - val_auc_2: 0.9531\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3793 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9453 - specificity_at_sensitivity_2: 0.9844 - recall_2: 0.8125 - precision_2: 0.8000 - auc_2: 0.9065\n",
            "Epoch 475: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3793 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9453 - specificity_at_sensitivity_2: 0.9844 - recall_2: 0.8125 - precision_2: 0.8000 - auc_2: 0.9065 - val_loss: 0.3916 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9324 - val_specificity_at_sensitivity_2: 0.9884 - val_recall_2: 0.7568 - val_precision_2: 0.9333 - val_auc_2: 0.9125\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9653 - specificity_at_sensitivity_2: 0.9659 - recall_2: 0.7778 - precision_2: 0.7943 - auc_2: 0.9020\n",
            "Epoch 476: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3952 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9653 - specificity_at_sensitivity_2: 0.9659 - recall_2: 0.7778 - precision_2: 0.7943 - auc_2: 0.9020 - val_loss: 0.3169 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_2: 0.9500 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9000 - val_precision_2: 0.8889 - val_auc_2: 0.9383\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4090 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9384 - specificity_at_sensitivity_2: 0.9943 - recall_2: 0.6986 - precision_2: 0.8947 - auc_2: 0.8974\n",
            "Epoch 477: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4090 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9384 - specificity_at_sensitivity_2: 0.9943 - recall_2: 0.6986 - precision_2: 0.8947 - auc_2: 0.8974 - val_loss: 0.3555 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9867 - val_specificity_at_sensitivity_2: 0.9882 - val_recall_2: 0.8533 - val_precision_2: 0.8205 - val_auc_2: 0.9261\n",
            "Epoch 478/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4644 - accuracy: 0.7917 - sensitivity_at_specificity_2: 0.9237 - specificity_at_sensitivity_2: 0.9554 - recall_2: 0.7939 - precision_2: 0.7591 - auc_2: 0.8684\n",
            "Epoch 478: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4581 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9396 - specificity_at_sensitivity_2: 0.9532 - recall_2: 0.7852 - precision_2: 0.7647 - auc_2: 0.8721 - val_loss: 0.4841 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9036 - val_specificity_at_sensitivity_2: 0.9870 - val_recall_2: 0.7229 - val_precision_2: 0.8824 - val_auc_2: 0.8488\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4110 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9592 - specificity_at_sensitivity_2: 0.9653 - recall_2: 0.7347 - precision_2: 0.8372 - auc_2: 0.8975\n",
            "Epoch 479: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4110 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9592 - specificity_at_sensitivity_2: 0.9653 - recall_2: 0.7347 - precision_2: 0.8372 - auc_2: 0.8975 - val_loss: 0.3382 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9425 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8276 - val_precision_2: 0.8889 - val_auc_2: 0.9360\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3694 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9404 - specificity_at_sensitivity_2: 0.9941 - recall_2: 0.8212 - precision_2: 0.8552 - auc_2: 0.9143\n",
            "Epoch 480: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3694 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9404 - specificity_at_sensitivity_2: 0.9941 - recall_2: 0.8212 - precision_2: 0.8552 - auc_2: 0.9143 - val_loss: 0.2814 - val_accuracy: 0.9000 - val_sensitivity_at_specificity_2: 1.0000 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8592 - val_precision_2: 0.9104 - val_auc_2: 0.9616\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4245 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9130 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.7950 - precision_2: 0.8153 - auc_2: 0.8862\n",
            "Epoch 481: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4245 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9130 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.7950 - precision_2: 0.8153 - auc_2: 0.8862 - val_loss: 0.3565 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9663 - val_specificity_at_sensitivity_2: 0.9859 - val_recall_2: 0.8989 - val_precision_2: 0.8511 - val_auc_2: 0.9209\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9549 - specificity_at_sensitivity_2: 0.9679 - recall_2: 0.7970 - precision_2: 0.7970 - auc_2: 0.9018\n",
            "Epoch 482: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.3902 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9549 - specificity_at_sensitivity_2: 0.9679 - recall_2: 0.7970 - precision_2: 0.7970 - auc_2: 0.9018 - val_loss: 0.4302 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9512 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.6585 - val_precision_2: 0.9474 - val_auc_2: 0.9200\n",
            "Epoch 483/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4278 - accuracy: 0.7930 - sensitivity_at_specificity_2: 0.9487 - specificity_at_sensitivity_2: 0.9712 - recall_2: 0.6667 - precision_2: 0.8478 - auc_2: 0.8867\n",
            "Epoch 483: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4268 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9517 - specificity_at_sensitivity_2: 0.9714 - recall_2: 0.6966 - precision_2: 0.8211 - auc_2: 0.8832 - val_loss: 0.4060 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9080 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8621 - val_precision_2: 0.7653 - val_auc_2: 0.9033\n",
            "Epoch 484/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3766 - accuracy: 0.8203 - sensitivity_at_specificity_2: 0.9504 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8099 - precision_2: 0.8099 - auc_2: 0.9128\n",
            "Epoch 484: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.3983 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9367 - specificity_at_sensitivity_2: 0.9877 - recall_2: 0.7785 - precision_2: 0.8255 - auc_2: 0.8985 - val_loss: 0.3706 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9341 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7912 - val_precision_2: 0.8889 - val_auc_2: 0.9197\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9496 - specificity_at_sensitivity_2: 0.9613 - recall_2: 0.7842 - precision_2: 0.7956 - auc_2: 0.8860\n",
            "Epoch 485: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4209 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9496 - specificity_at_sensitivity_2: 0.9613 - recall_2: 0.7842 - precision_2: 0.7956 - auc_2: 0.8860 - val_loss: 0.3961 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9500 - val_specificity_at_sensitivity_2: 0.9750 - val_recall_2: 0.7375 - val_precision_2: 0.9219 - val_auc_2: 0.9197\n",
            "Epoch 486/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4147 - accuracy: 0.8170 - sensitivity_at_specificity_2: 0.9314 - specificity_at_sensitivity_2: 0.9672 - recall_2: 0.7647 - precision_2: 0.8211 - auc_2: 0.8923\n",
            "Epoch 486: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.3877 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9398 - specificity_at_sensitivity_2: 0.9733 - recall_2: 0.7970 - precision_2: 0.7970 - auc_2: 0.9022 - val_loss: 0.3553 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9875 - val_specificity_at_sensitivity_2: 0.9875 - val_recall_2: 0.7625 - val_precision_2: 0.8971 - val_auc_2: 0.9327\n",
            "Epoch 487/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3986 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9612 - specificity_at_sensitivity_2: 0.9673 - recall_2: 0.6602 - precision_2: 0.8831 - auc_2: 0.9035\n",
            "Epoch 487: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4176 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9603 - specificity_at_sensitivity_2: 0.9536 - recall_2: 0.6825 - precision_2: 0.8190 - auc_2: 0.8870 - val_loss: 0.4068 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9390 - val_specificity_at_sensitivity_2: 0.9744 - val_recall_2: 0.7805 - val_precision_2: 0.8421 - val_auc_2: 0.8940\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9236 - specificity_at_sensitivity_2: 0.9632 - recall_2: 0.7962 - precision_2: 0.8389 - auc_2: 0.8892\n",
            "Epoch 488: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4148 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9236 - specificity_at_sensitivity_2: 0.9632 - recall_2: 0.7962 - precision_2: 0.8389 - auc_2: 0.8892 - val_loss: 0.3183 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9873 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8608 - val_precision_2: 0.8500 - val_auc_2: 0.9459\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4032 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9489 - specificity_at_sensitivity_2: 0.9945 - recall_2: 0.7737 - precision_2: 0.7852 - auc_2: 0.8931\n",
            "Epoch 489: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4032 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9489 - specificity_at_sensitivity_2: 0.9945 - recall_2: 0.7737 - precision_2: 0.7852 - auc_2: 0.8931 - val_loss: 0.4290 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9663 - val_specificity_at_sensitivity_2: 0.9859 - val_recall_2: 0.6966 - val_precision_2: 0.9538 - val_auc_2: 0.9240\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9552 - specificity_at_sensitivity_2: 0.9409 - recall_2: 0.7761 - precision_2: 0.7879 - auc_2: 0.8768\n",
            "Epoch 490: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4353 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9552 - specificity_at_sensitivity_2: 0.9409 - recall_2: 0.7761 - precision_2: 0.7879 - auc_2: 0.8768 - val_loss: 0.3523 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9620 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9241 - val_precision_2: 0.8111 - val_auc_2: 0.9359\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9697 - specificity_at_sensitivity_2: 0.9628 - recall_2: 0.7273 - precision_2: 0.8276 - auc_2: 0.8988\n",
            "Epoch 491: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4061 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9697 - specificity_at_sensitivity_2: 0.9628 - recall_2: 0.7273 - precision_2: 0.8276 - auc_2: 0.8988 - val_loss: 0.3748 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9429 - val_specificity_at_sensitivity_2: 0.9778 - val_recall_2: 0.7143 - val_precision_2: 0.9434 - val_auc_2: 0.9268\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9718 - specificity_at_sensitivity_2: 0.9831 - recall_2: 0.7606 - precision_2: 0.8571 - auc_2: 0.9191\n",
            "Epoch 492: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.3626 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9718 - specificity_at_sensitivity_2: 0.9831 - recall_2: 0.7606 - precision_2: 0.8571 - auc_2: 0.9191 - val_loss: 0.4046 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9730 - val_specificity_at_sensitivity_2: 0.9884 - val_recall_2: 0.8243 - val_precision_2: 0.7821 - val_auc_2: 0.8994\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9658 - specificity_at_sensitivity_2: 0.9770 - recall_2: 0.8425 - precision_2: 0.8483 - auc_2: 0.9160\n",
            "Epoch 493: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3653 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9658 - specificity_at_sensitivity_2: 0.9770 - recall_2: 0.8425 - precision_2: 0.8483 - auc_2: 0.9160 - val_loss: 0.3600 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9167 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8095 - val_precision_2: 0.8947 - val_auc_2: 0.9128\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9412 - specificity_at_sensitivity_2: 0.9760 - recall_2: 0.8170 - precision_2: 0.8224 - auc_2: 0.8944\n",
            "Epoch 494: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4052 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9412 - specificity_at_sensitivity_2: 0.9760 - recall_2: 0.8170 - precision_2: 0.8224 - auc_2: 0.8944 - val_loss: 0.3298 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9639 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8313 - val_precision_2: 0.9079 - val_auc_2: 0.9404\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9549 - specificity_at_sensitivity_2: 0.9733 - recall_2: 0.7293 - precision_2: 0.8083 - auc_2: 0.8977\n",
            "Epoch 495: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4008 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9549 - specificity_at_sensitivity_2: 0.9733 - recall_2: 0.7293 - precision_2: 0.8083 - auc_2: 0.8977 - val_loss: 0.3872 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9277 - val_specificity_at_sensitivity_2: 0.9740 - val_recall_2: 0.8193 - val_precision_2: 0.9067 - val_auc_2: 0.9057\n",
            "Epoch 496/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4121 - accuracy: 0.8259 - sensitivity_at_specificity_2: 0.9346 - specificity_at_sensitivity_2: 0.9829 - recall_2: 0.7850 - precision_2: 0.8400 - auc_2: 0.8902\n",
            "Epoch 496: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4187 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9419 - specificity_at_sensitivity_2: 0.9697 - recall_2: 0.8065 - precision_2: 0.8117 - auc_2: 0.8887 - val_loss: 0.4032 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.8977 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7841 - val_precision_2: 0.8734 - val_auc_2: 0.8926\n",
            "Epoch 497/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4041 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9558 - specificity_at_sensitivity_2: 0.9930 - recall_2: 0.7080 - precision_2: 0.8081 - auc_2: 0.8918\n",
            "Epoch 497: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4034 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9366 - specificity_at_sensitivity_2: 0.9944 - recall_2: 0.7113 - precision_2: 0.8211 - auc_2: 0.8907 - val_loss: 0.3171 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9886 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8295 - val_precision_2: 0.9481 - val_auc_2: 0.9534\n",
            "Epoch 498/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4531 - accuracy: 0.8398 - sensitivity_at_specificity_2: 0.9076 - specificity_at_sensitivity_2: 0.9489 - recall_2: 0.7899 - precision_2: 0.8545 - auc_2: 0.8683\n",
            "Epoch 498: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4464 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9097 - specificity_at_sensitivity_2: 0.9455 - recall_2: 0.7935 - precision_2: 0.8601 - auc_2: 0.8728 - val_loss: 0.4077 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9268 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8049 - val_precision_2: 0.7857 - val_auc_2: 0.8910\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4816 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.8733 - specificity_at_sensitivity_2: 0.9529 - recall_2: 0.7133 - precision_2: 0.7810 - auc_2: 0.8435\n",
            "Epoch 499: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4816 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.8733 - specificity_at_sensitivity_2: 0.9529 - recall_2: 0.7133 - precision_2: 0.7810 - auc_2: 0.8435 - val_loss: 0.3859 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9775 - val_specificity_at_sensitivity_2: 0.9859 - val_recall_2: 0.7528 - val_precision_2: 0.9437 - val_auc_2: 0.9381\n",
            "Epoch 500/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4227 - accuracy: 0.8164 - sensitivity_at_specificity_2: 0.9252 - specificity_at_sensitivity_2: 0.9866 - recall_2: 0.7383 - precision_2: 0.8061 - auc_2: 0.8823\n",
            "Epoch 500: val_accuracy did not improve from 0.91250\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4335 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9179 - specificity_at_sensitivity_2: 0.9731 - recall_2: 0.7090 - precision_2: 0.8051 - auc_2: 0.8736 - val_loss: 0.3595 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9625 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7625 - val_precision_2: 0.9385 - val_auc_2: 0.9362\n"
          ]
        }
      ],
      "source": [
        "#Model Execution\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Initializing Device Specification\n",
        "device_spec = tf.DeviceSpec(job =\"localhost\", replica = 0, device_type = \"GPU\")\n",
        "\n",
        "# Printing the DeviceSpec\n",
        "print('Device Spec: ', device_spec.to_string())\n",
        "\n",
        "# Enabling device logging\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "# Specifying the device\n",
        "with tf.device(device_spec):\n",
        "\n",
        "#with tf.device('/gpu:10'):\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\"ECG_Model_Lead_0.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "    mycallback=tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=180, mode=\"auto\")\n",
        "\n",
        "    history = model.fit(\n",
        "          train_data,\n",
        "          steps_per_epoch=10,\n",
        "          epochs=500,\n",
        "          verbose=1,\n",
        "          validation_data = val_data,\n",
        "          validation_steps=5,\n",
        "          callbacks = [mycallback,checkpoint]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDcjZc_f3uD5",
        "outputId": "031abf94-1e83-4cdb-9a72-cb62c57c79c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy:  0.859375\n",
            "Validation Accuracy:  0.9125000238418579\n",
            "Validation Specificity:  1.0\n",
            "Validation Sensitivity:  1.0\n",
            "Validation Recall:  0.9879518151283264\n",
            "Validation Precision:  1.0\n",
            "Validation Loss:  0.28142455220222473\n",
            "Validation AUC:  0.9616236090660095\n"
          ]
        }
      ],
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity_2']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity_2']\n",
        "Validation_Recall=history.history['val_recall_2']\n",
        "Validation_Precision=history.history['val_precision_2']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "Validation_AUC=history.history['val_auc_2']\n",
        "\n",
        "print(\"Training Accuracy: \",np.max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",np.max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",np.max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",np.max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",np.max(Validation_Recall))\n",
        "print(\"Validation Precision: \",np.max(Validation_Precision))\n",
        "print(\"Validation Loss: \",np.min(Validation_Loss))\n",
        "print(\"Validation AUC: \",np.max(Validation_AUC))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTZWiq8Q3uD5",
        "outputId": "b2227769-3afb-4152-854b-606233280c52"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to compute moving average\n",
        "def moving_average(data, window_size):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "# Smoothed accuracy values\n",
        "smoothed_train_acc = moving_average(history.history['accuracy'], window_size=5)\n",
        "smoothed_val_acc = moving_average(history.history['val_accuracy'], window_size=5)\n",
        "\n",
        "# Plotting the smoothed training accuracy and validation accuracy\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(smoothed_train_acc, label='Train', linewidth=2)\n",
        "plt.plot(smoothed_val_acc, label='Validate', linewidth=2)\n",
        "\n",
        "# Set the font size for tick labels, legend, and axis labels\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.legend(fontsize=18)\n",
        "\n",
        "# Set axis labels and title with larger font size\n",
        "plt.title('Model Accuracy', fontsize=17)\n",
        "plt.xlabel('Epoch', fontsize=17)\n",
        "plt.ylabel('Accuracy', fontsize=17)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtBYTRky3uD5",
        "outputId": "5567075b-0503-46e8-d826-0886fb895e67"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to compute moving average\n",
        "def moving_average(data, window_size):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "# Smoothed accuracy values\n",
        "smoothed_train_acc = moving_average(history.history['loss'], window_size=5)\n",
        "smoothed_val_acc = moving_average(history.history['val_loss'], window_size=5)\n",
        "\n",
        "# Plotting the smoothed training accuracy and validation accuracy\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(smoothed_train_acc, label='Train', linewidth=2)\n",
        "plt.plot(smoothed_val_acc, label='Validate', linewidth=2)\n",
        "\n",
        "# Set the font size for tick labels, legend, and axis labels\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.legend(fontsize=18)\n",
        "\n",
        "# Set axis labels and title with larger font size\n",
        "plt.title('Model Loss', fontsize=17)\n",
        "plt.xlabel('Epoch', fontsize=17)\n",
        "plt.ylabel('Accuracy', fontsize=17)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "DYvThcZf3uD5",
        "outputId": "2397686e-4c0c-4ca6-9844-f345c6538920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 134ms/step\n",
            "predicted_class 0, _ 0.18566015362739563\n",
            "File: A0271.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.048706889152526855\n",
            "File: A0274.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.05183819308876991\n",
            "File: A0217.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.05930867791175842\n",
            "File: A0231.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.06789398193359375\n",
            "File: A0019.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.06983386725187302\n",
            "File: A0222.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.03363819792866707\n",
            "File: A0109.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.455264151096344\n",
            "File: A0071.npy, Actual Label: 0, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.1477554589509964\n",
            "File: A0272.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.093429796397686\n",
            "File: A0290.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.08216942846775055\n",
            "File: A0086.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 0, _ 0.013126786798238754\n",
            "File: A0153.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.06736263632774353\n",
            "File: A0260.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.027545830234885216\n",
            "File: A0003.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.04877638444304466\n",
            "File: A0150.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.14580696821212769\n",
            "File: A0122.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.010538185946643353\n",
            "File: A0126.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.8381773233413696\n",
            "File: A0121.npy, Actual Label: 0, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.04187345132231712\n",
            "File: A0186.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.4771324694156647\n",
            "File: A0198.npy, Actual Label: 0, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5047614574432373\n",
            "File: A0145.npy, Actual Label: 0, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 0, _ 0.11507370322942734\n",
            "File: A0101.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6033084988594055\n",
            "File: A0235.npy, Actual Label: 0, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.12488611042499542\n",
            "File: A0117.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.07873287051916122\n",
            "File: A0184.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.11840706318616867\n",
            "File: A0203.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.05647439509630203\n",
            "File: A0017.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.015338396653532982\n",
            "File: A0205.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.045162003487348557\n",
            "File: A0257.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.04345428943634033\n",
            "File: A0247.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.38960275053977966\n",
            "File: A0061.npy, Actual Label: 0, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.03832755610346794\n",
            "File: A0023.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.06854882836341858\n",
            "File: A0279.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.09470506757497787\n",
            "File: A0214.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2652754485607147\n",
            "File: A0009.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.08854828774929047\n",
            "File: A0026.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.029791027307510376\n",
            "File: A0007.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.07403553277254105\n",
            "File: A0064.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.05559348687529564\n",
            "File: A0220.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.0631101131439209\n",
            "File: A0267.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.12637224793434143\n",
            "File: A0276.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.0237153097987175\n",
            "File: A0065.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.06163644790649414\n",
            "File: A0004.npy, Actual Label: 0, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.8541937470436096\n",
            "File: A0179.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.2831772565841675\n",
            "File: A0264.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 0, _ 0.09538552165031433\n",
            "File: A0285.npy, Actual Label: 1, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.7144485116004944\n",
            "File: A0175.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.6006534099578857\n",
            "File: A0164.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.5925944447517395\n",
            "File: A0254.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.32310736179351807\n",
            "File: A0029.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.2828071415424347\n",
            "File: A0281.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.8374292850494385\n",
            "File: A0075.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.5072791576385498\n",
            "File: A0002.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.7059369683265686\n",
            "File: A0166.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.8639937043190002\n",
            "File: A0037.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.8029839396476746\n",
            "File: A0189.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.4051402509212494\n",
            "File: A0283.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.8228918313980103\n",
            "File: A0208.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.5262205600738525\n",
            "File: A0233.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 0, _ 0.028403999283909798\n",
            "File: A0176.npy, Actual Label: 1, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.6817488074302673\n",
            "File: A0143.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.8791412711143494\n",
            "File: A0177.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 0, _ 0.25632792711257935\n",
            "File: A0094.npy, Actual Label: 1, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.33793023228645325\n",
            "File: A0107.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 0, _ 0.07802055776119232\n",
            "File: A0229.npy, Actual Label: 1, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.5202429890632629\n",
            "File: A0141.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.709637463092804\n",
            "File: A0287.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.8200439214706421\n",
            "File: A0073.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.8025039434432983\n",
            "File: A0059.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.7103089094161987\n",
            "File: A0173.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "predicted_class 1, _ 0.7946372032165527\n",
            "File: A0133.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 0, _ 0.14454129338264465\n",
            "File: A0090.npy, Actual Label: 1, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.31598636507987976\n",
            "File: A0125.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 0, _ 0.0891345962882042\n",
            "File: A0089.npy, Actual Label: 1, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.7663949131965637\n",
            "File: A0041.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.3049849271774292\n",
            "File: A0020.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.39461955428123474\n",
            "File: A0030.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.49484801292419434\n",
            "File: A0190.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.8001683354377747\n",
            "File: A0192.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.34473398327827454\n",
            "File: A0206.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.7932243943214417\n",
            "File: A0157.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.8701176643371582\n",
            "File: A0016.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.9196131229400635\n",
            "File: A0193.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 0, _ 0.20109733939170837\n",
            "File: A0221.npy, Actual Label: 1, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.8508360385894775\n",
            "File: A0038.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.09625741094350815\n",
            "File: A0149.npy, Actual Label: 1, Predicted Label: 0\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.5136334300041199\n",
            "File: A0170.npy, Actual Label: 1, Predicted Label: 1\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.17844711244106293\n",
            "File: A0210.npy, Actual Label: 1, Predicted Label: 0\n",
            "True labels:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "pred labels:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "\n",
            "Overall Accuracy: 82.95%\n",
            "AUC: 0.8302325581395349\n",
            "Misclassifications:\n",
            "Class 0: 6 misclassifications\n",
            "Class 1: 9 misclassifications\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Proposed Testing Architecture\n",
        "\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "import shutil\n",
        "import scipy\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Normalization layer\n",
        "nrmzln_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "def create_image(file_path, save_dir):\n",
        "    # Load file\n",
        "    x = np.load(file_path)\n",
        "\n",
        "    x= x[0][:5000]\n",
        "    #x_size=np.array(x).flatten()\n",
        "\n",
        "    if len(x) < 5000:\n",
        "        print(f\"Skipping file: {file_path} due to insufficient length.\")\n",
        "        return\n",
        "\n",
        "    #sub_signal = signal[start_idx:end_idx]\n",
        "    #normalized_array = (sub_signal / max(sub_signal)).clip(-1, 1)\n",
        "\n",
        "    plt.figure(figsize=(1.60, 1.62))\n",
        "    plt.plot(x, 'gray')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    sub_image_path = os.path.join(save_dir, f\"{1}.png\")\n",
        "    plt.savefig(sub_image_path, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "#Image Processing and Classification by the Proposed CNN Model\n",
        "def load_image(img_path, target_size=(124, 124)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "\n",
        "    img_tensor = image.img_to_array(img)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "    nrmzln_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
        "    img_tensor = nrmzln_layer(img_tensor)\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "def predict_class(model, img_path, threshold=0.28): #0.28 with ECG_Model_Lead_0_1d_cnn_0dot28 --> 82.95% acc. #misclassifications: 9 normal, 6 disease\n",
        "\n",
        "    img_tensor = load_image(img_path)\n",
        "    pred = model.predict(img_tensor)\n",
        "    return 1 if pred >= threshold else 0, pred[0][0]\n",
        "\n",
        "def evaluate_test_folder(model, test_folder):\n",
        "    class_labels = sorted(os.listdir(test_folder))\n",
        "    total_samples = 0\n",
        "    correct_predictions = 0\n",
        "    misclassifications = {0: 0, 1: 0}\n",
        "    skipped_files = []\n",
        "    true_labels = []\n",
        "    predicted_probabilities = []\n",
        "\n",
        "    for class_label in class_labels:\n",
        "        class_path = os.path.join(test_folder, class_label)\n",
        "        for npy_file in os.listdir(class_path):\n",
        "            npy_path = os.path.join(class_path, npy_file)\n",
        "\n",
        "            # Create three sub-images using create_image function\n",
        "            save_dir = \"path_to/temp_images/\"\n",
        "            create_image(npy_path, save_dir)\n",
        "\n",
        "            for i in range(1, 2):\n",
        "                sub_image_path = os.path.join(save_dir, f\"{i}.png\")\n",
        "                predicted_class, _ = predict_class(model, sub_image_path)\n",
        "                print(f\"predicted_class {predicted_class}, _ {_}\")\n",
        "\n",
        "            # Get true class label based on folder name\n",
        "            true_class = 0 if class_label == 'disease' else 1\n",
        "\n",
        "            # Print details for each file\n",
        "            print(f\"File: {npy_file}, Actual Label: {true_class}, Predicted Label: {predicted_class}\")\n",
        "\n",
        "            # Print details for each image\n",
        "            #print(f\"Image: {image_file}, Actual Label: {true_class}, Predicted Label: {predicted_class}, Prediction Value: {prediction_value}\")\n",
        "\n",
        "            # Update metrics\n",
        "            total_samples += 1\n",
        "            correct_predictions += 1 if predicted_class == true_class else 0\n",
        "            true_labels.append(true_class)\n",
        "            predicted_probabilities.append(predicted_class)\n",
        "\n",
        "            # Track misclassifications\n",
        "            if predicted_class != true_class:\n",
        "                misclassifications[true_class] += 1\n",
        "\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    auc = roc_auc_score(true_labels, predicted_probabilities)\n",
        "\n",
        "    print(\"True labels: \",true_labels)\n",
        "    print(\"pred labels: \",predicted_probabilities)\n",
        "    print(f\"\\nOverall Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"AUC: {auc}\")\n",
        "    print(\"Misclassifications:\")\n",
        "    for class_label, count in misclassifications.items():\n",
        "        print(f\"Class {class_label}: {count} misclassifications\")\n",
        "\n",
        "    if skipped_files:\n",
        "        print(\"\\nSkipped Files:\")\n",
        "        for skipped_file in skipped_files:\n",
        "            print(skipped_file)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_probabilities)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['disease', 'normal'])\n",
        "    disp.plot(cmap='OrRd', values_format='d', ax=plt.gca(), colorbar=False)\n",
        "    #plt.title(\"Confusion Matrix\", fontsize=16)\n",
        "    plt.xlabel(\"Predicted Labels\", fontsize=14)\n",
        "    plt.ylabel(\"True Labels\", fontsize=14)\n",
        "    plt.xticks(fontsize=13)\n",
        "    plt.yticks(fontsize=13)\n",
        "\n",
        "    # Increase font size for the sample counts inside the matrix\n",
        "    for text in disp.text_.ravel():\n",
        "        text.set_fontsize(14)\n",
        "\n",
        "    # Save the confusion matrix plot\n",
        "    plt.savefig(\"path_to/confusion_matrix_lead_1.png\", dpi=800, bbox_inches='tight')\n",
        "\n",
        "    # Clean up temporary images\n",
        "    files = glob.glob(r'path_to/folder/temp_images/*')\n",
        "    for items in files:\n",
        "        os.remove(items)\n",
        "\n",
        "# Load the model\n",
        "model_path = \"path_to/model/ECG_Model_Lead_0.h5\"\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Test folder path\n",
        "test_folder_path = 'path_to/test_folder/'\n",
        "\n",
        "# Evaluate the test folder\n",
        "evaluate_test_folder(model, test_folder_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}