{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "wTRUUS7f2UaH",
        "outputId": "18edb16a-0ce4-4e1d-9f06-09d22e034149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.0\n"
          ]
        }
      ],
      "source": [
        "#Tensorflow version\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "0lkVSw682UaH"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Conv2D, Dense, Flatten, BatchNormalization, Dropout, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.efficientnet import EfficientNetB0\n",
        "from keras.preprocessing import image\n",
        "#from keras.preprocessing.image import load_img\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK3l-nBR2UaI"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "uaAat16z2UaI"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join('path_to/dataset/training/')\n",
        "validation_dir = os.path.join('path_to/dataset/validation/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "8KbREKkg2UaI",
        "outputId": "ba7119bb-590e-40bb-a5b5-60096f9bc9c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8514 images belonging to 2 classes.\n",
            "Found 1500 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(124, 124),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    )\n",
        "\n",
        "val_data = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(124,124),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOgIt1Dv2UaI"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "    # First convolution layer\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(124, 124, 3),use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Second convolution layer\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "\n",
        "    # Third convolution layer\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Fourth convolution layer\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(96, activation='relu',use_bias=True),\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=regularizers.L1(0.001))\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "iPnCdAvR2UaI",
        "outputId": "67840fc0-e5eb-4059-fc57-373d6a78f425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 124, 122, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 62, 61, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 62, 59, 64)        6208      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 31, 29, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 31, 27, 128)       24704     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 13, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 15, 11, 128)       49280     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 5, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 7, 5, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4480)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4480)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 96)                430176    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 97        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 510,785\n",
            "Trainable params: 510,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#print model summary\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "-h73bqWN2UaI"
      },
      "outputs": [],
      "source": [
        "#Performance evaluation Metrics delcaration\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adamax,Nadam, Ftrl, Adadelta\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision, AUC\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0001),  #Adamax, 3e-4\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5), AUC(num_thresholds=200,curve='ROC')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "QAK-x9-S2UaI"
      },
      "outputs": [],
      "source": [
        "class mycallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('val_accuracy')>0.99):\n",
        "            print(\"\\n Reached 99% accuracy so cancelling training!\")\n",
        "            self.model.stop_training=True\n",
        "\n",
        "mycallback=mycallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "cIrN3l6p2UaJ",
        "outputId": "0c1157e4-8433-4ec8-e1a8-c6b362970cb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device Spec:  /job:localhost/replica:0/device:GPU:*\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5312 - sensitivity_at_specificity_2: 0.5033 - specificity_at_sensitivity_2: 0.5150 - recall_2: 0.4183 - precision_2: 0.5120 - auc_2: 0.5180\n",
            "Epoch 1: val_accuracy improved from -inf to 0.43750, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 2s 107ms/step - loss: 0.6936 - accuracy: 0.5312 - sensitivity_at_specificity_2: 0.5033 - specificity_at_sensitivity_2: 0.5150 - recall_2: 0.4183 - precision_2: 0.5120 - auc_2: 0.5180 - val_loss: 0.6969 - val_accuracy: 0.4375 - val_sensitivity_at_specificity_2: 0.0222 - val_specificity_at_sensitivity_2: 0.4286 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.5054\n",
            "Epoch 2/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6965 - accuracy: 0.5347 - sensitivity_at_specificity_2: 0.5188 - specificity_at_sensitivity_2: 0.5097 - recall_2: 0.3308 - precision_2: 0.4944 - auc_2: 0.5073\n",
            "Epoch 2: val_accuracy improved from 0.43750 to 0.48750, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.6973 - accuracy: 0.5344 - sensitivity_at_specificity_2: 0.5000 - specificity_at_sensitivity_2: 0.5058 - recall_2: 0.3243 - precision_2: 0.4948 - auc_2: 0.4997 - val_loss: 0.6966 - val_accuracy: 0.4875 - val_sensitivity_at_specificity_2: 0.0366 - val_specificity_at_sensitivity_2: 0.2692 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4882\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7018 - accuracy: 0.5094 - sensitivity_at_specificity_2: 0.4815 - specificity_at_sensitivity_2: 0.4937 - recall_2: 0.5926 - precision_2: 0.5134 - auc_2: 0.4999\n",
            "Epoch 3: val_accuracy did not improve from 0.48750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.7018 - accuracy: 0.5094 - sensitivity_at_specificity_2: 0.4815 - specificity_at_sensitivity_2: 0.4937 - recall_2: 0.5926 - precision_2: 0.5134 - auc_2: 0.4999 - val_loss: 0.6949 - val_accuracy: 0.4875 - val_sensitivity_at_specificity_2: 0.0385 - val_specificity_at_sensitivity_2: 0.2927 - val_recall_2: 1.0000 - val_precision_2: 0.4875 - val_auc_2: 0.5061\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7046 - accuracy: 0.5500 - sensitivity_at_specificity_2: 0.3729 - specificity_at_sensitivity_2: 0.3916 - recall_2: 0.8531 - precision_2: 0.5613 - auc_2: 0.4498\n",
            "Epoch 4: val_accuracy did not improve from 0.48750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.7046 - accuracy: 0.5500 - sensitivity_at_specificity_2: 0.3729 - specificity_at_sensitivity_2: 0.3916 - recall_2: 0.8531 - precision_2: 0.5613 - auc_2: 0.4498 - val_loss: 0.7029 - val_accuracy: 0.4688 - val_sensitivity_at_specificity_2: 0.5333 - val_specificity_at_sensitivity_2: 0.5412 - val_recall_2: 1.0000 - val_precision_2: 0.4688 - val_auc_2: 0.5502\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7013 - accuracy: 0.5031 - sensitivity_at_specificity_2: 0.5190 - specificity_at_sensitivity_2: 0.5062 - recall_2: 0.6709 - precision_2: 0.4977 - auc_2: 0.5167\n",
            "Epoch 5: val_accuracy improved from 0.48750 to 0.53750, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.7013 - accuracy: 0.5031 - sensitivity_at_specificity_2: 0.5190 - specificity_at_sensitivity_2: 0.5062 - recall_2: 0.6709 - precision_2: 0.4977 - auc_2: 0.5167 - val_loss: 0.6913 - val_accuracy: 0.5375 - val_sensitivity_at_specificity_2: 0.2027 - val_specificity_at_sensitivity_2: 0.1395 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.5396\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.5031 - sensitivity_at_specificity_2: 0.4161 - specificity_at_sensitivity_2: 0.4591 - recall_2: 0.2236 - precision_2: 0.5143 - auc_2: 0.4783\n",
            "Epoch 6: val_accuracy did not improve from 0.53750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.7014 - accuracy: 0.5031 - sensitivity_at_specificity_2: 0.4161 - specificity_at_sensitivity_2: 0.4591 - recall_2: 0.2236 - precision_2: 0.5143 - auc_2: 0.4783 - val_loss: 0.6914 - val_accuracy: 0.5312 - val_sensitivity_at_specificity_2: 0.6353 - val_specificity_at_sensitivity_2: 0.5200 - val_recall_2: 1.0000 - val_precision_2: 0.5312 - val_auc_2: 0.5847\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6966 - accuracy: 0.4906 - sensitivity_at_specificity_2: 0.5096 - specificity_at_sensitivity_2: 0.5092 - recall_2: 0.5987 - precision_2: 0.4845 - auc_2: 0.5007\n",
            "Epoch 7: val_accuracy improved from 0.53750 to 0.54375, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6966 - accuracy: 0.4906 - sensitivity_at_specificity_2: 0.5096 - specificity_at_sensitivity_2: 0.5092 - recall_2: 0.5987 - precision_2: 0.4845 - auc_2: 0.5007 - val_loss: 0.6909 - val_accuracy: 0.5437 - val_sensitivity_at_specificity_2: 0.3448 - val_specificity_at_sensitivity_2: 0.0411 - val_recall_2: 1.0000 - val_precision_2: 0.5437 - val_auc_2: 0.5205\n",
            "Epoch 8/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6905 - accuracy: 0.5243 - sensitivity_at_specificity_2: 0.5655 - specificity_at_sensitivity_2: 0.5594 - recall_2: 0.6414 - precision_2: 0.5225 - auc_2: 0.5428\n",
            "Epoch 8: val_accuracy improved from 0.54375 to 0.58125, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.6891 - accuracy: 0.5219 - sensitivity_at_specificity_2: 0.5569 - specificity_at_sensitivity_2: 0.5621 - recall_2: 0.6287 - precision_2: 0.5357 - auc_2: 0.5461 - val_loss: 0.6868 - val_accuracy: 0.5813 - val_sensitivity_at_specificity_2: 0.5376 - val_specificity_at_sensitivity_2: 0.7910 - val_recall_2: 1.0000 - val_precision_2: 0.5813 - val_auc_2: 0.6809\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.5219 - sensitivity_at_specificity_2: 0.5067 - specificity_at_sensitivity_2: 0.5176 - recall_2: 0.7200 - precision_2: 0.4932 - auc_2: 0.5295\n",
            "Epoch 9: val_accuracy did not improve from 0.58125\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6942 - accuracy: 0.5219 - sensitivity_at_specificity_2: 0.5067 - specificity_at_sensitivity_2: 0.5176 - recall_2: 0.7200 - precision_2: 0.4932 - auc_2: 0.5295 - val_loss: 0.6917 - val_accuracy: 0.5562 - val_sensitivity_at_specificity_2: 0.1529 - val_specificity_at_sensitivity_2: 0.3067 - val_recall_2: 0.9882 - val_precision_2: 0.5455 - val_auc_2: 0.6415\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.5688 - sensitivity_at_specificity_2: 0.5665 - specificity_at_sensitivity_2: 0.5374 - recall_2: 0.6763 - precision_2: 0.5879 - auc_2: 0.5546\n",
            "Epoch 10: val_accuracy did not improve from 0.58125\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.6893 - accuracy: 0.5688 - sensitivity_at_specificity_2: 0.5665 - specificity_at_sensitivity_2: 0.5374 - recall_2: 0.6763 - precision_2: 0.5879 - auc_2: 0.5546 - val_loss: 0.6956 - val_accuracy: 0.4750 - val_sensitivity_at_specificity_2: 0.0526 - val_specificity_at_sensitivity_2: 0.2857 - val_recall_2: 1.0000 - val_precision_2: 0.4750 - val_auc_2: 0.5470\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.5281 - sensitivity_at_specificity_2: 0.5466 - specificity_at_sensitivity_2: 0.5912 - recall_2: 0.9006 - precision_2: 0.5179 - auc_2: 0.5604\n",
            "Epoch 11: val_accuracy did not improve from 0.58125\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.6906 - accuracy: 0.5281 - sensitivity_at_specificity_2: 0.5466 - specificity_at_sensitivity_2: 0.5912 - recall_2: 0.9006 - precision_2: 0.5179 - auc_2: 0.5604 - val_loss: 0.6940 - val_accuracy: 0.4625 - val_sensitivity_at_specificity_2: 0.1351 - val_specificity_at_sensitivity_2: 0.3837 - val_recall_2: 1.0000 - val_precision_2: 0.4625 - val_auc_2: 0.6637\n",
            "Epoch 12/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6949 - accuracy: 0.5382 - sensitivity_at_specificity_2: 0.5734 - specificity_at_sensitivity_2: 0.5034 - recall_2: 0.6154 - precision_2: 0.5301 - auc_2: 0.5227\n",
            "Epoch 12: val_accuracy improved from 0.58125 to 0.68125, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.6967 - accuracy: 0.5250 - sensitivity_at_specificity_2: 0.4596 - specificity_at_sensitivity_2: 0.4906 - recall_2: 0.5963 - precision_2: 0.5246 - auc_2: 0.5068 - val_loss: 0.6905 - val_accuracy: 0.6812 - val_sensitivity_at_specificity_2: 0.4474 - val_specificity_at_sensitivity_2: 0.3452 - val_recall_2: 0.8553 - val_precision_2: 0.6190 - val_auc_2: 0.7205\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.5219 - sensitivity_at_specificity_2: 0.4247 - specificity_at_sensitivity_2: 0.4310 - recall_2: 0.2466 - precision_2: 0.4557 - auc_2: 0.4876\n",
            "Epoch 13: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6958 - accuracy: 0.5219 - sensitivity_at_specificity_2: 0.4247 - specificity_at_sensitivity_2: 0.4310 - recall_2: 0.2466 - precision_2: 0.4557 - auc_2: 0.4876 - val_loss: 0.6897 - val_accuracy: 0.5312 - val_sensitivity_at_specificity_2: 0.1867 - val_specificity_at_sensitivity_2: 0.4353 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.6900\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.5281 - sensitivity_at_specificity_2: 0.4877 - specificity_at_sensitivity_2: 0.4937 - recall_2: 0.3395 - precision_2: 0.5556 - auc_2: 0.5405\n",
            "Epoch 14: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6920 - accuracy: 0.5281 - sensitivity_at_specificity_2: 0.4877 - specificity_at_sensitivity_2: 0.4937 - recall_2: 0.3395 - precision_2: 0.5556 - auc_2: 0.5405 - val_loss: 0.6866 - val_accuracy: 0.5625 - val_sensitivity_at_specificity_2: 0.7444 - val_specificity_at_sensitivity_2: 0.6571 - val_recall_2: 1.0000 - val_precision_2: 0.5625 - val_auc_2: 0.7381\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7035 - accuracy: 0.5000 - sensitivity_at_specificity_2: 0.4507 - specificity_at_sensitivity_2: 0.4865 - recall_2: 0.9155 - precision_2: 0.4943 - auc_2: 0.4921\n",
            "Epoch 15: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.7035 - accuracy: 0.5000 - sensitivity_at_specificity_2: 0.4507 - specificity_at_sensitivity_2: 0.4865 - recall_2: 0.9155 - precision_2: 0.4943 - auc_2: 0.4921 - val_loss: 0.6902 - val_accuracy: 0.6313 - val_sensitivity_at_specificity_2: 0.1975 - val_specificity_at_sensitivity_2: 0.4684 - val_recall_2: 0.9877 - val_precision_2: 0.5797 - val_auc_2: 0.7230\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7117 - accuracy: 0.4906 - sensitivity_at_specificity_2: 0.3861 - specificity_at_sensitivity_2: 0.3580 - recall_2: 0.0570 - precision_2: 0.3913 - auc_2: 0.4392\n",
            "Epoch 16: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.7117 - accuracy: 0.4906 - sensitivity_at_specificity_2: 0.3861 - specificity_at_sensitivity_2: 0.3580 - recall_2: 0.0570 - precision_2: 0.3913 - auc_2: 0.4392 - val_loss: 0.6914 - val_accuracy: 0.5250 - val_sensitivity_at_specificity_2: 0.2632 - val_specificity_at_sensitivity_2: 0.0714 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.5793\n",
            "Epoch 17/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6974 - accuracy: 0.5208 - sensitivity_at_specificity_2: 0.4583 - specificity_at_sensitivity_2: 0.4861 - recall_2: 0.2431 - precision_2: 0.5469 - auc_2: 0.4928      \n",
            "Epoch 17: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.6992 - accuracy: 0.5000 - sensitivity_at_specificity_2: 0.4140 - specificity_at_sensitivity_2: 0.4294 - recall_2: 0.2675 - precision_2: 0.4828 - auc_2: 0.4696 - val_loss: 0.6938 - val_accuracy: 0.4625 - val_sensitivity_at_specificity_2: 0.2740 - val_specificity_at_sensitivity_2: 0.0920 - val_recall_2: 1.0000 - val_precision_2: 0.4591 - val_auc_2: 0.5382\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.5125 - sensitivity_at_specificity_2: 0.4583 - specificity_at_sensitivity_2: 0.4545 - recall_2: 0.4097 - precision_2: 0.4538 - auc_2: 0.4930\n",
            "Epoch 18: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6951 - accuracy: 0.5125 - sensitivity_at_specificity_2: 0.4583 - specificity_at_sensitivity_2: 0.4545 - recall_2: 0.4097 - precision_2: 0.4538 - auc_2: 0.4930 - val_loss: 0.6932 - val_accuracy: 0.4812 - val_sensitivity_at_specificity_2: 0.0595 - val_specificity_at_sensitivity_2: 0.2237 - val_recall_2: 0.0119 - val_precision_2: 1.0000 - val_auc_2: 0.5928\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5312 - sensitivity_at_specificity_2: 0.4570 - specificity_at_sensitivity_2: 0.3550 - recall_2: 0.2053 - precision_2: 0.5082 - auc_2: 0.4970\n",
            "Epoch 19: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6939 - accuracy: 0.5312 - sensitivity_at_specificity_2: 0.4570 - specificity_at_sensitivity_2: 0.3550 - recall_2: 0.2053 - precision_2: 0.5082 - auc_2: 0.4970 - val_loss: 0.6902 - val_accuracy: 0.5875 - val_sensitivity_at_specificity_2: 0.0152 - val_specificity_at_sensitivity_2: 0.3511 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.6451\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.5156 - sensitivity_at_specificity_2: 0.4702 - specificity_at_sensitivity_2: 0.4737 - recall_2: 0.3393 - precision_2: 0.5644 - auc_2: 0.5480\n",
            "Epoch 20: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6923 - accuracy: 0.5156 - sensitivity_at_specificity_2: 0.4702 - specificity_at_sensitivity_2: 0.4737 - recall_2: 0.3393 - precision_2: 0.5644 - auc_2: 0.5480 - val_loss: 0.6917 - val_accuracy: 0.5750 - val_sensitivity_at_specificity_2: 0.8846 - val_specificity_at_sensitivity_2: 0.5488 - val_recall_2: 1.0000 - val_precision_2: 0.5342 - val_auc_2: 0.7210\n",
            "Epoch 21/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6908 - accuracy: 0.5799 - sensitivity_at_specificity_2: 0.6159 - specificity_at_sensitivity_2: 0.6200 - recall_2: 0.5797 - precision_2: 0.5594 - auc_2: 0.5623\n",
            "Epoch 21: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.6910 - accuracy: 0.5750 - sensitivity_at_specificity_2: 0.6000 - specificity_at_sensitivity_2: 0.6176 - recall_2: 0.5667 - precision_2: 0.5449 - auc_2: 0.5598 - val_loss: 0.6911 - val_accuracy: 0.6250 - val_sensitivity_at_specificity_2: 0.8276 - val_specificity_at_sensitivity_2: 0.6986 - val_recall_2: 0.9885 - val_precision_2: 0.5931 - val_auc_2: 0.7690\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.5031 - sensitivity_at_specificity_2: 0.5000 - specificity_at_sensitivity_2: 0.5724 - recall_2: 0.3452 - precision_2: 0.5421 - auc_2: 0.5369\n",
            "Epoch 22: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6930 - accuracy: 0.5031 - sensitivity_at_specificity_2: 0.5000 - specificity_at_sensitivity_2: 0.5724 - recall_2: 0.3452 - precision_2: 0.5421 - auc_2: 0.5369 - val_loss: 0.6906 - val_accuracy: 0.5875 - val_sensitivity_at_specificity_2: 0.2500 - val_specificity_at_sensitivity_2: 0.1765 - val_recall_2: 0.9891 - val_precision_2: 0.5833 - val_auc_2: 0.6101\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6889 - accuracy: 0.5281 - sensitivity_at_specificity_2: 0.5660 - specificity_at_sensitivity_2: 0.5466 - recall_2: 0.8176 - precision_2: 0.5159 - auc_2: 0.5801\n",
            "Epoch 23: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6889 - accuracy: 0.5281 - sensitivity_at_specificity_2: 0.5660 - specificity_at_sensitivity_2: 0.5466 - recall_2: 0.8176 - precision_2: 0.5159 - auc_2: 0.5801 - val_loss: 0.6907 - val_accuracy: 0.5188 - val_sensitivity_at_specificity_2: 0.2892 - val_specificity_at_sensitivity_2: 0.2338 - val_recall_2: 1.0000 - val_precision_2: 0.5188 - val_auc_2: 0.6432\n",
            "Epoch 24/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6944 - accuracy: 0.4965 - sensitivity_at_specificity_2: 0.6111 - specificity_at_sensitivity_2: 0.6049 - recall_2: 0.8492 - precision_2: 0.4592 - auc_2: 0.5732\n",
            "Epoch 24: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6948 - accuracy: 0.5000 - sensitivity_at_specificity_2: 0.5724 - specificity_at_sensitivity_2: 0.5943 - recall_2: 0.7724 - precision_2: 0.4686 - auc_2: 0.5462 - val_loss: 0.6912 - val_accuracy: 0.6687 - val_sensitivity_at_specificity_2: 0.3671 - val_specificity_at_sensitivity_2: 0.2099 - val_recall_2: 0.8861 - val_precision_2: 0.6140 - val_auc_2: 0.6574\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5188 - sensitivity_at_specificity_2: 0.5215 - specificity_at_sensitivity_2: 0.5350 - recall_2: 0.2699 - precision_2: 0.5570 - auc_2: 0.5513\n",
            "Epoch 25: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6918 - accuracy: 0.5188 - sensitivity_at_specificity_2: 0.5215 - specificity_at_sensitivity_2: 0.5350 - recall_2: 0.2699 - precision_2: 0.5570 - auc_2: 0.5513 - val_loss: 0.6904 - val_accuracy: 0.6562 - val_sensitivity_at_specificity_2: 0.9167 - val_specificity_at_sensitivity_2: 0.5455 - val_recall_2: 0.4861 - val_precision_2: 0.6604 - val_auc_2: 0.7253\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6903 - accuracy: 0.5406 - sensitivity_at_specificity_2: 0.5301 - specificity_at_sensitivity_2: 0.5714 - recall_2: 0.3855 - precision_2: 0.5872 - auc_2: 0.5675\n",
            "Epoch 26: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6903 - accuracy: 0.5406 - sensitivity_at_specificity_2: 0.5301 - specificity_at_sensitivity_2: 0.5714 - recall_2: 0.3855 - precision_2: 0.5872 - auc_2: 0.5675 - val_loss: 0.6939 - val_accuracy: 0.4125 - val_sensitivity_at_specificity_2: 0.8871 - val_specificity_at_sensitivity_2: 0.5612 - val_recall_2: 0.9839 - val_precision_2: 0.3961 - val_auc_2: 0.7358\n",
            "Epoch 27/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6935 - accuracy: 0.5174 - sensitivity_at_specificity_2: 0.5333 - specificity_at_sensitivity_2: 0.5163 - recall_2: 0.8815 - precision_2: 0.4917 - auc_2: 0.5530\n",
            "Epoch 27: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6935 - accuracy: 0.5188 - sensitivity_at_specificity_2: 0.5503 - specificity_at_sensitivity_2: 0.5088 - recall_2: 0.8926 - precision_2: 0.4908 - auc_2: 0.5556 - val_loss: 0.6897 - val_accuracy: 0.5437 - val_sensitivity_at_specificity_2: 0.5476 - val_specificity_at_sensitivity_2: 0.7500 - val_recall_2: 1.0000 - val_precision_2: 0.5350 - val_auc_2: 0.6926\n",
            "Epoch 28/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6874 - accuracy: 0.5729 - sensitivity_at_specificity_2: 0.5364 - specificity_at_sensitivity_2: 0.5401 - recall_2: 0.6689 - precision_2: 0.5805 - auc_2: 0.5682\n",
            "Epoch 28: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6880 - accuracy: 0.5688 - sensitivity_at_specificity_2: 0.5273 - specificity_at_sensitivity_2: 0.5548 - recall_2: 0.6667 - precision_2: 0.5699 - auc_2: 0.5656 - val_loss: 0.6903 - val_accuracy: 0.5750 - val_sensitivity_at_specificity_2: 0.7436 - val_specificity_at_sensitivity_2: 0.5976 - val_recall_2: 0.9744 - val_precision_2: 0.5352 - val_auc_2: 0.6976\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.5156 - sensitivity_at_specificity_2: 0.5562 - specificity_at_sensitivity_2: 0.5250 - recall_2: 0.4250 - precision_2: 0.5191 - auc_2: 0.5571\n",
            "Epoch 29: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6893 - accuracy: 0.5156 - sensitivity_at_specificity_2: 0.5562 - specificity_at_sensitivity_2: 0.5250 - recall_2: 0.4250 - precision_2: 0.5191 - auc_2: 0.5571 - val_loss: 0.6895 - val_accuracy: 0.6812 - val_sensitivity_at_specificity_2: 0.9200 - val_specificity_at_sensitivity_2: 0.5765 - val_recall_2: 1.0000 - val_precision_2: 0.5952 - val_auc_2: 0.7478\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6899 - accuracy: 0.5469 - sensitivity_at_specificity_2: 0.4877 - specificity_at_sensitivity_2: 0.4873 - recall_2: 0.6852 - precision_2: 0.5415 - auc_2: 0.5551\n",
            "Epoch 30: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6899 - accuracy: 0.5469 - sensitivity_at_specificity_2: 0.4877 - specificity_at_sensitivity_2: 0.4873 - recall_2: 0.6852 - precision_2: 0.5415 - auc_2: 0.5551 - val_loss: 0.6920 - val_accuracy: 0.4812 - val_sensitivity_at_specificity_2: 0.1867 - val_specificity_at_sensitivity_2: 0.4000 - val_recall_2: 1.0000 - val_precision_2: 0.4747 - val_auc_2: 0.6828\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.5531 - sensitivity_at_specificity_2: 0.6894 - specificity_at_sensitivity_2: 0.6226 - recall_2: 0.8696 - precision_2: 0.5344 - auc_2: 0.5899\n",
            "Epoch 31: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6876 - accuracy: 0.5531 - sensitivity_at_specificity_2: 0.6894 - specificity_at_sensitivity_2: 0.6226 - recall_2: 0.8696 - precision_2: 0.5344 - auc_2: 0.5899 - val_loss: 0.6848 - val_accuracy: 0.5750 - val_sensitivity_at_specificity_2: 0.7841 - val_specificity_at_sensitivity_2: 0.6389 - val_recall_2: 0.9886 - val_precision_2: 0.5649 - val_auc_2: 0.7521\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.5938 - sensitivity_at_specificity_2: 0.6832 - specificity_at_sensitivity_2: 0.6352 - recall_2: 0.7950 - precision_2: 0.5689 - auc_2: 0.6340\n",
            "Epoch 32: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6811 - accuracy: 0.5938 - sensitivity_at_specificity_2: 0.6832 - specificity_at_sensitivity_2: 0.6352 - recall_2: 0.7950 - precision_2: 0.5689 - auc_2: 0.6340 - val_loss: 0.6874 - val_accuracy: 0.5875 - val_sensitivity_at_specificity_2: 0.8846 - val_specificity_at_sensitivity_2: 0.7683 - val_recall_2: 0.9872 - val_precision_2: 0.5423 - val_auc_2: 0.7658\n",
            "Epoch 33/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6754 - accuracy: 0.6389 - sensitivity_at_specificity_2: 0.7762 - specificity_at_sensitivity_2: 0.7241 - recall_2: 0.7552 - precision_2: 0.6102 - auc_2: 0.6698\n",
            "Epoch 33: val_accuracy improved from 0.68125 to 0.69375, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6763 - accuracy: 0.6344 - sensitivity_at_specificity_2: 0.7640 - specificity_at_sensitivity_2: 0.6855 - recall_2: 0.7453 - precision_2: 0.6122 - auc_2: 0.6611 - val_loss: 0.6854 - val_accuracy: 0.6938 - val_sensitivity_at_specificity_2: 0.8571 - val_specificity_at_sensitivity_2: 0.7500 - val_recall_2: 0.9167 - val_precision_2: 0.6471 - val_auc_2: 0.7604\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6827 - accuracy: 0.5688 - sensitivity_at_specificity_2: 0.6118 - specificity_at_sensitivity_2: 0.5467 - recall_2: 0.7882 - precision_2: 0.5678 - auc_2: 0.5815\n",
            "Epoch 34: val_accuracy did not improve from 0.69375\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6827 - accuracy: 0.5688 - sensitivity_at_specificity_2: 0.6118 - specificity_at_sensitivity_2: 0.5467 - recall_2: 0.7882 - precision_2: 0.5678 - auc_2: 0.5815 - val_loss: 0.6823 - val_accuracy: 0.5437 - val_sensitivity_at_specificity_2: 0.7143 - val_specificity_at_sensitivity_2: 0.8026 - val_recall_2: 0.9881 - val_precision_2: 0.5355 - val_auc_2: 0.7239\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.5312 - sensitivity_at_specificity_2: 0.6340 - specificity_at_sensitivity_2: 0.6766 - recall_2: 0.7386 - precision_2: 0.5067 - auc_2: 0.5876\n",
            "Epoch 35: val_accuracy did not improve from 0.69375\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6882 - accuracy: 0.5312 - sensitivity_at_specificity_2: 0.6340 - specificity_at_sensitivity_2: 0.6766 - recall_2: 0.7386 - precision_2: 0.5067 - auc_2: 0.5876 - val_loss: 0.6926 - val_accuracy: 0.4875 - val_sensitivity_at_specificity_2: 0.8415 - val_specificity_at_sensitivity_2: 0.7308 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.7443\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.5406 - sensitivity_at_specificity_2: 0.5197 - specificity_at_sensitivity_2: 0.5417 - recall_2: 0.1842 - precision_2: 0.5490 - auc_2: 0.5274       \n",
            "Epoch 36: val_accuracy did not improve from 0.69375\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6947 - accuracy: 0.5406 - sensitivity_at_specificity_2: 0.5197 - specificity_at_sensitivity_2: 0.5417 - recall_2: 0.1842 - precision_2: 0.5490 - auc_2: 0.5274 - val_loss: 0.6828 - val_accuracy: 0.6812 - val_sensitivity_at_specificity_2: 0.8409 - val_specificity_at_sensitivity_2: 0.8194 - val_recall_2: 0.8636 - val_precision_2: 0.6609 - val_auc_2: 0.7300\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6833 - accuracy: 0.5813 - sensitivity_at_specificity_2: 0.6200 - specificity_at_sensitivity_2: 0.6588 - recall_2: 0.7600 - precision_2: 0.5377 - auc_2: 0.6219\n",
            "Epoch 37: val_accuracy improved from 0.69375 to 0.74375, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.6833 - accuracy: 0.5813 - sensitivity_at_specificity_2: 0.6200 - specificity_at_sensitivity_2: 0.6588 - recall_2: 0.7600 - precision_2: 0.5377 - auc_2: 0.6219 - val_loss: 0.6771 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9444 - val_specificity_at_sensitivity_2: 0.8068 - val_recall_2: 0.8889 - val_precision_2: 0.6598 - val_auc_2: 0.8070\n",
            "Epoch 38/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6731 - accuracy: 0.6250 - sensitivity_at_specificity_2: 0.7616 - specificity_at_sensitivity_2: 0.7445 - recall_2: 0.5430 - precision_2: 0.6777 - auc_2: 0.6702\n",
            "Epoch 38: val_accuracy did not improve from 0.74375\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6740 - accuracy: 0.6125 - sensitivity_at_specificity_2: 0.7605 - specificity_at_sensitivity_2: 0.7255 - recall_2: 0.5329 - precision_2: 0.6593 - auc_2: 0.6611 - val_loss: 0.6742 - val_accuracy: 0.7000 - val_sensitivity_at_specificity_2: 0.8824 - val_specificity_at_sensitivity_2: 0.7333 - val_recall_2: 0.9529 - val_precision_2: 0.6480 - val_auc_2: 0.7598\n",
            "Epoch 39/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6866 - accuracy: 0.5660 - sensitivity_at_specificity_2: 0.5954 - specificity_at_sensitivity_2: 0.5796 - recall_2: 0.7481 - precision_2: 0.5158 - auc_2: 0.5839\n",
            "Epoch 39: val_accuracy did not improve from 0.74375\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6842 - accuracy: 0.5594 - sensitivity_at_specificity_2: 0.5959 - specificity_at_sensitivity_2: 0.5747 - recall_2: 0.6781 - precision_2: 0.5130 - auc_2: 0.5839 - val_loss: 0.6879 - val_accuracy: 0.4187 - val_sensitivity_at_specificity_2: 0.7849 - val_specificity_at_sensitivity_2: 0.8806 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.7787\n",
            "Epoch 40/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6811 - accuracy: 0.5590 - sensitivity_at_specificity_2: 0.6708 - specificity_at_sensitivity_2: 0.6850 - recall_2: 0.3789 - precision_2: 0.6932 - auc_2: 0.6248\n",
            "Epoch 40: val_accuracy did not improve from 0.74375\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6799 - accuracy: 0.5562 - sensitivity_at_specificity_2: 0.6193 - specificity_at_sensitivity_2: 0.6111 - recall_2: 0.4318 - precision_2: 0.6441 - auc_2: 0.6067 - val_loss: 0.6926 - val_accuracy: 0.4688 - val_sensitivity_at_specificity_2: 0.8889 - val_specificity_at_sensitivity_2: 0.8295 - val_recall_2: 1.0000 - val_precision_2: 0.4586 - val_auc_2: 0.8027\n",
            "Epoch 41/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6815 - accuracy: 0.5729 - sensitivity_at_specificity_2: 0.6370 - specificity_at_sensitivity_2: 0.6479 - recall_2: 0.9247 - precision_2: 0.5466 - auc_2: 0.6153\n",
            "Epoch 41: val_accuracy did not improve from 0.74375\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6771 - accuracy: 0.5875 - sensitivity_at_specificity_2: 0.6728 - specificity_at_sensitivity_2: 0.6772 - recall_2: 0.9136 - precision_2: 0.5564 - auc_2: 0.6271 - val_loss: 0.6685 - val_accuracy: 0.7063 - val_sensitivity_at_specificity_2: 0.8933 - val_specificity_at_sensitivity_2: 0.8588 - val_recall_2: 0.9067 - val_precision_2: 0.6296 - val_auc_2: 0.8191\n",
            "Epoch 42/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6801 - accuracy: 0.5625 - sensitivity_at_specificity_2: 0.5899 - specificity_at_sensitivity_2: 0.6376 - recall_2: 0.4101 - precision_2: 0.5644 - auc_2: 0.5989\n",
            "Epoch 42: val_accuracy improved from 0.74375 to 0.77500, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.6813 - accuracy: 0.5562 - sensitivity_at_specificity_2: 0.5813 - specificity_at_sensitivity_2: 0.6000 - recall_2: 0.3938 - precision_2: 0.5833 - auc_2: 0.5995 - val_loss: 0.6586 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9759 - val_specificity_at_sensitivity_2: 0.8701 - val_recall_2: 0.8554 - val_precision_2: 0.7474 - val_auc_2: 0.8485\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6542 - accuracy: 0.6344 - sensitivity_at_specificity_2: 0.7758 - specificity_at_sensitivity_2: 0.7742 - recall_2: 0.8606 - precision_2: 0.6017 - auc_2: 0.7067\n",
            "Epoch 43: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6542 - accuracy: 0.6344 - sensitivity_at_specificity_2: 0.7758 - specificity_at_sensitivity_2: 0.7742 - recall_2: 0.8606 - precision_2: 0.6017 - auc_2: 0.7067 - val_loss: 0.6624 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_2: 0.9429 - val_specificity_at_sensitivity_2: 0.8778 - val_recall_2: 0.9857 - val_precision_2: 0.5308 - val_auc_2: 0.8440\n",
            "Epoch 44/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6717 - accuracy: 0.6042 - sensitivity_at_specificity_2: 0.7203 - specificity_at_sensitivity_2: 0.6966 - recall_2: 0.5524 - precision_2: 0.6124 - auc_2: 0.6312\n",
            "Epoch 44: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.6647 - accuracy: 0.6219 - sensitivity_at_specificity_2: 0.7308 - specificity_at_sensitivity_2: 0.7195 - recall_2: 0.5577 - precision_2: 0.6259 - auc_2: 0.6545 - val_loss: 0.6669 - val_accuracy: 0.6875 - val_sensitivity_at_specificity_2: 0.9167 - val_specificity_at_sensitivity_2: 0.7159 - val_recall_2: 0.7778 - val_precision_2: 0.6222 - val_auc_2: 0.7143\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6469 - accuracy: 0.6656 - sensitivity_at_specificity_2: 0.7688 - specificity_at_sensitivity_2: 0.7688 - recall_2: 0.6438 - precision_2: 0.6732 - auc_2: 0.7014\n",
            "Epoch 45: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6469 - accuracy: 0.6656 - sensitivity_at_specificity_2: 0.7688 - specificity_at_sensitivity_2: 0.7688 - recall_2: 0.6438 - precision_2: 0.6732 - auc_2: 0.7014 - val_loss: 0.6353 - val_accuracy: 0.6812 - val_sensitivity_at_specificity_2: 0.9535 - val_specificity_at_sensitivity_2: 0.8243 - val_recall_2: 0.9651 - val_precision_2: 0.6336 - val_auc_2: 0.7928\n",
            "Epoch 46/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6485 - accuracy: 0.6328 - sensitivity_at_specificity_2: 0.8049 - specificity_at_sensitivity_2: 0.7744 - recall_2: 0.8455 - precision_2: 0.5810 - auc_2: 0.7138\n",
            "Epoch 46: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.6502 - accuracy: 0.6156 - sensitivity_at_specificity_2: 0.7548 - specificity_at_sensitivity_2: 0.7576 - recall_2: 0.7097 - precision_2: 0.5851 - auc_2: 0.6752 - val_loss: 0.6285 - val_accuracy: 0.7063 - val_sensitivity_at_specificity_2: 0.9155 - val_specificity_at_sensitivity_2: 0.8539 - val_recall_2: 0.4930 - val_precision_2: 0.7609 - val_auc_2: 0.8201\n",
            "Epoch 47/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6573 - accuracy: 0.6146 - sensitivity_at_specificity_2: 0.7482 - specificity_at_sensitivity_2: 0.7114 - recall_2: 0.6547 - precision_2: 0.5909 - auc_2: 0.6565\n",
            "Epoch 47: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6579 - accuracy: 0.6125 - sensitivity_at_specificity_2: 0.7548 - specificity_at_sensitivity_2: 0.7091 - recall_2: 0.6581 - precision_2: 0.5896 - auc_2: 0.6539 - val_loss: 0.6407 - val_accuracy: 0.7312 - val_sensitivity_at_specificity_2: 0.8831 - val_specificity_at_sensitivity_2: 0.8193 - val_recall_2: 0.8831 - val_precision_2: 0.6667 - val_auc_2: 0.7603\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6502 - accuracy: 0.6500 - sensitivity_at_specificity_2: 0.8485 - specificity_at_sensitivity_2: 0.6839 - recall_2: 0.7515 - precision_2: 0.6359 - auc_2: 0.6694\n",
            "Epoch 48: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6502 - accuracy: 0.6500 - sensitivity_at_specificity_2: 0.8485 - specificity_at_sensitivity_2: 0.6839 - recall_2: 0.7515 - precision_2: 0.6359 - auc_2: 0.6694 - val_loss: 0.6306 - val_accuracy: 0.7125 - val_sensitivity_at_specificity_2: 0.8608 - val_specificity_at_sensitivity_2: 0.8272 - val_recall_2: 0.8608 - val_precision_2: 0.6602 - val_auc_2: 0.7745\n",
            "Epoch 49/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6286 - accuracy: 0.6493 - sensitivity_at_specificity_2: 0.8358 - specificity_at_sensitivity_2: 0.7987 - recall_2: 0.4627 - precision_2: 0.6813 - auc_2: 0.7225\n",
            "Epoch 49: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6306 - accuracy: 0.6500 - sensitivity_at_specificity_2: 0.8477 - specificity_at_sensitivity_2: 0.7751 - recall_2: 0.5099 - precision_2: 0.6696 - auc_2: 0.7130 - val_loss: 0.6230 - val_accuracy: 0.6500 - val_sensitivity_at_specificity_2: 0.9294 - val_specificity_at_sensitivity_2: 0.7733 - val_recall_2: 0.9765 - val_precision_2: 0.6058 - val_auc_2: 0.8004\n",
            "Epoch 50/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6392 - accuracy: 0.6424 - sensitivity_at_specificity_2: 0.8077 - specificity_at_sensitivity_2: 0.7652 - recall_2: 0.9359 - precision_2: 0.6109 - auc_2: 0.7013\n",
            "Epoch 50: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6361 - accuracy: 0.6500 - sensitivity_at_specificity_2: 0.7816 - specificity_at_sensitivity_2: 0.7397 - recall_2: 0.9023 - precision_2: 0.6230 - auc_2: 0.6951 - val_loss: 0.6154 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9189 - val_specificity_at_sensitivity_2: 0.8721 - val_recall_2: 0.7973 - val_precision_2: 0.7024 - val_auc_2: 0.8088\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6474 - accuracy: 0.6094 - sensitivity_at_specificity_2: 0.8052 - specificity_at_sensitivity_2: 0.6867 - recall_2: 0.5909 - precision_2: 0.5948 - auc_2: 0.6698\n",
            "Epoch 51: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6474 - accuracy: 0.6094 - sensitivity_at_specificity_2: 0.8052 - specificity_at_sensitivity_2: 0.6867 - recall_2: 0.5909 - precision_2: 0.5948 - auc_2: 0.6698 - val_loss: 0.6499 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_2: 0.7973 - val_specificity_at_sensitivity_2: 0.7791 - val_recall_2: 0.7973 - val_precision_2: 0.5566 - val_auc_2: 0.7205\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6438 - accuracy: 0.6375 - sensitivity_at_specificity_2: 0.7922 - specificity_at_sensitivity_2: 0.7289 - recall_2: 0.5909 - precision_2: 0.6319 - auc_2: 0.6683\n",
            "Epoch 52: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6438 - accuracy: 0.6375 - sensitivity_at_specificity_2: 0.7922 - specificity_at_sensitivity_2: 0.7289 - recall_2: 0.5909 - precision_2: 0.6319 - auc_2: 0.6683 - val_loss: 0.6018 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9444 - val_specificity_at_sensitivity_2: 0.8750 - val_recall_2: 0.9028 - val_precision_2: 0.6373 - val_auc_2: 0.8498\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.6656 - sensitivity_at_specificity_2: 0.8365 - specificity_at_sensitivity_2: 0.7826 - recall_2: 0.7673 - precision_2: 0.6354 - auc_2: 0.7161\n",
            "Epoch 53: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6262 - accuracy: 0.6656 - sensitivity_at_specificity_2: 0.8365 - specificity_at_sensitivity_2: 0.7826 - recall_2: 0.7673 - precision_2: 0.6354 - auc_2: 0.7161 - val_loss: 0.5987 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.8824 - val_specificity_at_sensitivity_2: 0.8400 - val_recall_2: 0.8588 - val_precision_2: 0.7228 - val_auc_2: 0.7949\n",
            "Epoch 54/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6030 - accuracy: 0.6840 - sensitivity_at_specificity_2: 0.8768 - specificity_at_sensitivity_2: 0.7867 - recall_2: 0.6812 - precision_2: 0.6667 - auc_2: 0.7390\n",
            "Epoch 54: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.6007 - accuracy: 0.6875 - sensitivity_at_specificity_2: 0.8896 - specificity_at_sensitivity_2: 0.7892 - recall_2: 0.6948 - precision_2: 0.6687 - auc_2: 0.7431 - val_loss: 0.5651 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9551 - val_specificity_at_sensitivity_2: 0.9155 - val_recall_2: 0.8876 - val_precision_2: 0.7383 - val_auc_2: 0.8404\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5887 - accuracy: 0.7063 - sensitivity_at_specificity_2: 0.9096 - specificity_at_sensitivity_2: 0.8117 - recall_2: 0.8313 - precision_2: 0.6765 - auc_2: 0.7508\n",
            "Epoch 55: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5887 - accuracy: 0.7063 - sensitivity_at_specificity_2: 0.9096 - specificity_at_sensitivity_2: 0.8117 - recall_2: 0.8313 - precision_2: 0.6765 - auc_2: 0.7508 - val_loss: 0.5516 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9474 - val_specificity_at_sensitivity_2: 0.8690 - val_recall_2: 0.8421 - val_precision_2: 0.6882 - val_auc_2: 0.8152\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5966 - accuracy: 0.7063 - sensitivity_at_specificity_2: 0.8562 - specificity_at_sensitivity_2: 0.7750 - recall_2: 0.7750 - precision_2: 0.6813 - auc_2: 0.7337\n",
            "Epoch 56: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5966 - accuracy: 0.7063 - sensitivity_at_specificity_2: 0.8562 - specificity_at_sensitivity_2: 0.7750 - recall_2: 0.7750 - precision_2: 0.6813 - auc_2: 0.7337 - val_loss: 0.5846 - val_accuracy: 0.6750 - val_sensitivity_at_specificity_2: 0.9091 - val_specificity_at_sensitivity_2: 0.8795 - val_recall_2: 0.9610 - val_precision_2: 0.6016 - val_auc_2: 0.8406\n",
            "Epoch 57/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5957 - accuracy: 0.6771 - sensitivity_at_specificity_2: 0.8500 - specificity_at_sensitivity_2: 0.7770 - recall_2: 0.7286 - precision_2: 0.6497 - auc_2: 0.7340\n",
            "Epoch 57: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5937 - accuracy: 0.6812 - sensitivity_at_specificity_2: 0.8471 - specificity_at_sensitivity_2: 0.7853 - recall_2: 0.7261 - precision_2: 0.6590 - auc_2: 0.7384 - val_loss: 0.5960 - val_accuracy: 0.6812 - val_sensitivity_at_specificity_2: 0.8919 - val_specificity_at_sensitivity_2: 0.9186 - val_recall_2: 0.8919 - val_precision_2: 0.6055 - val_auc_2: 0.8158\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6091 - accuracy: 0.6781 - sensitivity_at_specificity_2: 0.8383 - specificity_at_sensitivity_2: 0.7908 - recall_2: 0.8204 - precision_2: 0.6524 - auc_2: 0.7255\n",
            "Epoch 58: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6091 - accuracy: 0.6781 - sensitivity_at_specificity_2: 0.8383 - specificity_at_sensitivity_2: 0.7908 - recall_2: 0.8204 - precision_2: 0.6524 - auc_2: 0.7255 - val_loss: 0.5788 - val_accuracy: 0.6812 - val_sensitivity_at_specificity_2: 0.8553 - val_specificity_at_sensitivity_2: 0.9167 - val_recall_2: 0.8947 - val_precision_2: 0.6126 - val_auc_2: 0.8340\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5872 - accuracy: 0.6750 - sensitivity_at_specificity_2: 0.8831 - specificity_at_sensitivity_2: 0.8253 - recall_2: 0.6948 - precision_2: 0.6524 - auc_2: 0.7472\n",
            "Epoch 59: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5872 - accuracy: 0.6750 - sensitivity_at_specificity_2: 0.8831 - specificity_at_sensitivity_2: 0.8253 - recall_2: 0.6948 - precision_2: 0.6524 - auc_2: 0.7472 - val_loss: 0.6083 - val_accuracy: 0.6313 - val_sensitivity_at_specificity_2: 0.9277 - val_specificity_at_sensitivity_2: 0.8961 - val_recall_2: 0.9518 - val_precision_2: 0.5896 - val_auc_2: 0.8255\n",
            "Epoch 60/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6101 - accuracy: 0.6562 - sensitivity_at_specificity_2: 0.8188 - specificity_at_sensitivity_2: 0.7867 - recall_2: 0.7319 - precision_2: 0.6196 - auc_2: 0.7274\n",
            "Epoch 60: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6220 - accuracy: 0.6406 - sensitivity_at_specificity_2: 0.7799 - specificity_at_sensitivity_2: 0.7329 - recall_2: 0.6730 - precision_2: 0.6294 - auc_2: 0.7055 - val_loss: 0.5857 - val_accuracy: 0.7000 - val_sensitivity_at_specificity_2: 0.8514 - val_specificity_at_sensitivity_2: 0.8372 - val_recall_2: 0.7703 - val_precision_2: 0.6477 - val_auc_2: 0.7846\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5678 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.9157 - specificity_at_sensitivity_2: 0.7987 - recall_2: 0.8072 - precision_2: 0.6872 - auc_2: 0.7740\n",
            "Epoch 61: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5678 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.9157 - specificity_at_sensitivity_2: 0.7987 - recall_2: 0.8072 - precision_2: 0.6872 - auc_2: 0.7740 - val_loss: 0.5532 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9467 - val_specificity_at_sensitivity_2: 0.8235 - val_recall_2: 0.8933 - val_precision_2: 0.6505 - val_auc_2: 0.8169\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.6594 - sensitivity_at_specificity_2: 0.8924 - specificity_at_sensitivity_2: 0.7716 - recall_2: 0.7089 - precision_2: 0.6400 - auc_2: 0.7422\n",
            "Epoch 62: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5847 - accuracy: 0.6594 - sensitivity_at_specificity_2: 0.8924 - specificity_at_sensitivity_2: 0.7716 - recall_2: 0.7089 - precision_2: 0.6400 - auc_2: 0.7422 - val_loss: 0.5544 - val_accuracy: 0.7125 - val_sensitivity_at_specificity_2: 0.9701 - val_specificity_at_sensitivity_2: 0.9355 - val_recall_2: 0.9552 - val_precision_2: 0.5981 - val_auc_2: 0.8778\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5771 - accuracy: 0.6812 - sensitivity_at_specificity_2: 0.8551 - specificity_at_sensitivity_2: 0.7967 - recall_2: 0.6957 - precision_2: 0.6154 - auc_2: 0.7569\n",
            "Epoch 63: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5771 - accuracy: 0.6812 - sensitivity_at_specificity_2: 0.8551 - specificity_at_sensitivity_2: 0.7967 - recall_2: 0.6957 - precision_2: 0.6154 - auc_2: 0.7569 - val_loss: 0.5881 - val_accuracy: 0.6938 - val_sensitivity_at_specificity_2: 0.8659 - val_specificity_at_sensitivity_2: 0.8974 - val_recall_2: 0.6341 - val_precision_2: 0.7324 - val_auc_2: 0.8048\n",
            "Epoch 64/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6064 - accuracy: 0.6806 - sensitivity_at_specificity_2: 0.8101 - specificity_at_sensitivity_2: 0.8231 - recall_2: 0.7785 - precision_2: 0.6833 - auc_2: 0.7404\n",
            "Epoch 64: val_accuracy did not improve from 0.77500\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.6141 - accuracy: 0.6656 - sensitivity_at_specificity_2: 0.8118 - specificity_at_sensitivity_2: 0.8200 - recall_2: 0.7824 - precision_2: 0.6552 - auc_2: 0.7357 - val_loss: 0.6383 - val_accuracy: 0.5813 - val_sensitivity_at_specificity_2: 0.9091 - val_specificity_at_sensitivity_2: 0.9277 - val_recall_2: 0.9610 - val_precision_2: 0.5362 - val_auc_2: 0.8159\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5998 - accuracy: 0.6781 - sensitivity_at_specificity_2: 0.8554 - specificity_at_sensitivity_2: 0.8247 - recall_2: 0.7651 - precision_2: 0.6649 - auc_2: 0.7507\n",
            "Epoch 65: val_accuracy improved from 0.77500 to 0.78125, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.5998 - accuracy: 0.6781 - sensitivity_at_specificity_2: 0.8554 - specificity_at_sensitivity_2: 0.8247 - recall_2: 0.7651 - precision_2: 0.6649 - auc_2: 0.7507 - val_loss: 0.5708 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9545 - val_specificity_at_sensitivity_2: 0.9167 - val_recall_2: 0.8864 - val_precision_2: 0.7573 - val_auc_2: 0.8432\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.6531 - sensitivity_at_specificity_2: 0.8397 - specificity_at_sensitivity_2: 0.7683 - recall_2: 0.7372 - precision_2: 0.6216 - auc_2: 0.7230\n",
            "Epoch 66: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6203 - accuracy: 0.6531 - sensitivity_at_specificity_2: 0.8397 - specificity_at_sensitivity_2: 0.7683 - recall_2: 0.7372 - precision_2: 0.6216 - auc_2: 0.7230 - val_loss: 0.5619 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 0.8947 - val_recall_2: 0.9167 - val_precision_2: 0.6875 - val_auc_2: 0.8317\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5507 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9036 - specificity_at_sensitivity_2: 0.8896 - recall_2: 0.7771 - precision_2: 0.7288 - auc_2: 0.8112\n",
            "Epoch 67: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.5507 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9036 - specificity_at_sensitivity_2: 0.8896 - recall_2: 0.7771 - precision_2: 0.7288 - auc_2: 0.8112 - val_loss: 0.5326 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9643 - val_specificity_at_sensitivity_2: 0.8684 - val_recall_2: 0.9405 - val_precision_2: 0.7054 - val_auc_2: 0.8379\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.7276 - sensitivity_at_specificity_2: 0.8961 - specificity_at_sensitivity_2: 0.8824 - recall_2: 0.8831 - precision_2: 0.6904 - auc_2: 0.8249\n",
            "Epoch 68: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.5262 - accuracy: 0.7276 - sensitivity_at_specificity_2: 0.8961 - specificity_at_sensitivity_2: 0.8824 - recall_2: 0.8831 - precision_2: 0.6904 - auc_2: 0.8249 - val_loss: 0.5455 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9500 - val_specificity_at_sensitivity_2: 0.9000 - val_recall_2: 0.9375 - val_precision_2: 0.6696 - val_auc_2: 0.8408\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.8707 - specificity_at_sensitivity_2: 0.8671 - recall_2: 0.7551 - precision_2: 0.6607 - auc_2: 0.7846\n",
            "Epoch 69: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5659 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.8707 - specificity_at_sensitivity_2: 0.8671 - recall_2: 0.7551 - precision_2: 0.6607 - auc_2: 0.7846 - val_loss: 0.5330 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9518 - val_specificity_at_sensitivity_2: 0.8442 - val_recall_2: 0.7711 - val_precision_2: 0.7191 - val_auc_2: 0.8356\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5826 - accuracy: 0.6938 - sensitivity_at_specificity_2: 0.8545 - specificity_at_sensitivity_2: 0.8452 - recall_2: 0.8121 - precision_2: 0.6667 - auc_2: 0.7647\n",
            "Epoch 70: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.5826 - accuracy: 0.6938 - sensitivity_at_specificity_2: 0.8545 - specificity_at_sensitivity_2: 0.8452 - recall_2: 0.8121 - precision_2: 0.6667 - auc_2: 0.7647 - val_loss: 0.5513 - val_accuracy: 0.7000 - val_sensitivity_at_specificity_2: 0.9610 - val_specificity_at_sensitivity_2: 0.8916 - val_recall_2: 0.9610 - val_precision_2: 0.6218 - val_auc_2: 0.8563\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.8896 - specificity_at_sensitivity_2: 0.8471 - recall_2: 0.7485 - precision_2: 0.7305 - auc_2: 0.7973\n",
            "Epoch 71: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5527 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.8896 - specificity_at_sensitivity_2: 0.8471 - recall_2: 0.7485 - precision_2: 0.7305 - auc_2: 0.7973 - val_loss: 0.5894 - val_accuracy: 0.6687 - val_sensitivity_at_specificity_2: 0.8734 - val_specificity_at_sensitivity_2: 0.8765 - val_recall_2: 0.8861 - val_precision_2: 0.6140 - val_auc_2: 0.7983\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8500 - specificity_at_sensitivity_2: 0.8562 - recall_2: 0.7812 - precision_2: 0.7267 - auc_2: 0.7934\n",
            "Epoch 72: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5555 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8500 - specificity_at_sensitivity_2: 0.8562 - recall_2: 0.7812 - precision_2: 0.7267 - auc_2: 0.7934 - val_loss: 0.5433 - val_accuracy: 0.6938 - val_sensitivity_at_specificity_2: 0.8961 - val_specificity_at_sensitivity_2: 0.9759 - val_recall_2: 0.8961 - val_precision_2: 0.6273 - val_auc_2: 0.8690\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5608 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8974 - specificity_at_sensitivity_2: 0.8841 - recall_2: 0.7244 - precision_2: 0.6975 - auc_2: 0.7900\n",
            "Epoch 73: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5608 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8974 - specificity_at_sensitivity_2: 0.8841 - recall_2: 0.7244 - precision_2: 0.6975 - auc_2: 0.7900 - val_loss: 0.5239 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9286 - val_specificity_at_sensitivity_2: 0.8684 - val_recall_2: 0.8929 - val_precision_2: 0.7075 - val_auc_2: 0.8358\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7069 - sensitivity_at_specificity_2: 0.8961 - specificity_at_sensitivity_2: 0.8529 - recall_2: 0.8701 - precision_2: 0.6734 - auc_2: 0.7973\n",
            "Epoch 74: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.5658 - accuracy: 0.7069 - sensitivity_at_specificity_2: 0.8961 - specificity_at_sensitivity_2: 0.8529 - recall_2: 0.8701 - precision_2: 0.6734 - auc_2: 0.7973 - val_loss: 0.5429 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.8904 - val_specificity_at_sensitivity_2: 0.9080 - val_recall_2: 0.8356 - val_precision_2: 0.6778 - val_auc_2: 0.8192\n",
            "Epoch 75/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5144 - accuracy: 0.7326 - sensitivity_at_specificity_2: 0.9247 - specificity_at_sensitivity_2: 0.9155 - recall_2: 0.6986 - precision_2: 0.7556 - auc_2: 0.8371\n",
            "Epoch 75: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5195 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.9097 - recall_2: 0.7212 - precision_2: 0.7532 - auc_2: 0.8328 - val_loss: 0.5498 - val_accuracy: 0.7063 - val_sensitivity_at_specificity_2: 0.9211 - val_specificity_at_sensitivity_2: 0.9762 - val_recall_2: 0.9079 - val_precision_2: 0.6330 - val_auc_2: 0.8612\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8571 - specificity_at_sensitivity_2: 0.8675 - recall_2: 0.7792 - precision_2: 0.6742 - auc_2: 0.7940\n",
            "Epoch 76: val_accuracy improved from 0.78125 to 0.80625, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5574 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8571 - specificity_at_sensitivity_2: 0.8675 - recall_2: 0.7792 - precision_2: 0.6742 - auc_2: 0.7940 - val_loss: 0.4990 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9390 - val_specificity_at_sensitivity_2: 0.9359 - val_recall_2: 0.9024 - val_precision_2: 0.7629 - val_auc_2: 0.8703\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5538 - accuracy: 0.7219 - sensitivity_at_specificity_2: 0.8690 - specificity_at_sensitivity_2: 0.8800 - recall_2: 0.7862 - precision_2: 0.6628 - auc_2: 0.7965\n",
            "Epoch 77: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5538 - accuracy: 0.7219 - sensitivity_at_specificity_2: 0.8690 - specificity_at_sensitivity_2: 0.8800 - recall_2: 0.7862 - precision_2: 0.6628 - auc_2: 0.7965 - val_loss: 0.5650 - val_accuracy: 0.6750 - val_sensitivity_at_specificity_2: 0.8718 - val_specificity_at_sensitivity_2: 0.9634 - val_recall_2: 0.8846 - val_precision_2: 0.6161 - val_auc_2: 0.8542\n",
            "Epoch 78/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5529 - accuracy: 0.7222 - sensitivity_at_specificity_2: 0.9104 - specificity_at_sensitivity_2: 0.8701 - recall_2: 0.6194 - precision_2: 0.7411 - auc_2: 0.7987\n",
            "Epoch 78: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5521 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.9073 - specificity_at_sensitivity_2: 0.8757 - recall_2: 0.6291 - precision_2: 0.7480 - auc_2: 0.7996 - val_loss: 0.5218 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9318 - val_specificity_at_sensitivity_2: 0.9861 - val_recall_2: 0.9432 - val_precision_2: 0.6803 - val_auc_2: 0.8711\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5018 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9362 - specificity_at_sensitivity_2: 0.9162 - recall_2: 0.7872 - precision_2: 0.7070 - auc_2: 0.8381\n",
            "Epoch 79: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5018 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9362 - specificity_at_sensitivity_2: 0.9162 - recall_2: 0.7872 - precision_2: 0.7070 - auc_2: 0.8381 - val_loss: 0.4754 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9747 - val_specificity_at_sensitivity_2: 0.9383 - val_recall_2: 0.8861 - val_precision_2: 0.7143 - val_auc_2: 0.8849\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5650 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8889 - specificity_at_sensitivity_2: 0.8743 - recall_2: 0.6928 - precision_2: 0.7518 - auc_2: 0.7911\n",
            "Epoch 80: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5650 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8889 - specificity_at_sensitivity_2: 0.8743 - recall_2: 0.6928 - precision_2: 0.7518 - auc_2: 0.7911 - val_loss: 0.6348 - val_accuracy: 0.6438 - val_sensitivity_at_specificity_2: 0.8750 - val_specificity_at_sensitivity_2: 0.8625 - val_recall_2: 0.9250 - val_precision_2: 0.5920 - val_auc_2: 0.7861\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6078 - accuracy: 0.7031 - sensitivity_at_specificity_2: 0.8062 - specificity_at_sensitivity_2: 0.8313 - recall_2: 0.7375 - precision_2: 0.6901 - auc_2: 0.7455\n",
            "Epoch 81: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6078 - accuracy: 0.7031 - sensitivity_at_specificity_2: 0.8062 - specificity_at_sensitivity_2: 0.8313 - recall_2: 0.7375 - precision_2: 0.6901 - auc_2: 0.7455 - val_loss: 0.5382 - val_accuracy: 0.7063 - val_sensitivity_at_specificity_2: 0.9241 - val_specificity_at_sensitivity_2: 0.9630 - val_recall_2: 0.8861 - val_precision_2: 0.6481 - val_auc_2: 0.8572\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5727 - accuracy: 0.7031 - sensitivity_at_specificity_2: 0.8466 - specificity_at_sensitivity_2: 0.8626 - recall_2: 0.8624 - precision_2: 0.7026 - auc_2: 0.7626\n",
            "Epoch 82: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5727 - accuracy: 0.7031 - sensitivity_at_specificity_2: 0.8466 - specificity_at_sensitivity_2: 0.8626 - recall_2: 0.8624 - precision_2: 0.7026 - auc_2: 0.7626 - val_loss: 0.6380 - val_accuracy: 0.6438 - val_sensitivity_at_specificity_2: 0.8861 - val_specificity_at_sensitivity_2: 0.8765 - val_recall_2: 0.9620 - val_precision_2: 0.5846 - val_auc_2: 0.8020\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6008 - accuracy: 0.6844 - sensitivity_at_specificity_2: 0.8042 - specificity_at_sensitivity_2: 0.8079 - recall_2: 0.7133 - precision_2: 0.6296 - auc_2: 0.7385\n",
            "Epoch 83: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6008 - accuracy: 0.6844 - sensitivity_at_specificity_2: 0.8042 - specificity_at_sensitivity_2: 0.8079 - recall_2: 0.7133 - precision_2: 0.6296 - auc_2: 0.7385 - val_loss: 0.5381 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9512 - val_specificity_at_sensitivity_2: 0.9487 - val_recall_2: 0.7195 - val_precision_2: 0.7973 - val_auc_2: 0.8730\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5852 - accuracy: 0.6969 - sensitivity_at_specificity_2: 0.9086 - specificity_at_sensitivity_2: 0.8433 - recall_2: 0.6505 - precision_2: 0.7908 - auc_2: 0.7862\n",
            "Epoch 84: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5852 - accuracy: 0.6969 - sensitivity_at_specificity_2: 0.9086 - specificity_at_sensitivity_2: 0.8433 - recall_2: 0.6505 - precision_2: 0.7908 - auc_2: 0.7862 - val_loss: 0.6232 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_2: 0.8182 - val_specificity_at_sensitivity_2: 0.8916 - val_recall_2: 0.8701 - val_precision_2: 0.5678 - val_auc_2: 0.7865\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5992 - accuracy: 0.6781 - sensitivity_at_specificity_2: 0.8896 - specificity_at_sensitivity_2: 0.8855 - recall_2: 0.9156 - precision_2: 0.6104 - auc_2: 0.7954\n",
            "Epoch 85: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5992 - accuracy: 0.6781 - sensitivity_at_specificity_2: 0.8896 - specificity_at_sensitivity_2: 0.8855 - recall_2: 0.9156 - precision_2: 0.6104 - auc_2: 0.7954 - val_loss: 0.5381 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9383 - val_specificity_at_sensitivity_2: 0.9241 - val_recall_2: 0.9012 - val_precision_2: 0.7449 - val_auc_2: 0.8746\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5792 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8693 - specificity_at_sensitivity_2: 0.8623 - recall_2: 0.6471 - precision_2: 0.7226 - auc_2: 0.7787\n",
            "Epoch 86: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5792 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8693 - specificity_at_sensitivity_2: 0.8623 - recall_2: 0.6471 - precision_2: 0.7226 - auc_2: 0.7787 - val_loss: 0.5607 - val_accuracy: 0.7188 - val_sensitivity_at_specificity_2: 0.8605 - val_specificity_at_sensitivity_2: 0.9189 - val_recall_2: 0.8488 - val_precision_2: 0.6952 - val_auc_2: 0.8274\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5642 - accuracy: 0.6844 - sensitivity_at_specificity_2: 0.8614 - specificity_at_sensitivity_2: 0.8831 - recall_2: 0.8675 - precision_2: 0.6457 - auc_2: 0.8032\n",
            "Epoch 87: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.5642 - accuracy: 0.6844 - sensitivity_at_specificity_2: 0.8614 - specificity_at_sensitivity_2: 0.8831 - recall_2: 0.8675 - precision_2: 0.6457 - auc_2: 0.8032 - val_loss: 0.5921 - val_accuracy: 0.6687 - val_sensitivity_at_specificity_2: 0.9242 - val_specificity_at_sensitivity_2: 0.9149 - val_recall_2: 0.9242 - val_precision_2: 0.5596 - val_auc_2: 0.8461\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5183 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9125 - specificity_at_sensitivity_2: 0.9625 - recall_2: 0.8188 - precision_2: 0.7238 - auc_2: 0.8494\n",
            "Epoch 88: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5183 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9125 - specificity_at_sensitivity_2: 0.9625 - recall_2: 0.8188 - precision_2: 0.7238 - auc_2: 0.8494 - val_loss: 0.5506 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.8625 - val_specificity_at_sensitivity_2: 0.9000 - val_recall_2: 0.8500 - val_precision_2: 0.7010 - val_auc_2: 0.8204\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5457 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.8846 - specificity_at_sensitivity_2: 0.8720 - recall_2: 0.7628 - precision_2: 0.7391 - auc_2: 0.8037\n",
            "Epoch 89: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5457 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.8846 - specificity_at_sensitivity_2: 0.8720 - recall_2: 0.7628 - precision_2: 0.7391 - auc_2: 0.8037 - val_loss: 0.5452 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9296 - val_specificity_at_sensitivity_2: 0.8764 - val_recall_2: 0.8732 - val_precision_2: 0.6596 - val_auc_2: 0.8264\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8497 - specificity_at_sensitivity_2: 0.9461 - recall_2: 0.7451 - precision_2: 0.7215 - auc_2: 0.8161\n",
            "Epoch 90: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5328 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8497 - specificity_at_sensitivity_2: 0.9461 - recall_2: 0.7451 - precision_2: 0.7215 - auc_2: 0.8161 - val_loss: 0.5352 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.8987 - val_specificity_at_sensitivity_2: 0.9259 - val_recall_2: 0.7848 - val_precision_2: 0.7209 - val_auc_2: 0.8241\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5567 - accuracy: 0.6906 - sensitivity_at_specificity_2: 0.8701 - specificity_at_sensitivity_2: 0.8614 - recall_2: 0.6753 - precision_2: 0.6797 - auc_2: 0.7894\n",
            "Epoch 91: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5567 - accuracy: 0.6906 - sensitivity_at_specificity_2: 0.8701 - specificity_at_sensitivity_2: 0.8614 - recall_2: 0.6753 - precision_2: 0.6797 - auc_2: 0.7894 - val_loss: 0.5820 - val_accuracy: 0.6750 - val_sensitivity_at_specificity_2: 0.8590 - val_specificity_at_sensitivity_2: 0.9024 - val_recall_2: 0.7949 - val_precision_2: 0.6327 - val_auc_2: 0.7828\n",
            "Epoch 92/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5342 - accuracy: 0.7361 - sensitivity_at_specificity_2: 0.8844 - specificity_at_sensitivity_2: 0.8227 - recall_2: 0.7619 - precision_2: 0.7320 - auc_2: 0.8059\n",
            "Epoch 92: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5203 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.9379 - specificity_at_sensitivity_2: 0.8302 - recall_2: 0.7578 - precision_2: 0.7394 - auc_2: 0.8176 - val_loss: 0.5473 - val_accuracy: 0.6875 - val_sensitivity_at_specificity_2: 0.8690 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9048 - val_precision_2: 0.6441 - val_auc_2: 0.8513\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5400 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.8861 - specificity_at_sensitivity_2: 0.8765 - recall_2: 0.7722 - precision_2: 0.6816 - auc_2: 0.8023\n",
            "Epoch 93: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5400 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.8861 - specificity_at_sensitivity_2: 0.8765 - recall_2: 0.7722 - precision_2: 0.6816 - auc_2: 0.8023 - val_loss: 0.4671 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9425 - val_specificity_at_sensitivity_2: 0.9726 - val_recall_2: 0.9195 - val_precision_2: 0.7273 - val_auc_2: 0.9073\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5081 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.9016 - specificity_at_sensitivity_2: 0.9197 - recall_2: 0.8743 - precision_2: 0.7306 - auc_2: 0.8247\n",
            "Epoch 94: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.5081 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.9016 - specificity_at_sensitivity_2: 0.9197 - recall_2: 0.8743 - precision_2: 0.7306 - auc_2: 0.8247 - val_loss: 0.5357 - val_accuracy: 0.7063 - val_sensitivity_at_specificity_2: 0.9452 - val_specificity_at_sensitivity_2: 0.9310 - val_recall_2: 0.9178 - val_precision_2: 0.6204 - val_auc_2: 0.8619\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.7281 - sensitivity_at_specificity_2: 0.9441 - specificity_at_sensitivity_2: 0.9371 - recall_2: 0.7516 - precision_2: 0.7202 - auc_2: 0.8372\n",
            "Epoch 95: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.5034 - accuracy: 0.7281 - sensitivity_at_specificity_2: 0.9441 - specificity_at_sensitivity_2: 0.9371 - recall_2: 0.7516 - precision_2: 0.7202 - auc_2: 0.8372 - val_loss: 0.5254 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.8966 - val_specificity_at_sensitivity_2: 0.9178 - val_recall_2: 0.8621 - val_precision_2: 0.7282 - val_auc_2: 0.8255\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.7000 - sensitivity_at_specificity_2: 0.9398 - specificity_at_sensitivity_2: 0.9156 - recall_2: 0.7711 - precision_2: 0.6882 - auc_2: 0.8101\n",
            "Epoch 96: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5298 - accuracy: 0.7000 - sensitivity_at_specificity_2: 0.9398 - specificity_at_sensitivity_2: 0.9156 - recall_2: 0.7711 - precision_2: 0.6882 - auc_2: 0.8101 - val_loss: 0.5199 - val_accuracy: 0.7312 - val_sensitivity_at_specificity_2: 0.8913 - val_specificity_at_sensitivity_2: 0.9412 - val_recall_2: 0.8478 - val_precision_2: 0.7290 - val_auc_2: 0.8266\n",
            "Epoch 97/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5237 - accuracy: 0.7639 - sensitivity_at_specificity_2: 0.8882 - specificity_at_sensitivity_2: 0.9449 - recall_2: 0.8199 - precision_2: 0.7719 - auc_2: 0.8313\n",
            "Epoch 97: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5251 - accuracy: 0.7594 - sensitivity_at_specificity_2: 0.8902 - specificity_at_sensitivity_2: 0.9388 - recall_2: 0.8208 - precision_2: 0.7553 - auc_2: 0.8294 - val_loss: 0.5339 - val_accuracy: 0.7063 - val_sensitivity_at_specificity_2: 0.9342 - val_specificity_at_sensitivity_2: 0.9405 - val_recall_2: 0.9474 - val_precision_2: 0.6261 - val_auc_2: 0.8612\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.9217 - specificity_at_sensitivity_2: 0.8961 - recall_2: 0.8072 - precision_2: 0.7204 - auc_2: 0.8211\n",
            "Epoch 98: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5188 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.9217 - specificity_at_sensitivity_2: 0.8961 - recall_2: 0.8072 - precision_2: 0.7204 - auc_2: 0.8211 - val_loss: 0.5087 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9600 - val_specificity_at_sensitivity_2: 0.9647 - val_recall_2: 0.9067 - val_precision_2: 0.6733 - val_auc_2: 0.8582\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5307 - accuracy: 0.7281 - sensitivity_at_specificity_2: 0.8912 - specificity_at_sensitivity_2: 0.9191 - recall_2: 0.6395 - precision_2: 0.7344 - auc_2: 0.8121\n",
            "Epoch 99: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5307 - accuracy: 0.7281 - sensitivity_at_specificity_2: 0.8912 - specificity_at_sensitivity_2: 0.9191 - recall_2: 0.6395 - precision_2: 0.7344 - auc_2: 0.8121 - val_loss: 0.5047 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9302 - val_specificity_at_sensitivity_2: 0.9324 - val_recall_2: 0.8605 - val_precision_2: 0.7184 - val_auc_2: 0.8492\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5437 - accuracy: 0.7156 - sensitivity_at_specificity_2: 0.8718 - specificity_at_sensitivity_2: 0.9146 - recall_2: 0.7500 - precision_2: 0.6923 - auc_2: 0.8074\n",
            "Epoch 100: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5437 - accuracy: 0.7156 - sensitivity_at_specificity_2: 0.8718 - specificity_at_sensitivity_2: 0.9146 - recall_2: 0.7500 - precision_2: 0.6923 - auc_2: 0.8074 - val_loss: 0.4737 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 0.9634 - val_recall_2: 0.8974 - val_precision_2: 0.7368 - val_auc_2: 0.8938\n",
            "Epoch 101/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4672 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9270 - specificity_at_sensitivity_2: 0.9801 - recall_2: 0.7956 - precision_2: 0.7569 - auc_2: 0.8739\n",
            "Epoch 101: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4731 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9281 - specificity_at_sensitivity_2: 0.9701 - recall_2: 0.7974 - precision_2: 0.7531 - auc_2: 0.8677 - val_loss: 0.4923 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9474 - val_specificity_at_sensitivity_2: 0.9286 - val_recall_2: 0.9079 - val_precision_2: 0.6970 - val_auc_2: 0.8662\n",
            "Epoch 102/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5052 - accuracy: 0.7674 - sensitivity_at_specificity_2: 0.9103 - specificity_at_sensitivity_2: 0.9161 - recall_2: 0.7655 - precision_2: 0.7708 - auc_2: 0.8365\n",
            "Epoch 102: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5012 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9125 - specificity_at_sensitivity_2: 0.9312 - recall_2: 0.7625 - precision_2: 0.7625 - auc_2: 0.8384 - val_loss: 0.5214 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9012 - val_specificity_at_sensitivity_2: 0.9620 - val_recall_2: 0.8148 - val_precision_2: 0.6947 - val_auc_2: 0.8375\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8938 - specificity_at_sensitivity_2: 0.9125 - recall_2: 0.7125 - precision_2: 0.7215 - auc_2: 0.8165\n",
            "Epoch 103: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5257 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8938 - specificity_at_sensitivity_2: 0.9125 - recall_2: 0.7125 - precision_2: 0.7215 - auc_2: 0.8165 - val_loss: 0.5373 - val_accuracy: 0.7063 - val_sensitivity_at_specificity_2: 0.9114 - val_specificity_at_sensitivity_2: 0.9506 - val_recall_2: 0.9114 - val_precision_2: 0.6429 - val_auc_2: 0.8469\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5027 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.9012 - specificity_at_sensitivity_2: 0.9620 - recall_2: 0.7531 - precision_2: 0.7349 - auc_2: 0.8364\n",
            "Epoch 104: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5027 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.9012 - specificity_at_sensitivity_2: 0.9620 - recall_2: 0.7531 - precision_2: 0.7349 - auc_2: 0.8364 - val_loss: 0.4952 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9518 - val_specificity_at_sensitivity_2: 0.9481 - val_recall_2: 0.9277 - val_precision_2: 0.6937 - val_auc_2: 0.8704\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5130 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.9286 - specificity_at_sensitivity_2: 0.9217 - recall_2: 0.7143 - precision_2: 0.7383 - auc_2: 0.8295\n",
            "Epoch 105: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5130 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.9286 - specificity_at_sensitivity_2: 0.9217 - recall_2: 0.7143 - precision_2: 0.7383 - auc_2: 0.8295 - val_loss: 0.4663 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 0.9474 - val_recall_2: 0.8690 - val_precision_2: 0.7374 - val_auc_2: 0.8784\n",
            "Epoch 106/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5103 - accuracy: 0.7431 - sensitivity_at_specificity_2: 0.8881 - specificity_at_sensitivity_2: 0.9286 - recall_2: 0.6642 - precision_2: 0.7542 - auc_2: 0.8292\n",
            "Epoch 106: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5140 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8933 - specificity_at_sensitivity_2: 0.9235 - recall_2: 0.6667 - precision_2: 0.7519 - auc_2: 0.8264 - val_loss: 0.5039 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9000 - val_specificity_at_sensitivity_2: 0.9143 - val_recall_2: 0.9000 - val_precision_2: 0.7297 - val_auc_2: 0.8469\n",
            "Epoch 107/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5919 - accuracy: 0.6771 - sensitivity_at_specificity_2: 0.8500 - specificity_at_sensitivity_2: 0.8514 - recall_2: 0.6929 - precision_2: 0.6599 - auc_2: 0.7637\n",
            "Epoch 107: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5718 - accuracy: 0.6969 - sensitivity_at_specificity_2: 0.8687 - specificity_at_sensitivity_2: 0.8625 - recall_2: 0.7188 - precision_2: 0.6886 - auc_2: 0.7795 - val_loss: 0.4756 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9383 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.8519 - val_precision_2: 0.7582 - val_auc_2: 0.8809\n",
            "Epoch 108/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5712 - accuracy: 0.7014 - sensitivity_at_specificity_2: 0.8531 - specificity_at_sensitivity_2: 0.8483 - recall_2: 0.7552 - precision_2: 0.6792 - auc_2: 0.7778\n",
            "Epoch 108: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5507 - accuracy: 0.7156 - sensitivity_at_specificity_2: 0.8780 - specificity_at_sensitivity_2: 0.8654 - recall_2: 0.7622 - precision_2: 0.7062 - auc_2: 0.7947 - val_loss: 0.5450 - val_accuracy: 0.6625 - val_sensitivity_at_specificity_2: 0.8642 - val_specificity_at_sensitivity_2: 0.9494 - val_recall_2: 0.8889 - val_precision_2: 0.6154 - val_auc_2: 0.8511\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5483 - accuracy: 0.7000 - sensitivity_at_specificity_2: 0.8443 - specificity_at_sensitivity_2: 0.9020 - recall_2: 0.7365 - precision_2: 0.7029 - auc_2: 0.7962\n",
            "Epoch 109: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5483 - accuracy: 0.7000 - sensitivity_at_specificity_2: 0.8443 - specificity_at_sensitivity_2: 0.9020 - recall_2: 0.7365 - precision_2: 0.7029 - auc_2: 0.7962 - val_loss: 0.5377 - val_accuracy: 0.7125 - val_sensitivity_at_specificity_2: 0.9500 - val_specificity_at_sensitivity_2: 0.8750 - val_recall_2: 0.8875 - val_precision_2: 0.6574 - val_auc_2: 0.8199\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5505 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8874 - specificity_at_sensitivity_2: 0.8757 - recall_2: 0.6424 - precision_2: 0.7185 - auc_2: 0.7955\n",
            "Epoch 110: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5505 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8874 - specificity_at_sensitivity_2: 0.8757 - recall_2: 0.6424 - precision_2: 0.7185 - auc_2: 0.7955 - val_loss: 0.5373 - val_accuracy: 0.7063 - val_sensitivity_at_specificity_2: 0.8734 - val_specificity_at_sensitivity_2: 0.9630 - val_recall_2: 0.8228 - val_precision_2: 0.6633 - val_auc_2: 0.8381\n",
            "Epoch 111/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5683 - accuracy: 0.7257 - sensitivity_at_specificity_2: 0.8444 - specificity_at_sensitivity_2: 0.8954 - recall_2: 0.8222 - precision_2: 0.6687 - auc_2: 0.7937\n",
            "Epoch 111: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5739 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8258 - specificity_at_sensitivity_2: 0.8848 - recall_2: 0.7806 - precision_2: 0.6836 - auc_2: 0.7821 - val_loss: 0.5132 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9296 - val_specificity_at_sensitivity_2: 0.9101 - val_recall_2: 0.7606 - val_precision_2: 0.7397 - val_auc_2: 0.8407\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5204 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9125 - specificity_at_sensitivity_2: 0.9125 - recall_2: 0.7812 - precision_2: 0.7310 - auc_2: 0.8233\n",
            "Epoch 112: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5204 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9125 - specificity_at_sensitivity_2: 0.9125 - recall_2: 0.7812 - precision_2: 0.7310 - auc_2: 0.8233 - val_loss: 0.5670 - val_accuracy: 0.7188 - val_sensitivity_at_specificity_2: 0.9070 - val_specificity_at_sensitivity_2: 0.8378 - val_recall_2: 0.9186 - val_precision_2: 0.6752 - val_auc_2: 0.7899\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6004 - accuracy: 0.6625 - sensitivity_at_specificity_2: 0.7892 - specificity_at_sensitivity_2: 0.8506 - recall_2: 0.6807 - precision_2: 0.6726 - auc_2: 0.7388\n",
            "Epoch 113: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6004 - accuracy: 0.6625 - sensitivity_at_specificity_2: 0.7892 - specificity_at_sensitivity_2: 0.8506 - recall_2: 0.6807 - precision_2: 0.6726 - auc_2: 0.7388 - val_loss: 0.5742 - val_accuracy: 0.6687 - val_sensitivity_at_specificity_2: 0.8904 - val_specificity_at_sensitivity_2: 0.9310 - val_recall_2: 0.8904 - val_precision_2: 0.5909 - val_auc_2: 0.8310\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5155 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8951 - specificity_at_sensitivity_2: 0.9494 - recall_2: 0.7840 - precision_2: 0.7384 - auc_2: 0.8318\n",
            "Epoch 114: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5155 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.8951 - specificity_at_sensitivity_2: 0.9494 - recall_2: 0.7840 - precision_2: 0.7384 - auc_2: 0.8318 - val_loss: 0.5108 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9359 - val_specificity_at_sensitivity_2: 0.9634 - val_recall_2: 0.8590 - val_precision_2: 0.7204 - val_auc_2: 0.8698\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5388 - accuracy: 0.7281 - sensitivity_at_specificity_2: 0.9097 - specificity_at_sensitivity_2: 0.9091 - recall_2: 0.6645 - precision_2: 0.7464 - auc_2: 0.8090\n",
            "Epoch 115: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5388 - accuracy: 0.7281 - sensitivity_at_specificity_2: 0.9097 - specificity_at_sensitivity_2: 0.9091 - recall_2: 0.6645 - precision_2: 0.7464 - auc_2: 0.8090 - val_loss: 0.4800 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9565 - val_specificity_at_sensitivity_2: 0.9560 - val_recall_2: 0.8841 - val_precision_2: 0.6489 - val_auc_2: 0.8815\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5469 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8773 - specificity_at_sensitivity_2: 0.8662 - recall_2: 0.7669 - precision_2: 0.6983 - auc_2: 0.7972\n",
            "Epoch 116: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5469 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8773 - specificity_at_sensitivity_2: 0.8662 - recall_2: 0.7669 - precision_2: 0.6983 - auc_2: 0.7972 - val_loss: 0.4988 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9318 - val_specificity_at_sensitivity_2: 0.9861 - val_recall_2: 0.8523 - val_precision_2: 0.7500 - val_auc_2: 0.8502\n",
            "Epoch 117/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5712 - accuracy: 0.6910 - sensitivity_at_specificity_2: 0.8298 - specificity_at_sensitivity_2: 0.8503 - recall_2: 0.6950 - precision_2: 0.6806 - auc_2: 0.7708\n",
            "Epoch 117: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5701 - accuracy: 0.6906 - sensitivity_at_specificity_2: 0.8165 - specificity_at_sensitivity_2: 0.8704 - recall_2: 0.6899 - precision_2: 0.6855 - auc_2: 0.7712 - val_loss: 0.4972 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9487 - val_specificity_at_sensitivity_2: 0.9512 - val_recall_2: 0.9359 - val_precision_2: 0.6697 - val_auc_2: 0.8877\n",
            "Epoch 118/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5125 - accuracy: 0.7118 - sensitivity_at_specificity_2: 0.9281 - specificity_at_sensitivity_2: 0.9329 - recall_2: 0.6619 - precision_2: 0.7188 - auc_2: 0.8345\n",
            "Epoch 118: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5039 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.9481 - specificity_at_sensitivity_2: 0.9337 - recall_2: 0.6753 - precision_2: 0.7222 - auc_2: 0.8405 - val_loss: 0.4758 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 0.9605 - val_recall_2: 0.9167 - val_precision_2: 0.7404 - val_auc_2: 0.8824\n",
            "Epoch 119/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5391 - accuracy: 0.7257 - sensitivity_at_specificity_2: 0.8774 - specificity_at_sensitivity_2: 0.8647 - recall_2: 0.7806 - precision_2: 0.7289 - auc_2: 0.7996\n",
            "Epoch 119: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5481 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8786 - specificity_at_sensitivity_2: 0.8639 - recall_2: 0.7746 - precision_2: 0.7322 - auc_2: 0.7953 - val_loss: 0.5491 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9103 - val_specificity_at_sensitivity_2: 0.9512 - val_recall_2: 0.8590 - val_precision_2: 0.6700 - val_auc_2: 0.8281\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5209 - accuracy: 0.7156 - sensitivity_at_specificity_2: 0.8882 - specificity_at_sensitivity_2: 0.9119 - recall_2: 0.7329 - precision_2: 0.7108 - auc_2: 0.8189\n",
            "Epoch 120: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5209 - accuracy: 0.7156 - sensitivity_at_specificity_2: 0.8882 - specificity_at_sensitivity_2: 0.9119 - recall_2: 0.7329 - precision_2: 0.7108 - auc_2: 0.8189 - val_loss: 0.4782 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9529 - val_specificity_at_sensitivity_2: 0.9467 - val_recall_2: 0.8471 - val_precision_2: 0.7500 - val_auc_2: 0.8675\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.7281 - sensitivity_at_specificity_2: 0.9050 - specificity_at_sensitivity_2: 0.8936 - recall_2: 0.7765 - precision_2: 0.7473 - auc_2: 0.8000\n",
            "Epoch 121: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5481 - accuracy: 0.7281 - sensitivity_at_specificity_2: 0.9050 - specificity_at_sensitivity_2: 0.8936 - recall_2: 0.7765 - precision_2: 0.7473 - auc_2: 0.8000 - val_loss: 0.4659 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 0.9620 - val_recall_2: 0.8642 - val_precision_2: 0.7609 - val_auc_2: 0.8795\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9310 - specificity_at_sensitivity_2: 0.9314 - recall_2: 0.7793 - precision_2: 0.7483 - auc_2: 0.8518\n",
            "Epoch 122: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4893 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9310 - specificity_at_sensitivity_2: 0.9314 - recall_2: 0.7793 - precision_2: 0.7483 - auc_2: 0.8518 - val_loss: 0.4716 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9315 - val_specificity_at_sensitivity_2: 0.9655 - val_recall_2: 0.8219 - val_precision_2: 0.7595 - val_auc_2: 0.8791\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9384 - specificity_at_sensitivity_2: 0.9195 - recall_2: 0.7055 - precision_2: 0.7863 - auc_2: 0.8491\n",
            "Epoch 123: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4889 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9384 - specificity_at_sensitivity_2: 0.9195 - recall_2: 0.7055 - precision_2: 0.7863 - auc_2: 0.8491 - val_loss: 0.5297 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.8916 - val_specificity_at_sensitivity_2: 0.9351 - val_recall_2: 0.8795 - val_precision_2: 0.6822 - val_auc_2: 0.8399\n",
            "Epoch 124/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5031 - accuracy: 0.7708 - sensitivity_at_specificity_2: 0.8913 - specificity_at_sensitivity_2: 0.9400 - recall_2: 0.8188 - precision_2: 0.7338 - auc_2: 0.8453\n",
            "Epoch 124: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5045 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9020 - specificity_at_sensitivity_2: 0.9401 - recall_2: 0.7908 - precision_2: 0.7423 - auc_2: 0.8409 - val_loss: 0.4665 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 0.9737 - val_recall_2: 0.8095 - val_precision_2: 0.7640 - val_auc_2: 0.8768\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5432 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8841 - specificity_at_sensitivity_2: 0.8974 - recall_2: 0.7134 - precision_2: 0.7405 - auc_2: 0.8074\n",
            "Epoch 125: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5432 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8841 - specificity_at_sensitivity_2: 0.8974 - recall_2: 0.7134 - precision_2: 0.7405 - auc_2: 0.8074 - val_loss: 0.5186 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9231 - val_specificity_at_sensitivity_2: 0.9275 - val_recall_2: 0.9341 - val_precision_2: 0.6911 - val_auc_2: 0.8493\n",
            "Epoch 126/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5520 - accuracy: 0.7396 - sensitivity_at_specificity_2: 0.9026 - specificity_at_sensitivity_2: 0.8806 - recall_2: 0.7922 - precision_2: 0.7394 - auc_2: 0.7954\n",
            "Epoch 126: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5495 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.9006 - specificity_at_sensitivity_2: 0.8926 - recall_2: 0.7836 - precision_2: 0.7403 - auc_2: 0.7981 - val_loss: 0.5273 - val_accuracy: 0.7125 - val_sensitivity_at_specificity_2: 0.9067 - val_specificity_at_sensitivity_2: 0.9529 - val_recall_2: 0.8400 - val_precision_2: 0.6495 - val_auc_2: 0.8400\n",
            "Epoch 127/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5059 - accuracy: 0.7639 - sensitivity_at_specificity_2: 0.9306 - specificity_at_sensitivity_2: 0.9375 - recall_2: 0.7639 - precision_2: 0.7639 - auc_2: 0.8408\n",
            "Epoch 127: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5223 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9286 - specificity_at_sensitivity_2: 0.9157 - recall_2: 0.7532 - precision_2: 0.7389 - auc_2: 0.8237 - val_loss: 0.5032 - val_accuracy: 0.7312 - val_sensitivity_at_specificity_2: 0.9474 - val_specificity_at_sensitivity_2: 0.9643 - val_recall_2: 0.8553 - val_precision_2: 0.6701 - val_auc_2: 0.8581\n",
            "Epoch 128/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5218 - accuracy: 0.7396 - sensitivity_at_specificity_2: 0.9000 - specificity_at_sensitivity_2: 0.9141 - recall_2: 0.7563 - precision_2: 0.7707 - auc_2: 0.8162\n",
            "Epoch 128: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5189 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.9022 - specificity_at_sensitivity_2: 0.9118 - recall_2: 0.7609 - precision_2: 0.7821 - auc_2: 0.8169 - val_loss: 0.5133 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9268 - val_specificity_at_sensitivity_2: 0.9744 - val_recall_2: 0.9024 - val_precision_2: 0.7048 - val_auc_2: 0.8508\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9398 - specificity_at_sensitivity_2: 0.9545 - recall_2: 0.8494 - precision_2: 0.7663 - auc_2: 0.8732\n",
            "Epoch 129: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4539 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9398 - specificity_at_sensitivity_2: 0.9545 - recall_2: 0.8494 - precision_2: 0.7663 - auc_2: 0.8732 - val_loss: 0.4907 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9114 - val_specificity_at_sensitivity_2: 0.9259 - val_recall_2: 0.8228 - val_precision_2: 0.7222 - val_auc_2: 0.8541\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5129 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9067 - specificity_at_sensitivity_2: 0.9118 - recall_2: 0.6800 - precision_2: 0.7338 - auc_2: 0.8242\n",
            "Epoch 130: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5129 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9067 - specificity_at_sensitivity_2: 0.9118 - recall_2: 0.6800 - precision_2: 0.7338 - auc_2: 0.8242 - val_loss: 0.4959 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9014 - val_specificity_at_sensitivity_2: 0.9888 - val_recall_2: 0.8873 - val_precision_2: 0.6562 - val_auc_2: 0.8816\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5444 - accuracy: 0.7000 - sensitivity_at_specificity_2: 0.9193 - specificity_at_sensitivity_2: 0.8805 - recall_2: 0.7267 - precision_2: 0.6923 - auc_2: 0.7963\n",
            "Epoch 131: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5444 - accuracy: 0.7000 - sensitivity_at_specificity_2: 0.9193 - specificity_at_sensitivity_2: 0.8805 - recall_2: 0.7267 - precision_2: 0.6923 - auc_2: 0.7963 - val_loss: 0.4816 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.8902 - val_specificity_at_sensitivity_2: 0.9872 - val_recall_2: 0.8293 - val_precision_2: 0.7907 - val_auc_2: 0.8634\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5458 - accuracy: 0.6875 - sensitivity_at_specificity_2: 0.8788 - specificity_at_sensitivity_2: 0.8968 - recall_2: 0.7091 - precision_2: 0.6923 - auc_2: 0.7909\n",
            "Epoch 132: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5458 - accuracy: 0.6875 - sensitivity_at_specificity_2: 0.8788 - specificity_at_sensitivity_2: 0.8968 - recall_2: 0.7091 - precision_2: 0.6923 - auc_2: 0.7909 - val_loss: 0.5048 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 0.9753 - val_recall_2: 0.9494 - val_precision_2: 0.6522 - val_auc_2: 0.8848\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5384 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8741 - specificity_at_sensitivity_2: 0.8865 - recall_2: 0.5630 - precision_2: 0.7600 - auc_2: 0.8032\n",
            "Epoch 133: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5384 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8741 - specificity_at_sensitivity_2: 0.8865 - recall_2: 0.5630 - precision_2: 0.7600 - auc_2: 0.8032 - val_loss: 0.5614 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.8553 - val_specificity_at_sensitivity_2: 0.8810 - val_recall_2: 0.6053 - val_precision_2: 0.7667 - val_auc_2: 0.7964\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5570 - accuracy: 0.7031 - sensitivity_at_specificity_2: 0.8553 - specificity_at_sensitivity_2: 0.8882 - recall_2: 0.7044 - precision_2: 0.7000 - auc_2: 0.7883\n",
            "Epoch 134: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5570 - accuracy: 0.7031 - sensitivity_at_specificity_2: 0.8553 - specificity_at_sensitivity_2: 0.8882 - recall_2: 0.7044 - precision_2: 0.7000 - auc_2: 0.7883 - val_loss: 0.5574 - val_accuracy: 0.7063 - val_sensitivity_at_specificity_2: 0.9231 - val_specificity_at_sensitivity_2: 0.9474 - val_recall_2: 0.8615 - val_precision_2: 0.5957 - val_auc_2: 0.8423\n",
            "Epoch 135/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4725 - accuracy: 0.7569 - sensitivity_at_specificity_2: 0.9310 - specificity_at_sensitivity_2: 0.9650 - recall_2: 0.7655 - precision_2: 0.7551 - auc_2: 0.8707\n",
            "Epoch 135: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4745 - accuracy: 0.7594 - sensitivity_at_specificity_2: 0.9308 - specificity_at_sensitivity_2: 0.9565 - recall_2: 0.7673 - precision_2: 0.7531 - auc_2: 0.8669 - val_loss: 0.4838 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9481 - val_specificity_at_sensitivity_2: 0.9639 - val_recall_2: 0.8831 - val_precision_2: 0.7234 - val_auc_2: 0.8661\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.7156 - sensitivity_at_specificity_2: 0.9226 - specificity_at_sensitivity_2: 0.9091 - recall_2: 0.7355 - precision_2: 0.6951 - auc_2: 0.8117\n",
            "Epoch 136: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.5272 - accuracy: 0.7156 - sensitivity_at_specificity_2: 0.9226 - specificity_at_sensitivity_2: 0.9091 - recall_2: 0.7355 - precision_2: 0.6951 - auc_2: 0.8117 - val_loss: 0.4286 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 1.0000 - val_specificity_at_sensitivity_2: 0.9583 - val_recall_2: 0.9205 - val_precision_2: 0.7642 - val_auc_2: 0.8943\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5209 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9079 - specificity_at_sensitivity_2: 0.9167 - recall_2: 0.7303 - precision_2: 0.7450 - auc_2: 0.8223\n",
            "Epoch 137: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5209 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9079 - specificity_at_sensitivity_2: 0.9167 - recall_2: 0.7303 - precision_2: 0.7450 - auc_2: 0.8223 - val_loss: 0.5463 - val_accuracy: 0.7000 - val_sensitivity_at_specificity_2: 0.8400 - val_specificity_at_sensitivity_2: 0.9294 - val_recall_2: 0.7333 - val_precision_2: 0.6627 - val_auc_2: 0.8004\n",
            "Epoch 138/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4810 - accuracy: 0.7639 - sensitivity_at_specificity_2: 0.8705 - specificity_at_sensitivity_2: 0.9664 - recall_2: 0.7050 - precision_2: 0.7840 - auc_2: 0.8525\n",
            "Epoch 138: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4872 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.8790 - specificity_at_sensitivity_2: 0.9448 - recall_2: 0.7261 - precision_2: 0.7808 - auc_2: 0.8488 - val_loss: 0.4898 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9286 - val_specificity_at_sensitivity_2: 0.9868 - val_recall_2: 0.9048 - val_precision_2: 0.7037 - val_auc_2: 0.8753\n",
            "Epoch 139/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5481 - accuracy: 0.7292 - sensitivity_at_specificity_2: 0.8626 - specificity_at_sensitivity_2: 0.8917 - recall_2: 0.6565 - precision_2: 0.7227 - auc_2: 0.7996\n",
            "Epoch 139: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5449 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.8600 - specificity_at_sensitivity_2: 0.9000 - recall_2: 0.6800 - precision_2: 0.7338 - auc_2: 0.8038 - val_loss: 0.4619 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9740 - val_specificity_at_sensitivity_2: 0.9518 - val_recall_2: 0.8831 - val_precision_2: 0.7158 - val_auc_2: 0.8711\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5261 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8903 - specificity_at_sensitivity_2: 0.9212 - recall_2: 0.7484 - precision_2: 0.6946 - auc_2: 0.8206\n",
            "Epoch 140: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5261 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8903 - specificity_at_sensitivity_2: 0.9212 - recall_2: 0.7484 - precision_2: 0.6946 - auc_2: 0.8206 - val_loss: 0.4528 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9756 - val_specificity_at_sensitivity_2: 0.9487 - val_recall_2: 0.8537 - val_precision_2: 0.7865 - val_auc_2: 0.8918\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5265 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8994 - specificity_at_sensitivity_2: 0.9006 - recall_2: 0.7044 - precision_2: 0.7619 - auc_2: 0.8188\n",
            "Epoch 141: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5265 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8994 - specificity_at_sensitivity_2: 0.9006 - recall_2: 0.7044 - precision_2: 0.7619 - auc_2: 0.8188 - val_loss: 0.5236 - val_accuracy: 0.7312 - val_sensitivity_at_specificity_2: 0.8889 - val_specificity_at_sensitivity_2: 0.9367 - val_recall_2: 0.7778 - val_precision_2: 0.7159 - val_auc_2: 0.8267\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9130 - specificity_at_sensitivity_2: 0.9497 - recall_2: 0.8012 - precision_2: 0.7633 - auc_2: 0.8455\n",
            "Epoch 142: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4922 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9130 - specificity_at_sensitivity_2: 0.9497 - recall_2: 0.8012 - precision_2: 0.7633 - auc_2: 0.8455 - val_loss: 0.4679 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9114 - val_precision_2: 0.6990 - val_auc_2: 0.9012\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.7586 - sensitivity_at_specificity_2: 0.8776 - specificity_at_sensitivity_2: 0.9091 - recall_2: 0.7279 - precision_2: 0.7810 - auc_2: 0.8171\n",
            "Epoch 143: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.5302 - accuracy: 0.7586 - sensitivity_at_specificity_2: 0.8776 - specificity_at_sensitivity_2: 0.9091 - recall_2: 0.7279 - precision_2: 0.7810 - auc_2: 0.8171 - val_loss: 0.5523 - val_accuracy: 0.7000 - val_sensitivity_at_specificity_2: 0.9545 - val_specificity_at_sensitivity_2: 0.9787 - val_recall_2: 0.9545 - val_precision_2: 0.5833 - val_auc_2: 0.8738\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9329 - specificity_at_sensitivity_2: 0.9181 - recall_2: 0.8121 - precision_2: 0.7035 - auc_2: 0.8312\n",
            "Epoch 144: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5230 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9329 - specificity_at_sensitivity_2: 0.9181 - recall_2: 0.8121 - precision_2: 0.7035 - auc_2: 0.8312 - val_loss: 0.5376 - val_accuracy: 0.7312 - val_sensitivity_at_specificity_2: 0.9091 - val_specificity_at_sensitivity_2: 0.9036 - val_recall_2: 0.8052 - val_precision_2: 0.6889 - val_auc_2: 0.8147\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4899 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9404 - specificity_at_sensitivity_2: 0.9467 - recall_2: 0.6821 - precision_2: 0.7863 - auc_2: 0.8490\n",
            "Epoch 145: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4899 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9404 - specificity_at_sensitivity_2: 0.9467 - recall_2: 0.6821 - precision_2: 0.7863 - auc_2: 0.8490 - val_loss: 0.4782 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9634 - val_specificity_at_sensitivity_2: 0.9103 - val_recall_2: 0.8902 - val_precision_2: 0.7300 - val_auc_2: 0.8581\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5939 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.8693 - specificity_at_sensitivity_2: 0.8683 - recall_2: 0.6732 - precision_2: 0.7055 - auc_2: 0.7703\n",
            "Epoch 146: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5939 - accuracy: 0.7094 - sensitivity_at_specificity_2: 0.8693 - specificity_at_sensitivity_2: 0.8683 - recall_2: 0.6732 - precision_2: 0.7055 - auc_2: 0.7703 - val_loss: 0.5150 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9136 - val_specificity_at_sensitivity_2: 0.9367 - val_recall_2: 0.7531 - val_precision_2: 0.7176 - val_auc_2: 0.8272\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5116 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8976 - specificity_at_sensitivity_2: 0.9545 - recall_2: 0.7651 - precision_2: 0.7471 - auc_2: 0.8289\n",
            "Epoch 147: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5116 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8976 - specificity_at_sensitivity_2: 0.9545 - recall_2: 0.7651 - precision_2: 0.7471 - auc_2: 0.8289 - val_loss: 0.5971 - val_accuracy: 0.6750 - val_sensitivity_at_specificity_2: 0.9123 - val_specificity_at_sensitivity_2: 0.9417 - val_recall_2: 0.9123 - val_precision_2: 0.5253 - val_auc_2: 0.8430\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.7219 - sensitivity_at_specificity_2: 0.9290 - specificity_at_sensitivity_2: 0.9470 - recall_2: 0.7574 - precision_2: 0.7273 - auc_2: 0.8354\n",
            "Epoch 148: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5065 - accuracy: 0.7219 - sensitivity_at_specificity_2: 0.9290 - specificity_at_sensitivity_2: 0.9470 - recall_2: 0.7574 - precision_2: 0.7273 - auc_2: 0.8354 - val_loss: 0.4348 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9872 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.9487 - val_precision_2: 0.7184 - val_auc_2: 0.9425\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.8944 - specificity_at_sensitivity_2: 0.9245 - recall_2: 0.6832 - precision_2: 0.7692 - auc_2: 0.8240\n",
            "Epoch 149: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.5196 - accuracy: 0.7375 - sensitivity_at_specificity_2: 0.8944 - specificity_at_sensitivity_2: 0.9245 - recall_2: 0.6832 - precision_2: 0.7692 - auc_2: 0.8240 - val_loss: 0.5213 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9286 - val_specificity_at_sensitivity_2: 0.9342 - val_recall_2: 0.9048 - val_precision_2: 0.6909 - val_auc_2: 0.8464\n",
            "Epoch 150/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5455 - accuracy: 0.7326 - sensitivity_at_specificity_2: 0.8973 - specificity_at_sensitivity_2: 0.8592 - recall_2: 0.8082 - precision_2: 0.7066 - auc_2: 0.8064\n",
            "Epoch 150: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5465 - accuracy: 0.7281 - sensitivity_at_specificity_2: 0.8889 - specificity_at_sensitivity_2: 0.8671 - recall_2: 0.8025 - precision_2: 0.7027 - auc_2: 0.8027 - val_loss: 0.5102 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9012 - val_specificity_at_sensitivity_2: 0.9620 - val_recall_2: 0.6914 - val_precision_2: 0.7671 - val_auc_2: 0.8307\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4817 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9441 - specificity_at_sensitivity_2: 0.9497 - recall_2: 0.7267 - precision_2: 0.8014 - auc_2: 0.8607\n",
            "Epoch 151: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4817 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9441 - specificity_at_sensitivity_2: 0.9497 - recall_2: 0.7267 - precision_2: 0.8014 - auc_2: 0.8607 - val_loss: 0.5438 - val_accuracy: 0.6938 - val_sensitivity_at_specificity_2: 0.8902 - val_specificity_at_sensitivity_2: 0.9359 - val_recall_2: 0.9024 - val_precision_2: 0.6435 - val_auc_2: 0.8412\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5184 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8797 - specificity_at_sensitivity_2: 0.9321 - recall_2: 0.7722 - precision_2: 0.7219 - auc_2: 0.8221\n",
            "Epoch 152: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5184 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8797 - specificity_at_sensitivity_2: 0.9321 - recall_2: 0.7722 - precision_2: 0.7219 - auc_2: 0.8221 - val_loss: 0.4666 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 0.9512 - val_recall_2: 0.8462 - val_precision_2: 0.7333 - val_auc_2: 0.8805\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8485 - specificity_at_sensitivity_2: 0.9355 - recall_2: 0.7515 - precision_2: 0.7168 - auc_2: 0.7982\n",
            "Epoch 153: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5540 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8485 - specificity_at_sensitivity_2: 0.9355 - recall_2: 0.7515 - precision_2: 0.7168 - auc_2: 0.7982 - val_loss: 0.5220 - val_accuracy: 0.7312 - val_sensitivity_at_specificity_2: 0.8939 - val_specificity_at_sensitivity_2: 0.9787 - val_recall_2: 0.8636 - val_precision_2: 0.6264 - val_auc_2: 0.8510\n",
            "Epoch 154/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4960 - accuracy: 0.7847 - sensitivity_at_specificity_2: 0.8897 - specificity_at_sensitivity_2: 0.9650 - recall_2: 0.7172 - precision_2: 0.8320 - auc_2: 0.8456\n",
            "Epoch 154: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5050 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.8896 - specificity_at_sensitivity_2: 0.9554 - recall_2: 0.7178 - precision_2: 0.8239 - auc_2: 0.8392 - val_loss: 0.4517 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9241 - val_specificity_at_sensitivity_2: 0.9630 - val_recall_2: 0.8354 - val_precision_2: 0.7500 - val_auc_2: 0.8885\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4779 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9241 - specificity_at_sensitivity_2: 0.9259 - recall_2: 0.8165 - precision_2: 0.7500 - auc_2: 0.8563\n",
            "Epoch 155: val_accuracy improved from 0.80625 to 0.81250, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.4779 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9241 - specificity_at_sensitivity_2: 0.9259 - recall_2: 0.8165 - precision_2: 0.7500 - auc_2: 0.8563 - val_loss: 0.4598 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9167 - val_specificity_at_sensitivity_2: 0.9773 - val_recall_2: 0.8611 - val_precision_2: 0.7561 - val_auc_2: 0.8855\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9178 - specificity_at_sensitivity_2: 0.8966 - recall_2: 0.6986 - precision_2: 0.7445 - auc_2: 0.8400\n",
            "Epoch 156: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4892 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9178 - specificity_at_sensitivity_2: 0.8966 - recall_2: 0.6986 - precision_2: 0.7445 - auc_2: 0.8400 - val_loss: 0.4438 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9452 - val_specificity_at_sensitivity_2: 0.9655 - val_recall_2: 0.8219 - val_precision_2: 0.7792 - val_auc_2: 0.8830\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4959 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9177 - specificity_at_sensitivity_2: 0.9321 - recall_2: 0.7785 - precision_2: 0.7785 - auc_2: 0.8466\n",
            "Epoch 157: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4959 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9177 - specificity_at_sensitivity_2: 0.9321 - recall_2: 0.7785 - precision_2: 0.7785 - auc_2: 0.8466 - val_loss: 0.4199 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9780 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9121 - val_precision_2: 0.7757 - val_auc_2: 0.9056\n",
            "Epoch 158/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4807 - accuracy: 0.7569 - sensitivity_at_specificity_2: 0.9346 - specificity_at_sensitivity_2: 0.9481 - recall_2: 0.7320 - precision_2: 0.7943 - auc_2: 0.8559\n",
            "Epoch 158: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4775 - accuracy: 0.7594 - sensitivity_at_specificity_2: 0.9349 - specificity_at_sensitivity_2: 0.9470 - recall_2: 0.7337 - precision_2: 0.7949 - auc_2: 0.8579 - val_loss: 0.4437 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 0.9474 - val_recall_2: 0.8929 - val_precision_2: 0.7576 - val_auc_2: 0.8917\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9181 - specificity_at_sensitivity_2: 0.9060 - recall_2: 0.8187 - precision_2: 0.7216 - auc_2: 0.8305\n",
            "Epoch 159: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5134 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9181 - specificity_at_sensitivity_2: 0.9060 - recall_2: 0.8187 - precision_2: 0.7216 - auc_2: 0.8305 - val_loss: 0.4650 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9344 - val_specificity_at_sensitivity_2: 0.9596 - val_recall_2: 0.8361 - val_precision_2: 0.6711 - val_auc_2: 0.8801\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.7594 - sensitivity_at_specificity_2: 0.9351 - specificity_at_sensitivity_2: 0.9398 - recall_2: 0.6753 - precision_2: 0.7939 - auc_2: 0.8402\n",
            "Epoch 160: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.4980 - accuracy: 0.7594 - sensitivity_at_specificity_2: 0.9351 - specificity_at_sensitivity_2: 0.9398 - recall_2: 0.6753 - precision_2: 0.7939 - auc_2: 0.8402 - val_loss: 0.4591 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 0.9737 - val_recall_2: 0.8333 - val_precision_2: 0.7216 - val_auc_2: 0.8769\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4896 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.8873 - specificity_at_sensitivity_2: 0.9270 - recall_2: 0.7394 - precision_2: 0.7447 - auc_2: 0.8409\n",
            "Epoch 161: val_accuracy improved from 0.81250 to 0.85000, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4896 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.8873 - specificity_at_sensitivity_2: 0.9270 - recall_2: 0.7394 - precision_2: 0.7447 - auc_2: 0.8409 - val_loss: 0.4094 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9730 - val_specificity_at_sensitivity_2: 0.9651 - val_recall_2: 0.7838 - val_precision_2: 0.8788 - val_auc_2: 0.9192\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8767 - specificity_at_sensitivity_2: 0.8793 - recall_2: 0.6918 - precision_2: 0.7319 - auc_2: 0.8040\n",
            "Epoch 162: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5429 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8767 - specificity_at_sensitivity_2: 0.8793 - recall_2: 0.6918 - precision_2: 0.7319 - auc_2: 0.8040 - val_loss: 0.4880 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9714 - val_specificity_at_sensitivity_2: 0.9333 - val_recall_2: 0.9000 - val_precision_2: 0.6923 - val_auc_2: 0.8722\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4713 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9438 - specificity_at_sensitivity_2: 0.9312 - recall_2: 0.7750 - precision_2: 0.8212 - auc_2: 0.8655\n",
            "Epoch 163: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4713 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9438 - specificity_at_sensitivity_2: 0.9312 - recall_2: 0.7750 - precision_2: 0.8212 - auc_2: 0.8655 - val_loss: 0.4495 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9467 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8667 - val_precision_2: 0.7303 - val_auc_2: 0.8949\n",
            "Epoch 164/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5408 - accuracy: 0.7461 - sensitivity_at_specificity_2: 0.8682 - specificity_at_sensitivity_2: 0.8976 - recall_2: 0.7829 - precision_2: 0.7319 - auc_2: 0.8122\n",
            "Epoch 164: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.5420 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8718 - specificity_at_sensitivity_2: 0.9024 - recall_2: 0.7756 - precision_2: 0.7202 - auc_2: 0.8109 - val_loss: 0.4854 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9589 - val_specificity_at_sensitivity_2: 0.9195 - val_recall_2: 0.8630 - val_precision_2: 0.7326 - val_auc_2: 0.8687\n",
            "Epoch 165/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4636 - accuracy: 0.8056 - sensitivity_at_specificity_2: 0.9189 - specificity_at_sensitivity_2: 0.9786 - recall_2: 0.7230 - precision_2: 0.8770 - auc_2: 0.8737\n",
            "Epoch 165: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4694 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9250 - specificity_at_sensitivity_2: 0.9750 - recall_2: 0.7375 - precision_2: 0.8369 - auc_2: 0.8653 - val_loss: 0.4768 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9595 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8784 - val_precision_2: 0.6842 - val_auc_2: 0.8913\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8616 - specificity_at_sensitivity_2: 0.9193 - recall_2: 0.7107 - precision_2: 0.7290 - auc_2: 0.8054\n",
            "Epoch 166: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5377 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8616 - specificity_at_sensitivity_2: 0.9193 - recall_2: 0.7107 - precision_2: 0.7290 - auc_2: 0.8054 - val_loss: 0.4934 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9294 - val_specificity_at_sensitivity_2: 0.9467 - val_recall_2: 0.7882 - val_precision_2: 0.8072 - val_auc_2: 0.8435\n",
            "Epoch 167/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4862 - accuracy: 0.7431 - sensitivity_at_specificity_2: 0.9441 - specificity_at_sensitivity_2: 0.9379 - recall_2: 0.7063 - precision_2: 0.7594 - auc_2: 0.8487\n",
            "Epoch 167: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4922 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.9312 - specificity_at_sensitivity_2: 0.9312 - recall_2: 0.7125 - precision_2: 0.7600 - auc_2: 0.8432 - val_loss: 0.5522 - val_accuracy: 0.6750 - val_sensitivity_at_specificity_2: 0.8442 - val_specificity_at_sensitivity_2: 0.9277 - val_recall_2: 0.8312 - val_precision_2: 0.6214 - val_auc_2: 0.8269\n",
            "Epoch 168/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4768 - accuracy: 0.7743 - sensitivity_at_specificity_2: 0.9353 - specificity_at_sensitivity_2: 0.9396 - recall_2: 0.7410 - precision_2: 0.7803 - auc_2: 0.8551\n",
            "Epoch 168: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4788 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9481 - specificity_at_sensitivity_2: 0.9398 - recall_2: 0.7338 - precision_2: 0.7740 - auc_2: 0.8533 - val_loss: 0.4656 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9231 - val_specificity_at_sensitivity_2: 0.9634 - val_recall_2: 0.7821 - val_precision_2: 0.7722 - val_auc_2: 0.8641\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9042 - specificity_at_sensitivity_2: 0.9020 - recall_2: 0.7365 - precision_2: 0.7785 - auc_2: 0.8300\n",
            "Epoch 169: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5045 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.9042 - specificity_at_sensitivity_2: 0.9020 - recall_2: 0.7365 - precision_2: 0.7785 - auc_2: 0.8300 - val_loss: 0.4419 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 0.9753 - val_recall_2: 0.8608 - val_precision_2: 0.7234 - val_auc_2: 0.8864\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4987 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9080 - specificity_at_sensitivity_2: 0.9299 - recall_2: 0.7914 - precision_2: 0.7679 - auc_2: 0.8446\n",
            "Epoch 170: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4987 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9080 - specificity_at_sensitivity_2: 0.9299 - recall_2: 0.7914 - precision_2: 0.7679 - auc_2: 0.8446 - val_loss: 0.4755 - val_accuracy: 0.7312 - val_sensitivity_at_specificity_2: 0.8471 - val_specificity_at_sensitivity_2: 0.9733 - val_recall_2: 0.8118 - val_precision_2: 0.7188 - val_auc_2: 0.8584\n",
            "Epoch 171/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4716 - accuracy: 0.7569 - sensitivity_at_specificity_2: 0.9708 - specificity_at_sensitivity_2: 0.9470 - recall_2: 0.6715 - precision_2: 0.7863 - auc_2: 0.8650\n",
            "Epoch 171: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.4705 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.9600 - specificity_at_sensitivity_2: 0.9647 - recall_2: 0.6933 - precision_2: 0.7647 - auc_2: 0.8615 - val_loss: 0.4663 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 0.9506 - val_recall_2: 0.9367 - val_precision_2: 0.7184 - val_auc_2: 0.8858\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8833 - specificity_at_sensitivity_2: 0.9214 - recall_2: 0.8444 - precision_2: 0.7343 - auc_2: 0.8301\n",
            "Epoch 172: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5057 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8833 - specificity_at_sensitivity_2: 0.9214 - recall_2: 0.8444 - precision_2: 0.7343 - auc_2: 0.8301 - val_loss: 0.5126 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9167 - val_specificity_at_sensitivity_2: 0.9342 - val_recall_2: 0.8571 - val_precision_2: 0.6923 - val_auc_2: 0.8436\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9136 - specificity_at_sensitivity_2: 0.9367 - recall_2: 0.7654 - precision_2: 0.7848 - auc_2: 0.8450\n",
            "Epoch 173: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4970 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9136 - specificity_at_sensitivity_2: 0.9367 - recall_2: 0.7654 - precision_2: 0.7848 - auc_2: 0.8450 - val_loss: 0.4708 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9459 - val_specificity_at_sensitivity_2: 0.9884 - val_recall_2: 0.8514 - val_precision_2: 0.6848 - val_auc_2: 0.8756\n",
            "Epoch 174/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5175 - accuracy: 0.7617 - sensitivity_at_specificity_2: 0.8837 - specificity_at_sensitivity_2: 0.9449 - recall_2: 0.7519 - precision_2: 0.7698 - auc_2: 0.8286\n",
            "Epoch 174: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5071 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.8834 - specificity_at_sensitivity_2: 0.9554 - recall_2: 0.7485 - precision_2: 0.7871 - auc_2: 0.8367 - val_loss: 0.4339 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9877 - val_specificity_at_sensitivity_2: 0.9747 - val_recall_2: 0.8889 - val_precision_2: 0.7579 - val_auc_2: 0.9025\n",
            "Epoch 175/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4408 - accuracy: 0.8047 - sensitivity_at_specificity_2: 0.9492 - specificity_at_sensitivity_2: 0.9783 - recall_2: 0.7797 - precision_2: 0.7931 - auc_2: 0.8807\n",
            "Epoch 175: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4437 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9338 - specificity_at_sensitivity_2: 0.9822 - recall_2: 0.7682 - precision_2: 0.8056 - auc_2: 0.8768 - val_loss: 0.4118 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9571 - val_specificity_at_sensitivity_2: 0.9889 - val_recall_2: 0.8714 - val_precision_2: 0.7349 - val_auc_2: 0.9092\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5644 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8625 - specificity_at_sensitivity_2: 0.9000 - recall_2: 0.6562 - precision_2: 0.7394 - auc_2: 0.7942\n",
            "Epoch 176: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5644 - accuracy: 0.7125 - sensitivity_at_specificity_2: 0.8625 - specificity_at_sensitivity_2: 0.9000 - recall_2: 0.6562 - precision_2: 0.7394 - auc_2: 0.7942 - val_loss: 0.5142 - val_accuracy: 0.7312 - val_sensitivity_at_specificity_2: 0.8721 - val_specificity_at_sensitivity_2: 0.9189 - val_recall_2: 0.8605 - val_precision_2: 0.7048 - val_auc_2: 0.8371\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5514 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.8986 - specificity_at_sensitivity_2: 0.8953 - recall_2: 0.7230 - precision_2: 0.7279 - auc_2: 0.7993\n",
            "Epoch 177: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5514 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.8986 - specificity_at_sensitivity_2: 0.8953 - recall_2: 0.7230 - precision_2: 0.7279 - auc_2: 0.7993 - val_loss: 0.4837 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.8919 - val_specificity_at_sensitivity_2: 0.9767 - val_recall_2: 0.7703 - val_precision_2: 0.7500 - val_auc_2: 0.8689\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.8792 - specificity_at_sensitivity_2: 0.9708 - recall_2: 0.6913 - precision_2: 0.8175 - auc_2: 0.8529\n",
            "Epoch 178: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4795 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.8792 - specificity_at_sensitivity_2: 0.9708 - recall_2: 0.6913 - precision_2: 0.8175 - auc_2: 0.8529 - val_loss: 0.4420 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.8846 - val_precision_2: 0.7500 - val_auc_2: 0.8994\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5169 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8862 - specificity_at_sensitivity_2: 0.9346 - recall_2: 0.7545 - precision_2: 0.7500 - auc_2: 0.8232\n",
            "Epoch 179: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5169 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8862 - specificity_at_sensitivity_2: 0.9346 - recall_2: 0.7545 - precision_2: 0.7500 - auc_2: 0.8232 - val_loss: 0.4707 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9744 - val_specificity_at_sensitivity_2: 0.9390 - val_recall_2: 0.8846 - val_precision_2: 0.7113 - val_auc_2: 0.8765\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.9252 - recall_2: 0.7902 - precision_2: 0.8014 - auc_2: 0.8547\n",
            "Epoch 180: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4732 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.9252 - recall_2: 0.7902 - precision_2: 0.8014 - auc_2: 0.8547 - val_loss: 0.4523 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 0.9494 - val_recall_2: 0.9259 - val_precision_2: 0.7143 - val_auc_2: 0.9061\n",
            "Epoch 181/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5419 - accuracy: 0.7383 - sensitivity_at_specificity_2: 0.8739 - specificity_at_sensitivity_2: 0.9197 - recall_2: 0.7311 - precision_2: 0.7131 - auc_2: 0.8067\n",
            "Epoch 181: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5328 - accuracy: 0.7437 - sensitivity_at_specificity_2: 0.8805 - specificity_at_sensitivity_2: 0.9130 - recall_2: 0.7296 - precision_2: 0.7484 - auc_2: 0.8133 - val_loss: 0.4527 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9259 - val_specificity_at_sensitivity_2: 0.9620 - val_recall_2: 0.8272 - val_precision_2: 0.7614 - val_auc_2: 0.8743\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5069 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.9080 - specificity_at_sensitivity_2: 0.9363 - recall_2: 0.8282 - precision_2: 0.7219 - auc_2: 0.8349\n",
            "Epoch 182: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5069 - accuracy: 0.7500 - sensitivity_at_specificity_2: 0.9080 - specificity_at_sensitivity_2: 0.9363 - recall_2: 0.8282 - precision_2: 0.7219 - auc_2: 0.8349 - val_loss: 0.5222 - val_accuracy: 0.7188 - val_sensitivity_at_specificity_2: 0.9268 - val_specificity_at_sensitivity_2: 0.9231 - val_recall_2: 0.8659 - val_precision_2: 0.6762 - val_auc_2: 0.8316\n",
            "Epoch 183/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5419 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8643 - specificity_at_sensitivity_2: 0.9257 - recall_2: 0.6500 - precision_2: 0.7398 - auc_2: 0.8045\n",
            "Epoch 183: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5279 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.8758 - specificity_at_sensitivity_2: 0.9341 - recall_2: 0.6536 - precision_2: 0.7519 - auc_2: 0.8145 - val_loss: 0.5018 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.8831 - val_specificity_at_sensitivity_2: 0.9759 - val_recall_2: 0.8442 - val_precision_2: 0.6701 - val_auc_2: 0.8564\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9080 - specificity_at_sensitivity_2: 0.9236 - recall_2: 0.7914 - precision_2: 0.7330 - auc_2: 0.8289\n",
            "Epoch 184: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5042 - accuracy: 0.7469 - sensitivity_at_specificity_2: 0.9080 - specificity_at_sensitivity_2: 0.9236 - recall_2: 0.7914 - precision_2: 0.7330 - auc_2: 0.8289 - val_loss: 0.4814 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9213 - val_specificity_at_sensitivity_2: 0.9437 - val_recall_2: 0.9101 - val_precision_2: 0.7570 - val_auc_2: 0.8688\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.9036 - recall_2: 0.6558 - precision_2: 0.8016 - auc_2: 0.8201\n",
            "Epoch 185: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5269 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.9036 - recall_2: 0.6558 - precision_2: 0.8016 - auc_2: 0.8201 - val_loss: 0.4057 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9744 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8590 - val_precision_2: 0.7528 - val_auc_2: 0.9128\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4935 - accuracy: 0.7594 - sensitivity_at_specificity_2: 0.9185 - specificity_at_sensitivity_2: 0.9191 - recall_2: 0.8641 - precision_2: 0.7536 - auc_2: 0.8433\n",
            "Epoch 186: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4935 - accuracy: 0.7594 - sensitivity_at_specificity_2: 0.9185 - specificity_at_sensitivity_2: 0.9191 - recall_2: 0.8641 - precision_2: 0.7536 - auc_2: 0.8433 - val_loss: 0.5186 - val_accuracy: 0.7063 - val_sensitivity_at_specificity_2: 0.9136 - val_specificity_at_sensitivity_2: 0.9747 - val_recall_2: 0.9136 - val_precision_2: 0.6491 - val_auc_2: 0.8572\n",
            "Epoch 187/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4837 - accuracy: 0.7597 - sensitivity_at_specificity_2: 0.9244 - specificity_at_sensitivity_2: 0.9424 - recall_2: 0.6639 - precision_2: 0.7822 - auc_2: 0.8457\n",
            "Epoch 187: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4985 - accuracy: 0.7414 - sensitivity_at_specificity_2: 0.9051 - specificity_at_sensitivity_2: 0.9412 - recall_2: 0.6204 - precision_2: 0.7870 - auc_2: 0.8332 - val_loss: 0.4598 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9630 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.7037 - val_precision_2: 0.9194 - val_auc_2: 0.9032\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5156 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8940 - specificity_at_sensitivity_2: 0.9172 - recall_2: 0.7020 - precision_2: 0.7361 - auc_2: 0.8213\n",
            "Epoch 188: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5156 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8940 - specificity_at_sensitivity_2: 0.9172 - recall_2: 0.7020 - precision_2: 0.7361 - auc_2: 0.8213 - val_loss: 0.5273 - val_accuracy: 0.7250 - val_sensitivity_at_specificity_2: 0.9178 - val_specificity_at_sensitivity_2: 0.9655 - val_recall_2: 0.8630 - val_precision_2: 0.6495 - val_auc_2: 0.8671\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5169 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8917 - specificity_at_sensitivity_2: 0.9202 - recall_2: 0.6752 - precision_2: 0.7681 - auc_2: 0.8251\n",
            "Epoch 189: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5169 - accuracy: 0.7406 - sensitivity_at_specificity_2: 0.8917 - specificity_at_sensitivity_2: 0.9202 - recall_2: 0.6752 - precision_2: 0.7681 - auc_2: 0.8251 - val_loss: 0.4132 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.8148 - val_precision_2: 0.8571 - val_auc_2: 0.9055\n",
            "Epoch 190/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4719 - accuracy: 0.7778 - sensitivity_at_specificity_2: 0.9310 - specificity_at_sensitivity_2: 0.9790 - recall_2: 0.8069 - precision_2: 0.7647 - auc_2: 0.8603\n",
            "Epoch 190: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4665 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9427 - specificity_at_sensitivity_2: 0.9755 - recall_2: 0.8089 - precision_2: 0.7605 - auc_2: 0.8652 - val_loss: 0.3972 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9211 - val_specificity_at_sensitivity_2: 0.9881 - val_recall_2: 0.8816 - val_precision_2: 0.7976 - val_auc_2: 0.9174\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9329 - specificity_at_sensitivity_2: 0.9808 - recall_2: 0.7866 - precision_2: 0.8431 - auc_2: 0.8769\n",
            "Epoch 191: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4399 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9329 - specificity_at_sensitivity_2: 0.9808 - recall_2: 0.7866 - precision_2: 0.8431 - auc_2: 0.8769 - val_loss: 0.4352 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9759 - val_specificity_at_sensitivity_2: 0.9351 - val_recall_2: 0.7831 - val_precision_2: 0.8125 - val_auc_2: 0.8883\n",
            "Epoch 192/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4888 - accuracy: 0.7847 - sensitivity_at_specificity_2: 0.9058 - specificity_at_sensitivity_2: 0.9200 - recall_2: 0.7391 - precision_2: 0.7969 - auc_2: 0.8444\n",
            "Epoch 192: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4799 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9103 - specificity_at_sensitivity_2: 0.9512 - recall_2: 0.7436 - precision_2: 0.8056 - auc_2: 0.8511 - val_loss: 0.4744 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9194 - val_specificity_at_sensitivity_2: 0.9694 - val_recall_2: 0.8871 - val_precision_2: 0.6790 - val_auc_2: 0.8844\n",
            "Epoch 193/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4203 - accuracy: 0.8299 - sensitivity_at_specificity_2: 0.9733 - specificity_at_sensitivity_2: 0.9348 - recall_2: 0.8667 - precision_2: 0.8176 - auc_2: 0.8960\n",
            "Epoch 193: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4217 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9762 - specificity_at_sensitivity_2: 0.9408 - recall_2: 0.8631 - precision_2: 0.8192 - auc_2: 0.8953 - val_loss: 0.5371 - val_accuracy: 0.7063 - val_sensitivity_at_specificity_2: 0.8734 - val_specificity_at_sensitivity_2: 0.9506 - val_recall_2: 0.8734 - val_precision_2: 0.6509 - val_auc_2: 0.8476\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5115 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.8839 - specificity_at_sensitivity_2: 0.9333 - recall_2: 0.7290 - precision_2: 0.7793 - auc_2: 0.8352\n",
            "Epoch 194: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5115 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.8839 - specificity_at_sensitivity_2: 0.9333 - recall_2: 0.7290 - precision_2: 0.7793 - auc_2: 0.8352 - val_loss: 0.4259 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9545 - val_specificity_at_sensitivity_2: 0.9722 - val_recall_2: 0.9091 - val_precision_2: 0.7692 - val_auc_2: 0.9018\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.8882 - specificity_at_sensitivity_2: 0.9467 - recall_2: 0.7235 - precision_2: 0.7987 - auc_2: 0.8361\n",
            "Epoch 195: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5030 - accuracy: 0.7563 - sensitivity_at_specificity_2: 0.8882 - specificity_at_sensitivity_2: 0.9467 - recall_2: 0.7235 - precision_2: 0.7987 - auc_2: 0.8361 - val_loss: 0.4771 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9167 - val_specificity_at_sensitivity_2: 0.9474 - val_recall_2: 0.8095 - val_precision_2: 0.7727 - val_auc_2: 0.8557\n",
            "Epoch 196/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4903 - accuracy: 0.8021 - sensitivity_at_specificity_2: 0.9037 - specificity_at_sensitivity_2: 0.9150 - recall_2: 0.8074 - precision_2: 0.7786 - auc_2: 0.8483\n",
            "Epoch 196: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4883 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.9217 - recall_2: 0.7727 - precision_2: 0.7933 - auc_2: 0.8480 - val_loss: 0.4484 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9583 - val_specificity_at_sensitivity_2: 0.9659 - val_recall_2: 0.7778 - val_precision_2: 0.8116 - val_auc_2: 0.8868\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9618 - specificity_at_sensitivity_2: 0.9387 - recall_2: 0.8153 - precision_2: 0.8421 - auc_2: 0.8852\n",
            "Epoch 197: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4366 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9618 - specificity_at_sensitivity_2: 0.9387 - recall_2: 0.8153 - precision_2: 0.8421 - auc_2: 0.8852 - val_loss: 0.4605 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 0.9474 - val_recall_2: 0.9167 - val_precision_2: 0.7476 - val_auc_2: 0.8758\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9371 - specificity_at_sensitivity_2: 0.9565 - recall_2: 0.7044 - precision_2: 0.7943 - auc_2: 0.8607\n",
            "Epoch 198: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4645 - accuracy: 0.7625 - sensitivity_at_specificity_2: 0.9371 - specificity_at_sensitivity_2: 0.9565 - recall_2: 0.7044 - precision_2: 0.7943 - auc_2: 0.8607 - val_loss: 0.5260 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.8941 - val_specificity_at_sensitivity_2: 0.9067 - val_recall_2: 0.8588 - val_precision_2: 0.7228 - val_auc_2: 0.8264\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9161 - specificity_at_sensitivity_2: 0.9515 - recall_2: 0.7548 - precision_2: 0.7134 - auc_2: 0.8387\n",
            "Epoch 199: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5001 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9161 - specificity_at_sensitivity_2: 0.9515 - recall_2: 0.7548 - precision_2: 0.7134 - auc_2: 0.8387 - val_loss: 0.4272 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9773 - val_specificity_at_sensitivity_2: 0.9722 - val_recall_2: 0.7386 - val_precision_2: 0.8904 - val_auc_2: 0.9114\n",
            "Epoch 200/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5445 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8889 - specificity_at_sensitivity_2: 0.9037 - recall_2: 0.6471 - precision_2: 0.7857 - auc_2: 0.8104\n",
            "Epoch 200: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5369 - accuracy: 0.7219 - sensitivity_at_specificity_2: 0.8916 - specificity_at_sensitivity_2: 0.8896 - recall_2: 0.6747 - precision_2: 0.7619 - auc_2: 0.8099 - val_loss: 0.5261 - val_accuracy: 0.7312 - val_sensitivity_at_specificity_2: 0.9101 - val_specificity_at_sensitivity_2: 0.9437 - val_recall_2: 0.9101 - val_precision_2: 0.6983 - val_auc_2: 0.8262\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8596 - specificity_at_sensitivity_2: 0.9128 - recall_2: 0.7544 - precision_2: 0.7288 - auc_2: 0.7993\n",
            "Epoch 201: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5493 - accuracy: 0.7188 - sensitivity_at_specificity_2: 0.8596 - specificity_at_sensitivity_2: 0.9128 - recall_2: 0.7544 - precision_2: 0.7288 - auc_2: 0.7993 - val_loss: 0.4982 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9054 - val_specificity_at_sensitivity_2: 0.9302 - val_recall_2: 0.8514 - val_precision_2: 0.7241 - val_auc_2: 0.8543\n",
            "Epoch 202/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4946 - accuracy: 0.7812 - sensitivity_at_specificity_2: 0.9091 - specificity_at_sensitivity_2: 0.9254 - recall_2: 0.7597 - precision_2: 0.8182 - auc_2: 0.8480\n",
            "Epoch 202: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4943 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9143 - specificity_at_sensitivity_2: 0.9310 - recall_2: 0.7657 - precision_2: 0.8121 - auc_2: 0.8460 - val_loss: 0.4539 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9610 - val_specificity_at_sensitivity_2: 0.9518 - val_recall_2: 0.8831 - val_precision_2: 0.7312 - val_auc_2: 0.9028\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5069 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9097 - specificity_at_sensitivity_2: 0.9205 - recall_2: 0.7708 - precision_2: 0.7762 - auc_2: 0.8389\n",
            "Epoch 203: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5069 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9097 - specificity_at_sensitivity_2: 0.9205 - recall_2: 0.7708 - precision_2: 0.7762 - auc_2: 0.8389 - val_loss: 0.4520 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9432 - val_specificity_at_sensitivity_2: 0.9444 - val_recall_2: 0.8977 - val_precision_2: 0.7980 - val_auc_2: 0.8821\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9216 - specificity_at_sensitivity_2: 0.9102 - recall_2: 0.7386 - precision_2: 0.7740 - auc_2: 0.8561\n",
            "Epoch 204: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4746 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9216 - specificity_at_sensitivity_2: 0.9102 - recall_2: 0.7386 - precision_2: 0.7740 - auc_2: 0.8561 - val_loss: 0.5134 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.8816 - val_specificity_at_sensitivity_2: 0.9524 - val_recall_2: 0.7237 - val_precision_2: 0.7333 - val_auc_2: 0.8222\n",
            "Epoch 205/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4606 - accuracy: 0.7917 - sensitivity_at_specificity_2: 0.9362 - specificity_at_sensitivity_2: 0.9592 - recall_2: 0.7518 - precision_2: 0.8092 - auc_2: 0.8699\n",
            "Epoch 205: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4608 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9281 - specificity_at_sensitivity_2: 0.9581 - recall_2: 0.7451 - precision_2: 0.7972 - auc_2: 0.8666 - val_loss: 0.4617 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9412 - val_specificity_at_sensitivity_2: 0.9733 - val_recall_2: 0.8118 - val_precision_2: 0.7500 - val_auc_2: 0.8658\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8896 - specificity_at_sensitivity_2: 0.9217 - recall_2: 0.6883 - precision_2: 0.7260 - auc_2: 0.8222\n",
            "Epoch 206: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.5185 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8896 - specificity_at_sensitivity_2: 0.9217 - recall_2: 0.6883 - precision_2: 0.7260 - auc_2: 0.8222 - val_loss: 0.4793 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9231 - val_specificity_at_sensitivity_2: 0.9684 - val_recall_2: 0.8000 - val_precision_2: 0.6753 - val_auc_2: 0.8636\n",
            "Epoch 207/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5243 - accuracy: 0.7396 - sensitivity_at_specificity_2: 0.8590 - specificity_at_sensitivity_2: 0.9394 - recall_2: 0.8077 - precision_2: 0.7368 - auc_2: 0.8229\n",
            "Epoch 207: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.5167 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.8765 - specificity_at_sensitivity_2: 0.9400 - recall_2: 0.8059 - precision_2: 0.7486 - auc_2: 0.8280 - val_loss: 0.4200 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9114 - val_specificity_at_sensitivity_2: 0.9753 - val_recall_2: 0.8101 - val_precision_2: 0.8649 - val_auc_2: 0.8960\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4554 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9193 - specificity_at_sensitivity_2: 0.9623 - recall_2: 0.7516 - precision_2: 0.8231 - auc_2: 0.8712\n",
            "Epoch 208: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4554 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9193 - specificity_at_sensitivity_2: 0.9623 - recall_2: 0.7516 - precision_2: 0.8231 - auc_2: 0.8712 - val_loss: 0.4714 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9512 - val_specificity_at_sensitivity_2: 0.9231 - val_recall_2: 0.9146 - val_precision_2: 0.7426 - val_auc_2: 0.8832\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.8929 - specificity_at_sensitivity_2: 0.9671 - recall_2: 0.7381 - precision_2: 0.7799 - auc_2: 0.8303\n",
            "Epoch 209: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5024 - accuracy: 0.7531 - sensitivity_at_specificity_2: 0.8929 - specificity_at_sensitivity_2: 0.9671 - recall_2: 0.7381 - precision_2: 0.7799 - auc_2: 0.8303 - val_loss: 0.4853 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9351 - val_specificity_at_sensitivity_2: 0.9639 - val_recall_2: 0.8831 - val_precision_2: 0.7158 - val_auc_2: 0.8669\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.9118 - specificity_at_sensitivity_2: 0.8800 - recall_2: 0.7941 - precision_2: 0.7258 - auc_2: 0.8192\n",
            "Epoch 210: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5213 - accuracy: 0.7312 - sensitivity_at_specificity_2: 0.9118 - specificity_at_sensitivity_2: 0.8800 - recall_2: 0.7941 - precision_2: 0.7258 - auc_2: 0.8192 - val_loss: 0.4457 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9136 - val_specificity_at_sensitivity_2: 0.9747 - val_recall_2: 0.8272 - val_precision_2: 0.8171 - val_auc_2: 0.8920\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9338 - specificity_at_sensitivity_2: 0.9645 - recall_2: 0.6291 - precision_2: 0.8482 - auc_2: 0.8810\n",
            "Epoch 211: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4663 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9338 - specificity_at_sensitivity_2: 0.9645 - recall_2: 0.6291 - precision_2: 0.8482 - auc_2: 0.8810 - val_loss: 0.4408 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9535 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9302 - val_precision_2: 0.7207 - val_auc_2: 0.9117\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9172 - specificity_at_sensitivity_2: 0.9448 - recall_2: 0.8280 - precision_2: 0.7386 - auc_2: 0.8481\n",
            "Epoch 212: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4941 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9172 - specificity_at_sensitivity_2: 0.9448 - recall_2: 0.8280 - precision_2: 0.7386 - auc_2: 0.8481 - val_loss: 0.4260 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9259 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.8642 - val_precision_2: 0.8235 - val_auc_2: 0.8994\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5181 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9273 - specificity_at_sensitivity_2: 0.8839 - recall_2: 0.7091 - precision_2: 0.7597 - auc_2: 0.8257\n",
            "Epoch 213: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5181 - accuracy: 0.7344 - sensitivity_at_specificity_2: 0.9273 - specificity_at_sensitivity_2: 0.8839 - recall_2: 0.7091 - precision_2: 0.7597 - auc_2: 0.8257 - val_loss: 0.4539 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9659 - val_specificity_at_sensitivity_2: 0.9583 - val_recall_2: 0.9545 - val_precision_2: 0.7568 - val_auc_2: 0.8961\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5440 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8974 - specificity_at_sensitivity_2: 0.8963 - recall_2: 0.6282 - precision_2: 0.7656 - auc_2: 0.8035\n",
            "Epoch 214: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5440 - accuracy: 0.7250 - sensitivity_at_specificity_2: 0.8974 - specificity_at_sensitivity_2: 0.8963 - recall_2: 0.6282 - precision_2: 0.7656 - auc_2: 0.8035 - val_loss: 0.4311 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9880 - val_specificity_at_sensitivity_2: 0.9870 - val_recall_2: 0.8072 - val_precision_2: 0.7791 - val_auc_2: 0.9058\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4478 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9467 - specificity_at_sensitivity_2: 0.9603 - recall_2: 0.8521 - precision_2: 0.7869 - auc_2: 0.8807\n",
            "Epoch 215: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4478 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9467 - specificity_at_sensitivity_2: 0.9603 - recall_2: 0.8521 - precision_2: 0.7869 - auc_2: 0.8807 - val_loss: 0.5005 - val_accuracy: 0.7188 - val_sensitivity_at_specificity_2: 0.9130 - val_specificity_at_sensitivity_2: 0.9560 - val_recall_2: 0.7826 - val_precision_2: 0.6429 - val_auc_2: 0.8582\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4717 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9045 - specificity_at_sensitivity_2: 0.9577 - recall_2: 0.7865 - precision_2: 0.8589 - auc_2: 0.8608\n",
            "Epoch 216: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4717 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9045 - specificity_at_sensitivity_2: 0.9577 - recall_2: 0.7865 - precision_2: 0.8589 - auc_2: 0.8608 - val_loss: 0.4757 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9268 - val_specificity_at_sensitivity_2: 0.9615 - val_recall_2: 0.8659 - val_precision_2: 0.7245 - val_auc_2: 0.8723\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9217 - specificity_at_sensitivity_2: 0.9481 - recall_2: 0.8253 - precision_2: 0.7874 - auc_2: 0.8670\n",
            "Epoch 217: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4575 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9217 - specificity_at_sensitivity_2: 0.9481 - recall_2: 0.8253 - precision_2: 0.7874 - auc_2: 0.8670 - val_loss: 0.4363 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9091 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8182 - val_precision_2: 0.7875 - val_auc_2: 0.8891\n",
            "Epoch 218/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4936 - accuracy: 0.7917 - sensitivity_at_specificity_2: 0.8841 - specificity_at_sensitivity_2: 0.9400 - recall_2: 0.7174 - precision_2: 0.8250 - auc_2: 0.8388\n",
            "Epoch 218: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4959 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.8968 - specificity_at_sensitivity_2: 0.9394 - recall_2: 0.7290 - precision_2: 0.8129 - auc_2: 0.8384 - val_loss: 0.4506 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9545 - val_specificity_at_sensitivity_2: 0.9722 - val_recall_2: 0.8864 - val_precision_2: 0.7800 - val_auc_2: 0.8841\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9427 - specificity_at_sensitivity_2: 0.9448 - recall_2: 0.7325 - precision_2: 0.7877 - auc_2: 0.8637\n",
            "Epoch 219: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4655 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9427 - specificity_at_sensitivity_2: 0.9448 - recall_2: 0.7325 - precision_2: 0.7877 - auc_2: 0.8637 - val_loss: 0.4641 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9310 - val_specificity_at_sensitivity_2: 0.9315 - val_recall_2: 0.8851 - val_precision_2: 0.7624 - val_auc_2: 0.8717\n",
            "Epoch 220/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4351 - accuracy: 0.8140 - sensitivity_at_specificity_2: 0.9344 - specificity_at_sensitivity_2: 0.9706 - recall_2: 0.8279 - precision_2: 0.7891 - auc_2: 0.8840\n",
            "Epoch 220: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4381 - accuracy: 0.8138 - sensitivity_at_specificity_2: 0.9179 - specificity_at_sensitivity_2: 0.9744 - recall_2: 0.8060 - precision_2: 0.7941 - auc_2: 0.8777 - val_loss: 0.4030 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9437 - val_specificity_at_sensitivity_2: 0.9888 - val_recall_2: 0.7746 - val_precision_2: 0.8088 - val_auc_2: 0.9065\n",
            "Epoch 221/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4705 - accuracy: 0.7743 - sensitivity_at_specificity_2: 0.9420 - specificity_at_sensitivity_2: 0.9467 - recall_2: 0.7246 - precision_2: 0.7874 - auc_2: 0.8583\n",
            "Epoch 221: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4704 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9412 - specificity_at_sensitivity_2: 0.9461 - recall_2: 0.7059 - precision_2: 0.7883 - auc_2: 0.8590 - val_loss: 0.4496 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9868 - val_specificity_at_sensitivity_2: 0.9643 - val_recall_2: 0.8816 - val_precision_2: 0.7444 - val_auc_2: 0.8843\n",
            "Epoch 222/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4105 - accuracy: 0.7986 - sensitivity_at_specificity_2: 0.9658 - specificity_at_sensitivity_2: 0.9437 - recall_2: 0.8356 - precision_2: 0.7821 - auc_2: 0.8973\n",
            "Epoch 222: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4029 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9632 - specificity_at_sensitivity_2: 0.9490 - recall_2: 0.8466 - precision_2: 0.7977 - auc_2: 0.9022 - val_loss: 0.4287 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9054 - val_specificity_at_sensitivity_2: 0.9884 - val_recall_2: 0.8108 - val_precision_2: 0.7792 - val_auc_2: 0.8853\n",
            "Epoch 223/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3915 - accuracy: 0.8333 - sensitivity_at_specificity_2: 0.9660 - specificity_at_sensitivity_2: 0.9858 - recall_2: 0.8503 - precision_2: 0.8278 - auc_2: 0.9120\n",
            "Epoch 223: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3985 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9699 - specificity_at_sensitivity_2: 0.9870 - recall_2: 0.8253 - precision_2: 0.8303 - auc_2: 0.9064 - val_loss: 0.3763 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9571 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8429 - val_precision_2: 0.7564 - val_auc_2: 0.9210\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9416 - specificity_at_sensitivity_2: 0.9759 - recall_2: 0.7468 - precision_2: 0.8214 - auc_2: 0.8843\n",
            "Epoch 224: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4304 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9416 - specificity_at_sensitivity_2: 0.9759 - recall_2: 0.7468 - precision_2: 0.8214 - auc_2: 0.8843 - val_loss: 0.4187 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9740 - val_specificity_at_sensitivity_2: 0.9518 - val_recall_2: 0.9091 - val_precision_2: 0.7609 - val_auc_2: 0.9014\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4739 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9054 - specificity_at_sensitivity_2: 0.9826 - recall_2: 0.7162 - precision_2: 0.7852 - auc_2: 0.8547\n",
            "Epoch 225: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4739 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9054 - specificity_at_sensitivity_2: 0.9826 - recall_2: 0.7162 - precision_2: 0.7852 - auc_2: 0.8547 - val_loss: 0.5299 - val_accuracy: 0.7312 - val_sensitivity_at_specificity_2: 0.8169 - val_specificity_at_sensitivity_2: 0.9213 - val_recall_2: 0.7465 - val_precision_2: 0.6795 - val_auc_2: 0.8160\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4850 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9162 - specificity_at_sensitivity_2: 0.9346 - recall_2: 0.8144 - precision_2: 0.7727 - auc_2: 0.8497\n",
            "Epoch 226: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4850 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9162 - specificity_at_sensitivity_2: 0.9346 - recall_2: 0.8144 - precision_2: 0.7727 - auc_2: 0.8497 - val_loss: 0.4086 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9730 - val_specificity_at_sensitivity_2: 0.9884 - val_recall_2: 0.8919 - val_precision_2: 0.7765 - val_auc_2: 0.9252\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4701 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9107 - specificity_at_sensitivity_2: 0.9605 - recall_2: 0.7381 - precision_2: 0.8158 - auc_2: 0.8617\n",
            "Epoch 227: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4701 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9107 - specificity_at_sensitivity_2: 0.9605 - recall_2: 0.7381 - precision_2: 0.8158 - auc_2: 0.8617 - val_loss: 0.4390 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9873 - val_specificity_at_sensitivity_2: 0.9630 - val_recall_2: 0.9747 - val_precision_2: 0.7264 - val_auc_2: 0.9135\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4662 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9463 - specificity_at_sensitivity_2: 0.9415 - recall_2: 0.7718 - precision_2: 0.7986 - auc_2: 0.8617\n",
            "Epoch 228: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4662 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9463 - specificity_at_sensitivity_2: 0.9415 - recall_2: 0.7718 - precision_2: 0.7986 - auc_2: 0.8617 - val_loss: 0.4017 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9383 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8519 - val_precision_2: 0.8313 - val_auc_2: 0.9101\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3937 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9636 - specificity_at_sensitivity_2: 0.9677 - recall_2: 0.8364 - precision_2: 0.8571 - auc_2: 0.9056\n",
            "Epoch 229: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3937 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9636 - specificity_at_sensitivity_2: 0.9677 - recall_2: 0.8364 - precision_2: 0.8571 - auc_2: 0.9056 - val_loss: 0.4467 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9655 - val_specificity_at_sensitivity_2: 0.9452 - val_recall_2: 0.9080 - val_precision_2: 0.7383 - val_auc_2: 0.8837\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9119 - specificity_at_sensitivity_2: 0.9255 - recall_2: 0.7233 - precision_2: 0.7877 - auc_2: 0.8394\n",
            "Epoch 230: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5030 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.9119 - specificity_at_sensitivity_2: 0.9255 - recall_2: 0.7233 - precision_2: 0.7877 - auc_2: 0.8394 - val_loss: 0.5087 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.8608 - val_specificity_at_sensitivity_2: 0.9753 - val_recall_2: 0.8481 - val_precision_2: 0.6907 - val_auc_2: 0.8561\n",
            "Epoch 231/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4389 - accuracy: 0.8090 - sensitivity_at_specificity_2: 0.9589 - specificity_at_sensitivity_2: 0.9437 - recall_2: 0.8836 - precision_2: 0.7725 - auc_2: 0.8825\n",
            "Epoch 231: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4286 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9643 - specificity_at_sensitivity_2: 0.9474 - recall_2: 0.8869 - precision_2: 0.7926 - auc_2: 0.8877 - val_loss: 0.4031 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9405 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8929 - val_precision_2: 0.8065 - val_auc_2: 0.9186\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4235 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9470 - specificity_at_sensitivity_2: 0.9645 - recall_2: 0.7947 - precision_2: 0.8000 - auc_2: 0.8878\n",
            "Epoch 232: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4235 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9470 - specificity_at_sensitivity_2: 0.9645 - recall_2: 0.7947 - precision_2: 0.8000 - auc_2: 0.8878 - val_loss: 0.4046 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9200 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8533 - val_precision_2: 0.8101 - val_auc_2: 0.9042\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9625 - recall_2: 0.7750 - precision_2: 0.8322 - auc_2: 0.8900\n",
            "Epoch 233: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4223 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9625 - recall_2: 0.7750 - precision_2: 0.8322 - auc_2: 0.8900 - val_loss: 0.5170 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9157 - val_specificity_at_sensitivity_2: 0.9091 - val_recall_2: 0.8554 - val_precision_2: 0.7100 - val_auc_2: 0.8388\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9512 - specificity_at_sensitivity_2: 0.9679 - recall_2: 0.8537 - precision_2: 0.8333 - auc_2: 0.8972\n",
            "Epoch 234: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4132 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9512 - specificity_at_sensitivity_2: 0.9679 - recall_2: 0.8537 - precision_2: 0.8333 - auc_2: 0.8972 - val_loss: 0.4577 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9348 - val_specificity_at_sensitivity_2: 0.9412 - val_recall_2: 0.9130 - val_precision_2: 0.7850 - val_auc_2: 0.8708\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9321 - specificity_at_sensitivity_2: 0.9367 - recall_2: 0.8395 - precision_2: 0.7684 - auc_2: 0.8475\n",
            "Epoch 235: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4951 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9321 - specificity_at_sensitivity_2: 0.9367 - recall_2: 0.8395 - precision_2: 0.7684 - auc_2: 0.8475 - val_loss: 0.4074 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9231 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.8333 - val_precision_2: 0.8125 - val_auc_2: 0.8977\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5265 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.8690 - specificity_at_sensitivity_2: 0.9371 - recall_2: 0.6483 - precision_2: 0.7966 - auc_2: 0.8141\n",
            "Epoch 236: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.5265 - accuracy: 0.7656 - sensitivity_at_specificity_2: 0.8690 - specificity_at_sensitivity_2: 0.9371 - recall_2: 0.6483 - precision_2: 0.7966 - auc_2: 0.8141 - val_loss: 0.5256 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9342 - val_specificity_at_sensitivity_2: 0.9524 - val_recall_2: 0.8421 - val_precision_2: 0.6882 - val_auc_2: 0.8386\n",
            "Epoch 237/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4125 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9545 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.9015 - precision_2: 0.7933 - auc_2: 0.9144\n",
            "Epoch 237: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4128 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9632 - specificity_at_sensitivity_2: 0.9936 - recall_2: 0.8834 - precision_2: 0.8000 - auc_2: 0.9110 - val_loss: 0.4463 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9310 - val_specificity_at_sensitivity_2: 0.9726 - val_recall_2: 0.8391 - val_precision_2: 0.8202 - val_auc_2: 0.8795\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4569 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9074 - specificity_at_sensitivity_2: 0.9684 - recall_2: 0.7469 - precision_2: 0.8345 - auc_2: 0.8657\n",
            "Epoch 238: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4569 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9074 - specificity_at_sensitivity_2: 0.9684 - recall_2: 0.7469 - precision_2: 0.8345 - auc_2: 0.8657 - val_loss: 0.4359 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9114 - val_specificity_at_sensitivity_2: 0.9877 - val_recall_2: 0.8861 - val_precision_2: 0.7527 - val_auc_2: 0.8915\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4829 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9161 - specificity_at_sensitivity_2: 0.9394 - recall_2: 0.7226 - precision_2: 0.7943 - auc_2: 0.8488\n",
            "Epoch 239: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4829 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.9161 - specificity_at_sensitivity_2: 0.9394 - recall_2: 0.7226 - precision_2: 0.7943 - auc_2: 0.8488 - val_loss: 0.4518 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9359 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9231 - val_precision_2: 0.7347 - val_auc_2: 0.8946\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4257 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9118 - specificity_at_sensitivity_2: 0.9933 - recall_2: 0.8176 - precision_2: 0.8274 - auc_2: 0.8884\n",
            "Epoch 240: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4257 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9118 - specificity_at_sensitivity_2: 0.9933 - recall_2: 0.8176 - precision_2: 0.8274 - auc_2: 0.8884 - val_loss: 0.4047 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9348 - val_specificity_at_sensitivity_2: 0.9853 - val_recall_2: 0.8804 - val_precision_2: 0.7642 - val_auc_2: 0.9070\n",
            "Epoch 241/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4373 - accuracy: 0.8229 - sensitivity_at_specificity_2: 0.9363 - specificity_at_sensitivity_2: 0.9618 - recall_2: 0.8854 - precision_2: 0.8081 - auc_2: 0.8786\n",
            "Epoch 241: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4297 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9419 - specificity_at_sensitivity_2: 0.9662 - recall_2: 0.8721 - precision_2: 0.8065 - auc_2: 0.8839 - val_loss: 0.4380 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9359 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.7949 - val_precision_2: 0.8267 - val_auc_2: 0.8763\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9324 - specificity_at_sensitivity_2: 0.9767 - recall_2: 0.6689 - precision_2: 0.8462 - auc_2: 0.8705\n",
            "Epoch 242: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4454 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9324 - specificity_at_sensitivity_2: 0.9767 - recall_2: 0.6689 - precision_2: 0.8462 - auc_2: 0.8705 - val_loss: 0.4874 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.8889 - val_specificity_at_sensitivity_2: 0.9747 - val_recall_2: 0.7407 - val_precision_2: 0.7692 - val_auc_2: 0.8422\n",
            "Epoch 243/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4262 - accuracy: 0.8090 - sensitivity_at_specificity_2: 0.9248 - specificity_at_sensitivity_2: 0.9871 - recall_2: 0.7820 - precision_2: 0.8000 - auc_2: 0.8829\n",
            "Epoch 243: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4228 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9267 - specificity_at_sensitivity_2: 0.9824 - recall_2: 0.7667 - precision_2: 0.8156 - auc_2: 0.8854 - val_loss: 0.3923 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9767 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7791 - val_precision_2: 0.8933 - val_auc_2: 0.9187\n",
            "Epoch 244/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4320 - accuracy: 0.8021 - sensitivity_at_specificity_2: 0.9504 - specificity_at_sensitivity_2: 0.9592 - recall_2: 0.8298 - precision_2: 0.7800 - auc_2: 0.8861\n",
            "Epoch 244: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4247 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9484 - specificity_at_sensitivity_2: 0.9636 - recall_2: 0.8323 - precision_2: 0.7866 - auc_2: 0.8900 - val_loss: 0.4332 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9157 - val_specificity_at_sensitivity_2: 0.9740 - val_recall_2: 0.8072 - val_precision_2: 0.8590 - val_auc_2: 0.8766\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4664 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9304 - specificity_at_sensitivity_2: 0.9506 - recall_2: 0.7278 - precision_2: 0.8156 - auc_2: 0.8621\n",
            "Epoch 245: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4664 - accuracy: 0.7844 - sensitivity_at_specificity_2: 0.9304 - specificity_at_sensitivity_2: 0.9506 - recall_2: 0.7278 - precision_2: 0.8156 - auc_2: 0.8621 - val_loss: 0.4887 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9103 - val_specificity_at_sensitivity_2: 0.9634 - val_recall_2: 0.8077 - val_precision_2: 0.7159 - val_auc_2: 0.8590\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9200 - specificity_at_sensitivity_2: 0.9412 - recall_2: 0.7533 - precision_2: 0.8188 - auc_2: 0.8735\n",
            "Epoch 246: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4449 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9200 - specificity_at_sensitivity_2: 0.9412 - recall_2: 0.7533 - precision_2: 0.8188 - auc_2: 0.8735 - val_loss: 0.4354 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9342 - val_specificity_at_sensitivity_2: 0.9881 - val_recall_2: 0.7763 - val_precision_2: 0.7662 - val_auc_2: 0.8790\n",
            "Epoch 247/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4350 - accuracy: 0.7951 - sensitivity_at_specificity_2: 0.9189 - specificity_at_sensitivity_2: 0.9786 - recall_2: 0.7365 - precision_2: 0.8450 - auc_2: 0.8773\n",
            "Epoch 247: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4371 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9268 - specificity_at_sensitivity_2: 0.9808 - recall_2: 0.7439 - precision_2: 0.8472 - auc_2: 0.8773 - val_loss: 0.4488 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9341 - val_specificity_at_sensitivity_2: 0.9565 - val_recall_2: 0.8791 - val_precision_2: 0.7407 - val_auc_2: 0.8814\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4608 - accuracy: 0.8103 - sensitivity_at_specificity_2: 0.9085 - specificity_at_sensitivity_2: 0.9595 - recall_2: 0.7817 - precision_2: 0.8222 - auc_2: 0.8642\n",
            "Epoch 248: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4608 - accuracy: 0.8103 - sensitivity_at_specificity_2: 0.9085 - specificity_at_sensitivity_2: 0.9595 - recall_2: 0.7817 - precision_2: 0.8222 - auc_2: 0.8642 - val_loss: 0.4471 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9625 - val_specificity_at_sensitivity_2: 0.9750 - val_recall_2: 0.8500 - val_precision_2: 0.7556 - val_auc_2: 0.8842\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4296 - accuracy: 0.8241 - sensitivity_at_specificity_2: 0.9333 - specificity_at_sensitivity_2: 0.9643 - recall_2: 0.7800 - precision_2: 0.8667 - auc_2: 0.8874\n",
            "Epoch 249: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.4296 - accuracy: 0.8241 - sensitivity_at_specificity_2: 0.9333 - specificity_at_sensitivity_2: 0.9643 - recall_2: 0.7800 - precision_2: 0.8667 - auc_2: 0.8874 - val_loss: 0.4257 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9767 - val_specificity_at_sensitivity_2: 0.9730 - val_recall_2: 0.8372 - val_precision_2: 0.8000 - val_auc_2: 0.8923\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4694 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.8882 - specificity_at_sensitivity_2: 0.9497 - recall_2: 0.7578 - precision_2: 0.8356 - auc_2: 0.8559\n",
            "Epoch 250: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4694 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.8882 - specificity_at_sensitivity_2: 0.9497 - recall_2: 0.7578 - precision_2: 0.8356 - auc_2: 0.8559 - val_loss: 0.4282 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9600 - val_specificity_at_sensitivity_2: 0.9882 - val_recall_2: 0.9333 - val_precision_2: 0.7143 - val_auc_2: 0.9212\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4776 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9064 - specificity_at_sensitivity_2: 0.9530 - recall_2: 0.7251 - precision_2: 0.8212 - auc_2: 0.8525\n",
            "Epoch 251: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4776 - accuracy: 0.7688 - sensitivity_at_specificity_2: 0.9064 - specificity_at_sensitivity_2: 0.9530 - recall_2: 0.7251 - precision_2: 0.8212 - auc_2: 0.8525 - val_loss: 0.5260 - val_accuracy: 0.7188 - val_sensitivity_at_specificity_2: 0.9200 - val_specificity_at_sensitivity_2: 0.9412 - val_recall_2: 0.8533 - val_precision_2: 0.6531 - val_auc_2: 0.8565\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9156 - specificity_at_sensitivity_2: 0.9578 - recall_2: 0.7857 - precision_2: 0.7610 - auc_2: 0.8685\n",
            "Epoch 252: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4565 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.9156 - specificity_at_sensitivity_2: 0.9578 - recall_2: 0.7857 - precision_2: 0.7610 - auc_2: 0.8685 - val_loss: 0.4403 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9242 - val_specificity_at_sensitivity_2: 0.9681 - val_recall_2: 0.7424 - val_precision_2: 0.7538 - val_auc_2: 0.8775\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4352 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9515 - specificity_at_sensitivity_2: 0.9419 - recall_2: 0.7636 - precision_2: 0.8456 - auc_2: 0.8876\n",
            "Epoch 253: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4352 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9515 - specificity_at_sensitivity_2: 0.9419 - recall_2: 0.7636 - precision_2: 0.8456 - auc_2: 0.8876 - val_loss: 0.4823 - val_accuracy: 0.7375 - val_sensitivity_at_specificity_2: 0.9302 - val_specificity_at_sensitivity_2: 0.9865 - val_recall_2: 0.9186 - val_precision_2: 0.6930 - val_auc_2: 0.8958\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9141 - specificity_at_sensitivity_2: 0.9682 - recall_2: 0.7975 - precision_2: 0.8125 - auc_2: 0.8677\n",
            "Epoch 254: val_accuracy improved from 0.85000 to 0.88125, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4496 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9141 - specificity_at_sensitivity_2: 0.9682 - recall_2: 0.7975 - precision_2: 0.8125 - auc_2: 0.8677 - val_loss: 0.3438 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9737 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8947 - val_precision_2: 0.8608 - val_auc_2: 0.9456\n",
            "Epoch 255/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3883 - accuracy: 0.8299 - sensitivity_at_specificity_2: 0.9398 - specificity_at_sensitivity_2: 0.9935 - recall_2: 0.8346 - precision_2: 0.8043 - auc_2: 0.9100\n",
            "Epoch 255: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3771 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9539 - specificity_at_sensitivity_2: 0.9940 - recall_2: 0.8487 - precision_2: 0.8217 - auc_2: 0.9167 - val_loss: 0.4178 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9383 - val_specificity_at_sensitivity_2: 0.9620 - val_recall_2: 0.8395 - val_precision_2: 0.8395 - val_auc_2: 0.8912\n",
            "Epoch 256/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4137 - accuracy: 0.8333 - sensitivity_at_specificity_2: 0.9459 - specificity_at_sensitivity_2: 0.9643 - recall_2: 0.8243 - precision_2: 0.8472 - auc_2: 0.8944\n",
            "Epoch 256: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3996 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9509 - specificity_at_sensitivity_2: 0.9682 - recall_2: 0.8282 - precision_2: 0.8491 - auc_2: 0.9019 - val_loss: 0.3817 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9487 - val_specificity_at_sensitivity_2: 0.9756 - val_recall_2: 0.8718 - val_precision_2: 0.7816 - val_auc_2: 0.9192\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4277 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9294 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.7706 - precision_2: 0.8452 - auc_2: 0.8798\n",
            "Epoch 257: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4277 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9294 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.7706 - precision_2: 0.8452 - auc_2: 0.8798 - val_loss: 0.4942 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.8795 - val_specificity_at_sensitivity_2: 0.9091 - val_recall_2: 0.7831 - val_precision_2: 0.8025 - val_auc_2: 0.8370\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9125 - specificity_at_sensitivity_2: 0.9688 - recall_2: 0.7437 - precision_2: 0.8380 - auc_2: 0.8661\n",
            "Epoch 258: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4507 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9125 - specificity_at_sensitivity_2: 0.9688 - recall_2: 0.7437 - precision_2: 0.8380 - auc_2: 0.8661 - val_loss: 0.3844 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9756 - val_specificity_at_sensitivity_2: 0.9872 - val_recall_2: 0.9146 - val_precision_2: 0.7653 - val_auc_2: 0.9221\n",
            "Epoch 259/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4584 - accuracy: 0.8090 - sensitivity_at_specificity_2: 0.8794 - specificity_at_sensitivity_2: 0.9592 - recall_2: 0.7660 - precision_2: 0.8308 - auc_2: 0.8601\n",
            "Epoch 259: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4649 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.8792 - specificity_at_sensitivity_2: 0.9474 - recall_2: 0.7651 - precision_2: 0.7862 - auc_2: 0.8535 - val_loss: 0.4575 - val_accuracy: 0.7500 - val_sensitivity_at_specificity_2: 0.9733 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8267 - val_precision_2: 0.6966 - val_auc_2: 0.8855\n",
            "Epoch 260/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4261 - accuracy: 0.8021 - sensitivity_at_specificity_2: 0.9392 - specificity_at_sensitivity_2: 0.9714 - recall_2: 0.7838 - precision_2: 0.8227 - auc_2: 0.8846\n",
            "Epoch 260: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4142 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9333 - specificity_at_sensitivity_2: 0.9742 - recall_2: 0.7939 - precision_2: 0.8291 - auc_2: 0.8925 - val_loss: 0.4095 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9535 - val_specificity_at_sensitivity_2: 0.9865 - val_recall_2: 0.8605 - val_precision_2: 0.8222 - val_auc_2: 0.8992\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3988 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9545 - specificity_at_sensitivity_2: 0.9819 - recall_2: 0.8117 - precision_2: 0.8803 - auc_2: 0.9049\n",
            "Epoch 261: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3988 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9545 - specificity_at_sensitivity_2: 0.9819 - recall_2: 0.8117 - precision_2: 0.8803 - auc_2: 0.9049 - val_loss: 0.3875 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9750 - val_specificity_at_sensitivity_2: 0.9875 - val_recall_2: 0.8375 - val_precision_2: 0.8171 - val_auc_2: 0.9122\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9529 - specificity_at_sensitivity_2: 0.9533 - recall_2: 0.8059 - precision_2: 0.8204 - auc_2: 0.8799\n",
            "Epoch 262: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4371 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9529 - specificity_at_sensitivity_2: 0.9533 - recall_2: 0.8059 - precision_2: 0.8204 - auc_2: 0.8799 - val_loss: 0.4824 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9420 - val_specificity_at_sensitivity_2: 0.9670 - val_recall_2: 0.9130 - val_precision_2: 0.6702 - val_auc_2: 0.8807\n",
            "Epoch 263/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4239 - accuracy: 0.7951 - sensitivity_at_specificity_2: 0.9485 - specificity_at_sensitivity_2: 0.9934 - recall_2: 0.7500 - precision_2: 0.8031 - auc_2: 0.8843\n",
            "Epoch 263: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4290 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9408 - specificity_at_sensitivity_2: 0.9881 - recall_2: 0.7566 - precision_2: 0.8042 - auc_2: 0.8829 - val_loss: 0.4376 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9326 - val_specificity_at_sensitivity_2: 0.9718 - val_recall_2: 0.8315 - val_precision_2: 0.8315 - val_auc_2: 0.8784\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4488 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9268 - specificity_at_sensitivity_2: 0.9551 - recall_2: 0.8354 - precision_2: 0.7784 - auc_2: 0.8764\n",
            "Epoch 264: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4488 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9268 - specificity_at_sensitivity_2: 0.9551 - recall_2: 0.8354 - precision_2: 0.7784 - auc_2: 0.8764 - val_loss: 0.4237 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9333 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7600 - val_precision_2: 0.8769 - val_auc_2: 0.9003\n",
            "Epoch 265/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4825 - accuracy: 0.7917 - sensitivity_at_specificity_2: 0.9296 - specificity_at_sensitivity_2: 0.9315 - recall_2: 0.7042 - precision_2: 0.8475 - auc_2: 0.8538\n",
            "Epoch 265: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4975 - accuracy: 0.7875 - sensitivity_at_specificity_2: 0.9167 - specificity_at_sensitivity_2: 0.9329 - recall_2: 0.7115 - precision_2: 0.8284 - auc_2: 0.8422 - val_loss: 0.5439 - val_accuracy: 0.7188 - val_sensitivity_at_specificity_2: 0.9452 - val_specificity_at_sensitivity_2: 0.9770 - val_recall_2: 0.8904 - val_precision_2: 0.6373 - val_auc_2: 0.8672\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4589 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.8800 - specificity_at_sensitivity_2: 0.9588 - recall_2: 0.7333 - precision_2: 0.8462 - auc_2: 0.8590\n",
            "Epoch 266: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4589 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.8800 - specificity_at_sensitivity_2: 0.9588 - recall_2: 0.7333 - precision_2: 0.8462 - auc_2: 0.8590 - val_loss: 0.4412 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9342 - val_specificity_at_sensitivity_2: 0.9643 - val_recall_2: 0.7237 - val_precision_2: 0.8462 - val_auc_2: 0.8748\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.7759 - sensitivity_at_specificity_2: 0.8958 - specificity_at_sensitivity_2: 0.9658 - recall_2: 0.7500 - precision_2: 0.7883 - auc_2: 0.8534\n",
            "Epoch 267: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4709 - accuracy: 0.7759 - sensitivity_at_specificity_2: 0.8958 - specificity_at_sensitivity_2: 0.9658 - recall_2: 0.7500 - precision_2: 0.7883 - auc_2: 0.8534 - val_loss: 0.4394 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8974 - val_precision_2: 0.7071 - val_auc_2: 0.9164\n",
            "Epoch 268/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4101 - accuracy: 0.8368 - sensitivity_at_specificity_2: 0.9580 - specificity_at_sensitivity_2: 0.9517 - recall_2: 0.8741 - precision_2: 0.8117 - auc_2: 0.9017\n",
            "Epoch 268: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4073 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9557 - specificity_at_sensitivity_2: 0.9568 - recall_2: 0.8608 - precision_2: 0.8193 - auc_2: 0.9033 - val_loss: 0.3936 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 1.0000 - val_specificity_at_sensitivity_2: 0.9620 - val_recall_2: 0.8519 - val_precision_2: 0.7931 - val_auc_2: 0.9119\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9048 - specificity_at_sensitivity_2: 0.9769 - recall_2: 0.7823 - precision_2: 0.8519 - auc_2: 0.8706\n",
            "Epoch 269: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4361 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9048 - specificity_at_sensitivity_2: 0.9769 - recall_2: 0.7823 - precision_2: 0.8519 - auc_2: 0.8706 - val_loss: 0.4397 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9296 - val_specificity_at_sensitivity_2: 0.9888 - val_recall_2: 0.8451 - val_precision_2: 0.7143 - val_auc_2: 0.8826\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4239 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9682 - specificity_at_sensitivity_2: 0.9632 - recall_2: 0.7707 - precision_2: 0.8345 - auc_2: 0.8861\n",
            "Epoch 270: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4239 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9682 - specificity_at_sensitivity_2: 0.9632 - recall_2: 0.7707 - precision_2: 0.8345 - auc_2: 0.8861 - val_loss: 0.4146 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.9136 - val_precision_2: 0.7629 - val_auc_2: 0.9062\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4108 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9367 - specificity_at_sensitivity_2: 0.9753 - recall_2: 0.8291 - precision_2: 0.7892 - auc_2: 0.8946\n",
            "Epoch 271: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4108 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9367 - specificity_at_sensitivity_2: 0.9753 - recall_2: 0.8291 - precision_2: 0.7892 - auc_2: 0.8946 - val_loss: 0.3882 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9625 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7875 - val_precision_2: 0.8873 - val_auc_2: 0.9144\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4691 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.8750 - specificity_at_sensitivity_2: 0.9812 - recall_2: 0.7437 - precision_2: 0.7987 - auc_2: 0.8504\n",
            "Epoch 272: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4691 - accuracy: 0.7781 - sensitivity_at_specificity_2: 0.8750 - specificity_at_sensitivity_2: 0.9812 - recall_2: 0.7437 - precision_2: 0.7987 - auc_2: 0.8504 - val_loss: 0.4238 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9359 - val_specificity_at_sensitivity_2: 0.9756 - val_recall_2: 0.8077 - val_precision_2: 0.8182 - val_auc_2: 0.8925\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9808 - specificity_at_sensitivity_2: 0.9756 - recall_2: 0.7564 - precision_2: 0.8806 - auc_2: 0.9268\n",
            "Epoch 273: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3746 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9808 - specificity_at_sensitivity_2: 0.9756 - recall_2: 0.7564 - precision_2: 0.8806 - auc_2: 0.9268 - val_loss: 0.3881 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9474 - val_specificity_at_sensitivity_2: 0.9881 - val_recall_2: 0.8947 - val_precision_2: 0.7473 - val_auc_2: 0.9265\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9392 - specificity_at_sensitivity_2: 0.9477 - recall_2: 0.7905 - precision_2: 0.8182 - auc_2: 0.8737\n",
            "Epoch 274: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4435 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9392 - specificity_at_sensitivity_2: 0.9477 - recall_2: 0.7905 - precision_2: 0.8182 - auc_2: 0.8737 - val_loss: 0.3993 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9315 - val_specificity_at_sensitivity_2: 0.9770 - val_recall_2: 0.8356 - val_precision_2: 0.8356 - val_auc_2: 0.9022\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9470 - specificity_at_sensitivity_2: 0.9822 - recall_2: 0.8079 - precision_2: 0.7974 - auc_2: 0.8982\n",
            "Epoch 275: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4002 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9470 - specificity_at_sensitivity_2: 0.9822 - recall_2: 0.8079 - precision_2: 0.7974 - auc_2: 0.8982 - val_loss: 0.4205 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9390 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7561 - val_precision_2: 0.8732 - val_auc_2: 0.8864\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4249 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9304 - specificity_at_sensitivity_2: 0.9568 - recall_2: 0.7785 - precision_2: 0.8367 - auc_2: 0.8836\n",
            "Epoch 276: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4249 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9304 - specificity_at_sensitivity_2: 0.9568 - recall_2: 0.7785 - precision_2: 0.8367 - auc_2: 0.8836 - val_loss: 0.4464 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9195 - val_specificity_at_sensitivity_2: 0.9452 - val_recall_2: 0.8851 - val_precision_2: 0.7624 - val_auc_2: 0.8804\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9524 - specificity_at_sensitivity_2: 0.9364 - recall_2: 0.7687 - precision_2: 0.7740 - auc_2: 0.8687\n",
            "Epoch 277: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4548 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9524 - specificity_at_sensitivity_2: 0.9364 - recall_2: 0.7687 - precision_2: 0.7740 - auc_2: 0.8687 - val_loss: 0.3701 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9600 - val_specificity_at_sensitivity_2: 0.9882 - val_recall_2: 0.8533 - val_precision_2: 0.8205 - val_auc_2: 0.9272\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4193 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9187 - specificity_at_sensitivity_2: 0.9750 - recall_2: 0.7625 - precision_2: 0.8472 - auc_2: 0.8834\n",
            "Epoch 278: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4193 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9187 - specificity_at_sensitivity_2: 0.9750 - recall_2: 0.7625 - precision_2: 0.8472 - auc_2: 0.8834 - val_loss: 0.4693 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9625 - val_specificity_at_sensitivity_2: 0.9750 - val_recall_2: 0.9000 - val_precision_2: 0.6990 - val_auc_2: 0.9045\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4640 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.8981 - specificity_at_sensitivity_2: 0.9571 - recall_2: 0.7707 - precision_2: 0.8176 - auc_2: 0.8581\n",
            "Epoch 279: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4640 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.8981 - specificity_at_sensitivity_2: 0.9571 - recall_2: 0.7707 - precision_2: 0.8176 - auc_2: 0.8581 - val_loss: 0.3964 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9306 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7917 - val_precision_2: 0.8769 - val_auc_2: 0.8956\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4154 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9080 - specificity_at_sensitivity_2: 0.9873 - recall_2: 0.7914 - precision_2: 0.8217 - auc_2: 0.8860\n",
            "Epoch 280: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4154 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9080 - specificity_at_sensitivity_2: 0.9873 - recall_2: 0.7914 - precision_2: 0.8217 - auc_2: 0.8860 - val_loss: 0.3956 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9714 - val_specificity_at_sensitivity_2: 0.9556 - val_recall_2: 0.9000 - val_precision_2: 0.8182 - val_auc_2: 0.9171\n",
            "Epoch 281/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4507 - accuracy: 0.8021 - sensitivity_at_specificity_2: 0.8919 - specificity_at_sensitivity_2: 0.9786 - recall_2: 0.7905 - precision_2: 0.8182 - auc_2: 0.8653\n",
            "Epoch 281: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4520 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.8963 - specificity_at_sensitivity_2: 0.9744 - recall_2: 0.7866 - precision_2: 0.8113 - auc_2: 0.8649 - val_loss: 0.4179 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9059 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8235 - val_precision_2: 0.7865 - val_auc_2: 0.8876\n",
            "Epoch 282/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4057 - accuracy: 0.8299 - sensitivity_at_specificity_2: 0.9658 - specificity_at_sensitivity_2: 0.9789 - recall_2: 0.7671 - precision_2: 0.8819 - auc_2: 0.9035\n",
            "Epoch 282: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4049 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9641 - specificity_at_sensitivity_2: 0.9804 - recall_2: 0.7844 - precision_2: 0.8851 - auc_2: 0.9036 - val_loss: 0.4557 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.9067 - val_specificity_at_sensitivity_2: 0.9882 - val_recall_2: 0.8267 - val_precision_2: 0.7126 - val_auc_2: 0.8838\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.7594 - sensitivity_at_specificity_2: 0.9610 - specificity_at_sensitivity_2: 0.9518 - recall_2: 0.6948 - precision_2: 0.7810 - auc_2: 0.8709\n",
            "Epoch 283: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4547 - accuracy: 0.7594 - sensitivity_at_specificity_2: 0.9610 - specificity_at_sensitivity_2: 0.9518 - recall_2: 0.6948 - precision_2: 0.7810 - auc_2: 0.8709 - val_loss: 0.3527 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9859 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8451 - val_precision_2: 0.7895 - val_auc_2: 0.9357\n",
            "Epoch 284/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3903 - accuracy: 0.8194 - sensitivity_at_specificity_2: 0.9608 - specificity_at_sensitivity_2: 0.9852 - recall_2: 0.8693 - precision_2: 0.8061 - auc_2: 0.9058\n",
            "Epoch 284: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.3966 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9645 - specificity_at_sensitivity_2: 0.9868 - recall_2: 0.8580 - precision_2: 0.8011 - auc_2: 0.9041 - val_loss: 0.3528 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9643 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8810 - val_precision_2: 0.8810 - val_auc_2: 0.9373\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4192 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9250 - specificity_at_sensitivity_2: 0.9750 - recall_2: 0.7375 - precision_2: 0.8429 - auc_2: 0.8888\n",
            "Epoch 285: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4192 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9250 - specificity_at_sensitivity_2: 0.9750 - recall_2: 0.7375 - precision_2: 0.8429 - auc_2: 0.8888 - val_loss: 0.4294 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9062 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8438 - val_precision_2: 0.8265 - val_auc_2: 0.8743\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9321 - specificity_at_sensitivity_2: 0.9747 - recall_2: 0.8272 - precision_2: 0.8024 - auc_2: 0.8916\n",
            "Epoch 286: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4129 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9321 - specificity_at_sensitivity_2: 0.9747 - recall_2: 0.8272 - precision_2: 0.8024 - auc_2: 0.8916 - val_loss: 0.3876 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9342 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7763 - val_precision_2: 0.8806 - val_auc_2: 0.9072\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9641 - specificity_at_sensitivity_2: 0.9804 - recall_2: 0.8084 - precision_2: 0.8491 - auc_2: 0.9092\n",
            "Epoch 287: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3853 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9641 - specificity_at_sensitivity_2: 0.9804 - recall_2: 0.8084 - precision_2: 0.8491 - auc_2: 0.9092 - val_loss: 0.4506 - val_accuracy: 0.7750 - val_sensitivity_at_specificity_2: 0.9012 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.8765 - val_precision_2: 0.7320 - val_auc_2: 0.8956\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9695 - specificity_at_sensitivity_2: 0.9872 - recall_2: 0.7866 - precision_2: 0.8431 - auc_2: 0.9013\n",
            "Epoch 288: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4011 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9695 - specificity_at_sensitivity_2: 0.9872 - recall_2: 0.7866 - precision_2: 0.8431 - auc_2: 0.9013 - val_loss: 0.4251 - val_accuracy: 0.8125 - val_sensitivity_at_specificity_2: 0.9296 - val_specificity_at_sensitivity_2: 0.9775 - val_recall_2: 0.8592 - val_precision_2: 0.7531 - val_auc_2: 0.8944\n",
            "Epoch 289/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4011 - accuracy: 0.8229 - sensitivity_at_specificity_2: 0.9310 - specificity_at_sensitivity_2: 0.9650 - recall_2: 0.8000 - precision_2: 0.8406 - auc_2: 0.8966\n",
            "Epoch 289: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4008 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9367 - specificity_at_sensitivity_2: 0.9691 - recall_2: 0.7911 - precision_2: 0.8333 - auc_2: 0.8977 - val_loss: 0.3660 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9545 - val_specificity_at_sensitivity_2: 0.9787 - val_recall_2: 0.8333 - val_precision_2: 0.8594 - val_auc_2: 0.9121\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4445 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9351 - specificity_at_sensitivity_2: 0.9578 - recall_2: 0.7468 - precision_2: 0.8099 - auc_2: 0.8724\n",
            "Epoch 290: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4445 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9351 - specificity_at_sensitivity_2: 0.9578 - recall_2: 0.7468 - precision_2: 0.8099 - auc_2: 0.8724 - val_loss: 0.3642 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9895 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8421 - val_precision_2: 0.8602 - val_auc_2: 0.9233\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3757 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9620 - specificity_at_sensitivity_2: 0.9779 - recall_2: 0.8587 - precision_2: 0.8681 - auc_2: 0.9146\n",
            "Epoch 291: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3757 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9620 - specificity_at_sensitivity_2: 0.9779 - recall_2: 0.8587 - precision_2: 0.8681 - auc_2: 0.9146 - val_loss: 0.3567 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9882 - val_specificity_at_sensitivity_2: 0.9867 - val_recall_2: 0.8941 - val_precision_2: 0.8172 - val_auc_2: 0.9373\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4693 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9085 - specificity_at_sensitivity_2: 0.9581 - recall_2: 0.7124 - precision_2: 0.8385 - auc_2: 0.8568\n",
            "Epoch 292: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4693 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9085 - specificity_at_sensitivity_2: 0.9581 - recall_2: 0.7124 - precision_2: 0.8385 - auc_2: 0.8568 - val_loss: 0.4306 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9326 - val_specificity_at_sensitivity_2: 0.9718 - val_recall_2: 0.8876 - val_precision_2: 0.7822 - val_auc_2: 0.8897\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4206 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9020 - specificity_at_sensitivity_2: 0.9581 - recall_2: 0.8039 - precision_2: 0.8425 - auc_2: 0.8846\n",
            "Epoch 293: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4206 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9020 - specificity_at_sensitivity_2: 0.9581 - recall_2: 0.8039 - precision_2: 0.8425 - auc_2: 0.8846 - val_loss: 0.3866 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9398 - val_specificity_at_sensitivity_2: 0.9870 - val_recall_2: 0.7349 - val_precision_2: 0.9531 - val_auc_2: 0.9193\n",
            "Epoch 294/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3872 - accuracy: 0.8403 - sensitivity_at_specificity_2: 0.9457 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.7674 - precision_2: 0.8609 - auc_2: 0.9069\n",
            "Epoch 294: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3831 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9943 - recall_2: 0.7847 - precision_2: 0.8626 - auc_2: 0.9090 - val_loss: 0.3774 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9367 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8987 - val_precision_2: 0.8161 - val_auc_2: 0.9203\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4414 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9329 - specificity_at_sensitivity_2: 0.9679 - recall_2: 0.7805 - precision_2: 0.8312 - auc_2: 0.8716\n",
            "Epoch 295: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4414 - accuracy: 0.8062 - sensitivity_at_specificity_2: 0.9329 - specificity_at_sensitivity_2: 0.9679 - recall_2: 0.7805 - precision_2: 0.8312 - auc_2: 0.8716 - val_loss: 0.3981 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9620 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7722 - val_precision_2: 0.8714 - val_auc_2: 0.9033\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3568 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9618 - specificity_at_sensitivity_2: 0.9877 - recall_2: 0.8280 - precision_2: 0.8609 - auc_2: 0.9248\n",
            "Epoch 296: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3568 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9618 - specificity_at_sensitivity_2: 0.9877 - recall_2: 0.8280 - precision_2: 0.8609 - auc_2: 0.9248 - val_loss: 0.3626 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9873 - val_specificity_at_sensitivity_2: 0.9753 - val_recall_2: 0.9114 - val_precision_2: 0.8276 - val_auc_2: 0.9341\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9489 - specificity_at_sensitivity_2: 0.9653 - recall_2: 0.8352 - precision_2: 0.8855 - auc_2: 0.8955\n",
            "Epoch 297: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4079 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9489 - specificity_at_sensitivity_2: 0.9653 - recall_2: 0.8352 - precision_2: 0.8855 - auc_2: 0.8955 - val_loss: 0.4714 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9231 - val_specificity_at_sensitivity_2: 0.9855 - val_recall_2: 0.6923 - val_precision_2: 0.9000 - val_auc_2: 0.8637\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4080 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9189 - specificity_at_sensitivity_2: 0.9942 - recall_2: 0.8108 - precision_2: 0.8108 - auc_2: 0.8895\n",
            "Epoch 298: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4080 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9189 - specificity_at_sensitivity_2: 0.9942 - recall_2: 0.8108 - precision_2: 0.8108 - auc_2: 0.8895 - val_loss: 0.3575 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9268 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8171 - val_precision_2: 0.9306 - val_auc_2: 0.9171\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9458 - specificity_at_sensitivity_2: 0.9870 - recall_2: 0.8072 - precision_2: 0.8590 - auc_2: 0.8978\n",
            "Epoch 299: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3993 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9458 - specificity_at_sensitivity_2: 0.9870 - recall_2: 0.8072 - precision_2: 0.8590 - auc_2: 0.8978 - val_loss: 0.3918 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9451 - val_specificity_at_sensitivity_2: 0.9855 - val_recall_2: 0.8352 - val_precision_2: 0.8085 - val_auc_2: 0.9042\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4105 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9342 - specificity_at_sensitivity_2: 0.9643 - recall_2: 0.7566 - precision_2: 0.8519 - auc_2: 0.8917\n",
            "Epoch 300: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4105 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9342 - specificity_at_sensitivity_2: 0.9643 - recall_2: 0.7566 - precision_2: 0.8519 - auc_2: 0.8917 - val_loss: 0.3411 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9740 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9221 - val_precision_2: 0.8161 - val_auc_2: 0.9402\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4149 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9398 - specificity_at_sensitivity_2: 0.9805 - recall_2: 0.8133 - precision_2: 0.8385 - auc_2: 0.8909\n",
            "Epoch 301: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4149 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9398 - specificity_at_sensitivity_2: 0.9805 - recall_2: 0.8133 - precision_2: 0.8385 - auc_2: 0.8909 - val_loss: 0.3704 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7949 - val_precision_2: 0.8378 - val_auc_2: 0.9091\n",
            "Epoch 302/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4361 - accuracy: 0.8194 - sensitivity_at_specificity_2: 0.9257 - specificity_at_sensitivity_2: 0.9714 - recall_2: 0.7838 - precision_2: 0.8529 - auc_2: 0.8773\n",
            "Epoch 302: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4500 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9268 - specificity_at_sensitivity_2: 0.9679 - recall_2: 0.7927 - precision_2: 0.8387 - auc_2: 0.8704 - val_loss: 0.4183 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.8831 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8182 - val_precision_2: 0.8077 - val_auc_2: 0.8809\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4095 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9427 - specificity_at_sensitivity_2: 0.9632 - recall_2: 0.7580 - precision_2: 0.8561 - auc_2: 0.8952\n",
            "Epoch 303: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4095 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9427 - specificity_at_sensitivity_2: 0.9632 - recall_2: 0.7580 - precision_2: 0.8561 - auc_2: 0.8952 - val_loss: 0.3548 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8608 - val_precision_2: 0.8293 - val_auc_2: 0.9299\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4522 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9079 - specificity_at_sensitivity_2: 0.9762 - recall_2: 0.7632 - precision_2: 0.7891 - auc_2: 0.8638\n",
            "Epoch 304: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4522 - accuracy: 0.7906 - sensitivity_at_specificity_2: 0.9079 - specificity_at_sensitivity_2: 0.9762 - recall_2: 0.7632 - precision_2: 0.7891 - auc_2: 0.8638 - val_loss: 0.3453 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9767 - val_specificity_at_sensitivity_2: 0.9865 - val_recall_2: 0.8023 - val_precision_2: 0.9718 - val_auc_2: 0.9478\n",
            "Epoch 305/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3842 - accuracy: 0.8299 - sensitivity_at_specificity_2: 0.9850 - specificity_at_sensitivity_2: 0.9613 - recall_2: 0.7970 - precision_2: 0.8281 - auc_2: 0.9137\n",
            "Epoch 305: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3765 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9870 - specificity_at_sensitivity_2: 0.9699 - recall_2: 0.7987 - precision_2: 0.8367 - auc_2: 0.9181 - val_loss: 0.3476 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9518 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8554 - val_precision_2: 0.8987 - val_auc_2: 0.9233\n",
            "Epoch 306/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4082 - accuracy: 0.8229 - sensitivity_at_specificity_2: 0.9209 - specificity_at_sensitivity_2: 0.9732 - recall_2: 0.7914 - precision_2: 0.8333 - auc_2: 0.8931\n",
            "Epoch 306: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4146 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9245 - specificity_at_sensitivity_2: 0.9752 - recall_2: 0.7673 - precision_2: 0.8472 - auc_2: 0.8908 - val_loss: 0.3347 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9878 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8659 - val_precision_2: 0.8452 - val_auc_2: 0.9395\n",
            "Epoch 307/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3729 - accuracy: 0.8403 - sensitivity_at_specificity_2: 0.9510 - specificity_at_sensitivity_2: 0.9724 - recall_2: 0.8252 - precision_2: 0.8489 - auc_2: 0.9126\n",
            "Epoch 307: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3743 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9545 - specificity_at_sensitivity_2: 0.9759 - recall_2: 0.8312 - precision_2: 0.8312 - auc_2: 0.9130 - val_loss: 0.3979 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9211 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8421 - val_precision_2: 0.8312 - val_auc_2: 0.8990\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9500 - specificity_at_sensitivity_2: 0.9625 - recall_2: 0.8313 - precision_2: 0.8526 - auc_2: 0.9096\n",
            "Epoch 308: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3812 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9500 - specificity_at_sensitivity_2: 0.9625 - recall_2: 0.8313 - precision_2: 0.8526 - auc_2: 0.9096 - val_loss: 0.3108 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9770 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8851 - val_precision_2: 0.8953 - val_auc_2: 0.9434\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3793 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9438 - specificity_at_sensitivity_2: 0.9875 - recall_2: 0.7688 - precision_2: 0.8601 - auc_2: 0.9099\n",
            "Epoch 309: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3793 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9438 - specificity_at_sensitivity_2: 0.9875 - recall_2: 0.7688 - precision_2: 0.8601 - auc_2: 0.9099 - val_loss: 0.3507 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9518 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8554 - val_precision_2: 0.8659 - val_auc_2: 0.9292\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9470 - specificity_at_sensitivity_2: 0.9822 - recall_2: 0.7881 - precision_2: 0.8440 - auc_2: 0.9039\n",
            "Epoch 310: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3903 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9470 - specificity_at_sensitivity_2: 0.9822 - recall_2: 0.7881 - precision_2: 0.8440 - auc_2: 0.9039 - val_loss: 0.4311 - val_accuracy: 0.7875 - val_sensitivity_at_specificity_2: 0.9167 - val_specificity_at_sensitivity_2: 0.9886 - val_recall_2: 0.7639 - val_precision_2: 0.7639 - val_auc_2: 0.8774\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3561 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9529 - specificity_at_sensitivity_2: 0.9933 - recall_2: 0.8765 - precision_2: 0.8371 - auc_2: 0.9208\n",
            "Epoch 311: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3561 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9529 - specificity_at_sensitivity_2: 0.9933 - recall_2: 0.8765 - precision_2: 0.8371 - auc_2: 0.9208 - val_loss: 0.3274 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8987 - val_precision_2: 0.8659 - val_auc_2: 0.9378\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.8735 - specificity_at_sensitivity_2: 0.9091 - recall_2: 0.7590 - precision_2: 0.7975 - auc_2: 0.8336\n",
            "Epoch 312: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5170 - accuracy: 0.7750 - sensitivity_at_specificity_2: 0.8735 - specificity_at_sensitivity_2: 0.9091 - recall_2: 0.7590 - precision_2: 0.7975 - auc_2: 0.8336 - val_loss: 0.4852 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.8690 - val_specificity_at_sensitivity_2: 0.9868 - val_recall_2: 0.8214 - val_precision_2: 0.7753 - val_auc_2: 0.8579\n",
            "Epoch 313/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4028 - accuracy: 0.8194 - sensitivity_at_specificity_2: 0.9456 - specificity_at_sensitivity_2: 0.9929 - recall_2: 0.7687 - precision_2: 0.8626 - auc_2: 0.8993\n",
            "Epoch 313: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4106 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9367 - specificity_at_sensitivity_2: 0.9877 - recall_2: 0.7722 - precision_2: 0.8472 - auc_2: 0.8906 - val_loss: 0.4118 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9342 - val_specificity_at_sensitivity_2: 0.9881 - val_recall_2: 0.8553 - val_precision_2: 0.7647 - val_auc_2: 0.9123\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4543 - accuracy: 0.7966 - sensitivity_at_specificity_2: 0.9237 - specificity_at_sensitivity_2: 0.9686 - recall_2: 0.6718 - precision_2: 0.8462 - auc_2: 0.8645\n",
            "Epoch 314: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.4543 - accuracy: 0.7966 - sensitivity_at_specificity_2: 0.9237 - specificity_at_sensitivity_2: 0.9686 - recall_2: 0.6718 - precision_2: 0.8462 - auc_2: 0.8645 - val_loss: 0.4210 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9451 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.6813 - val_precision_2: 0.9538 - val_auc_2: 0.9244\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4240 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9273 - specificity_at_sensitivity_2: 0.9677 - recall_2: 0.7939 - precision_2: 0.8037 - auc_2: 0.8848\n",
            "Epoch 315: val_accuracy did not improve from 0.88125\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4240 - accuracy: 0.7937 - sensitivity_at_specificity_2: 0.9273 - specificity_at_sensitivity_2: 0.9677 - recall_2: 0.7939 - precision_2: 0.8037 - auc_2: 0.8848 - val_loss: 0.4699 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9438 - val_specificity_at_sensitivity_2: 0.9859 - val_recall_2: 0.8652 - val_precision_2: 0.7549 - val_auc_2: 0.8827\n",
            "Epoch 316/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4908 - accuracy: 0.7639 - sensitivity_at_specificity_2: 0.9155 - specificity_at_sensitivity_2: 0.9315 - recall_2: 0.6549 - precision_2: 0.8304 - auc_2: 0.8531\n",
            "Epoch 316: val_accuracy improved from 0.88125 to 0.91875, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4789 - accuracy: 0.7719 - sensitivity_at_specificity_2: 0.9167 - specificity_at_sensitivity_2: 0.9390 - recall_2: 0.6538 - precision_2: 0.8430 - auc_2: 0.8607 - val_loss: 0.2999 - val_accuracy: 0.9187 - val_sensitivity_at_specificity_2: 1.0000 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8659 - val_precision_2: 0.9726 - val_auc_2: 0.9689\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.8483 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.8264 - precision_2: 0.8623 - auc_2: 0.9117\n",
            "Epoch 317: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3742 - accuracy: 0.8483 - sensitivity_at_specificity_2: 0.9375 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.8264 - precision_2: 0.8623 - auc_2: 0.9117 - val_loss: 0.3817 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9889 - val_specificity_at_sensitivity_2: 0.9714 - val_recall_2: 0.8444 - val_precision_2: 0.8444 - val_auc_2: 0.9172\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9618 - specificity_at_sensitivity_2: 0.9693 - recall_2: 0.7707 - precision_2: 0.8176 - auc_2: 0.8887\n",
            "Epoch 318: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4256 - accuracy: 0.8031 - sensitivity_at_specificity_2: 0.9618 - specificity_at_sensitivity_2: 0.9693 - recall_2: 0.7707 - precision_2: 0.8176 - auc_2: 0.8887 - val_loss: 0.3934 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9452 - val_specificity_at_sensitivity_2: 0.9885 - val_recall_2: 0.8356 - val_precision_2: 0.8026 - val_auc_2: 0.9077\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9477 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.8198 - precision_2: 0.8704 - auc_2: 0.9101\n",
            "Epoch 319: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.3808 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9477 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.8198 - precision_2: 0.8704 - auc_2: 0.9101 - val_loss: 0.4405 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9452 - val_specificity_at_sensitivity_2: 0.9770 - val_recall_2: 0.9178 - val_precision_2: 0.7204 - val_auc_2: 0.9106\n",
            "Epoch 320/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3971 - accuracy: 0.8264 - sensitivity_at_specificity_2: 0.9343 - specificity_at_sensitivity_2: 0.9801 - recall_2: 0.8102 - precision_2: 0.8222 - auc_2: 0.8998\n",
            "Epoch 320: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3899 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9412 - specificity_at_sensitivity_2: 0.9880 - recall_2: 0.8039 - precision_2: 0.8367 - auc_2: 0.9038 - val_loss: 0.3555 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9425 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8506 - val_precision_2: 0.8916 - val_auc_2: 0.9232\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3774 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9481 - specificity_at_sensitivity_2: 0.9880 - recall_2: 0.7922 - precision_2: 0.8592 - auc_2: 0.9084\n",
            "Epoch 321: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3774 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9481 - specificity_at_sensitivity_2: 0.9880 - recall_2: 0.7922 - precision_2: 0.8592 - auc_2: 0.9084 - val_loss: 0.3502 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9737 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8158 - val_precision_2: 0.8378 - val_auc_2: 0.9255\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4103 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9542 - specificity_at_sensitivity_2: 0.9641 - recall_2: 0.7974 - precision_2: 0.8188 - auc_2: 0.8954\n",
            "Epoch 322: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4103 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9542 - specificity_at_sensitivity_2: 0.9641 - recall_2: 0.7974 - precision_2: 0.8188 - auc_2: 0.8954 - val_loss: 0.4344 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9333 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.6889 - val_precision_2: 0.9394 - val_auc_2: 0.9053\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3937 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9662 - specificity_at_sensitivity_2: 0.9826 - recall_2: 0.7568 - precision_2: 0.8421 - auc_2: 0.9034\n",
            "Epoch 323: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3937 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9662 - specificity_at_sensitivity_2: 0.9826 - recall_2: 0.7568 - precision_2: 0.8421 - auc_2: 0.9034 - val_loss: 0.4391 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.8919 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8649 - val_precision_2: 0.7191 - val_auc_2: 0.8902\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9500 - specificity_at_sensitivity_2: 0.9750 - recall_2: 0.8250 - precision_2: 0.8627 - auc_2: 0.9133\n",
            "Epoch 324: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3780 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9500 - specificity_at_sensitivity_2: 0.9750 - recall_2: 0.8250 - precision_2: 0.8627 - auc_2: 0.9133 - val_loss: 0.4088 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9231 - val_specificity_at_sensitivity_2: 0.9878 - val_recall_2: 0.7692 - val_precision_2: 0.8451 - val_auc_2: 0.8908\n",
            "Epoch 325/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3928 - accuracy: 0.8229 - sensitivity_at_specificity_2: 0.9453 - specificity_at_sensitivity_2: 0.9688 - recall_2: 0.7812 - precision_2: 0.8130 - auc_2: 0.8982\n",
            "Epoch 325: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4059 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9521 - specificity_at_sensitivity_2: 0.9713 - recall_2: 0.7671 - precision_2: 0.8175 - auc_2: 0.8921 - val_loss: 0.3853 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9306 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8056 - val_precision_2: 0.8169 - val_auc_2: 0.9065\n",
            "Epoch 326/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3640 - accuracy: 0.8472 - sensitivity_at_specificity_2: 0.9733 - specificity_at_sensitivity_2: 0.9928 - recall_2: 0.8267 - precision_2: 0.8732 - auc_2: 0.9214\n",
            "Epoch 326: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3739 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9753 - specificity_at_sensitivity_2: 0.9873 - recall_2: 0.8395 - precision_2: 0.8500 - auc_2: 0.9155 - val_loss: 0.5381 - val_accuracy: 0.7625 - val_sensitivity_at_specificity_2: 0.8415 - val_specificity_at_sensitivity_2: 0.9615 - val_recall_2: 0.8293 - val_precision_2: 0.7391 - val_auc_2: 0.8297\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4167 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9193 - specificity_at_sensitivity_2: 0.9748 - recall_2: 0.8012 - precision_2: 0.8600 - auc_2: 0.8885\n",
            "Epoch 327: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4167 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9193 - specificity_at_sensitivity_2: 0.9748 - recall_2: 0.8012 - precision_2: 0.8600 - auc_2: 0.8885 - val_loss: 0.3358 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9595 - val_specificity_at_sensitivity_2: 0.9884 - val_recall_2: 0.8243 - val_precision_2: 0.8841 - val_auc_2: 0.9321\n",
            "Epoch 328/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3350 - accuracy: 0.8472 - sensitivity_at_specificity_2: 0.9574 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.8298 - precision_2: 0.8540 - auc_2: 0.9307\n",
            "Epoch 328: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3378 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9500 - specificity_at_sensitivity_2: 0.9875 - recall_2: 0.8313 - precision_2: 0.8636 - auc_2: 0.9270 - val_loss: 0.3322 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8590 - val_precision_2: 0.8933 - val_auc_2: 0.9214\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9623 - specificity_at_sensitivity_2: 0.9627 - recall_2: 0.8113 - precision_2: 0.8062 - auc_2: 0.8915\n",
            "Epoch 329: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4311 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9623 - specificity_at_sensitivity_2: 0.9627 - recall_2: 0.8113 - precision_2: 0.8062 - auc_2: 0.8915 - val_loss: 0.4019 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9467 - val_specificity_at_sensitivity_2: 0.9765 - val_recall_2: 0.8267 - val_precision_2: 0.8378 - val_auc_2: 0.8976\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3735 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9627 - specificity_at_sensitivity_2: 0.9811 - recall_2: 0.7826 - precision_2: 0.8690 - auc_2: 0.9200\n",
            "Epoch 330: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3735 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9627 - specificity_at_sensitivity_2: 0.9811 - recall_2: 0.7826 - precision_2: 0.8690 - auc_2: 0.9200 - val_loss: 0.3656 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 0.9259 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.8272 - val_precision_2: 0.9437 - val_auc_2: 0.9155\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9593 - specificity_at_sensitivity_2: 0.9797 - recall_2: 0.8256 - precision_2: 0.8452 - auc_2: 0.9011\n",
            "Epoch 331: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3938 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9593 - specificity_at_sensitivity_2: 0.9797 - recall_2: 0.8256 - precision_2: 0.8452 - auc_2: 0.9011 - val_loss: 0.3554 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9259 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.7901 - val_precision_2: 0.8889 - val_auc_2: 0.9161\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4224 - accuracy: 0.8276 - sensitivity_at_specificity_2: 0.9216 - specificity_at_sensitivity_2: 0.9927 - recall_2: 0.8170 - precision_2: 0.8503 - auc_2: 0.8829\n",
            "Epoch 332: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4224 - accuracy: 0.8276 - sensitivity_at_specificity_2: 0.9216 - specificity_at_sensitivity_2: 0.9927 - recall_2: 0.8170 - precision_2: 0.8503 - auc_2: 0.8829 - val_loss: 0.4495 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.8974 - val_specificity_at_sensitivity_2: 0.9756 - val_recall_2: 0.8333 - val_precision_2: 0.8125 - val_auc_2: 0.8723\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9195 - specificity_at_sensitivity_2: 0.9942 - recall_2: 0.7584 - precision_2: 0.8370 - auc_2: 0.8951\n",
            "Epoch 333: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3987 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9195 - specificity_at_sensitivity_2: 0.9942 - recall_2: 0.7584 - precision_2: 0.8370 - auc_2: 0.8951 - val_loss: 0.3609 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.8272 - val_precision_2: 0.8816 - val_auc_2: 0.9181\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4157 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9487 - specificity_at_sensitivity_2: 0.9573 - recall_2: 0.7885 - precision_2: 0.7935 - auc_2: 0.8918\n",
            "Epoch 334: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4157 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9487 - specificity_at_sensitivity_2: 0.9573 - recall_2: 0.7885 - precision_2: 0.7935 - auc_2: 0.8918 - val_loss: 0.3613 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9405 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8810 - val_precision_2: 0.8506 - val_auc_2: 0.9161\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9451 - specificity_at_sensitivity_2: 0.9872 - recall_2: 0.7561 - precision_2: 0.8611 - auc_2: 0.8994\n",
            "Epoch 335: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3952 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9451 - specificity_at_sensitivity_2: 0.9872 - recall_2: 0.7561 - precision_2: 0.8611 - auc_2: 0.8994 - val_loss: 0.3510 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9733 - val_specificity_at_sensitivity_2: 0.9882 - val_recall_2: 0.8667 - val_precision_2: 0.8667 - val_auc_2: 0.9367\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9363 - specificity_at_sensitivity_2: 0.9693 - recall_2: 0.7771 - precision_2: 0.8243 - auc_2: 0.8932\n",
            "Epoch 336: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4131 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9363 - specificity_at_sensitivity_2: 0.9693 - recall_2: 0.7771 - precision_2: 0.8243 - auc_2: 0.8932 - val_loss: 0.3469 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9403 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8209 - val_precision_2: 0.8730 - val_auc_2: 0.9280\n",
            "Epoch 337/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3795 - accuracy: 0.8368 - sensitivity_at_specificity_2: 0.9680 - specificity_at_sensitivity_2: 0.9816 - recall_2: 0.7600 - precision_2: 0.8482 - auc_2: 0.9138\n",
            "Epoch 337: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3890 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9580 - specificity_at_sensitivity_2: 0.9774 - recall_2: 0.7762 - precision_2: 0.8409 - auc_2: 0.9063 - val_loss: 0.3264 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9639 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8675 - val_precision_2: 0.8675 - val_auc_2: 0.9398\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9355 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.7935 - precision_2: 0.8425 - auc_2: 0.9008\n",
            "Epoch 338: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3906 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9355 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.7935 - precision_2: 0.8425 - auc_2: 0.9008 - val_loss: 0.3410 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9747 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8861 - val_precision_2: 0.8434 - val_auc_2: 0.9362\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3625 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9630 - specificity_at_sensitivity_2: 0.9873 - recall_2: 0.8457 - precision_2: 0.8562 - auc_2: 0.9195\n",
            "Epoch 339: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3625 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9630 - specificity_at_sensitivity_2: 0.9873 - recall_2: 0.8457 - precision_2: 0.8562 - auc_2: 0.9195 - val_loss: 0.3594 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9425 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7931 - val_precision_2: 0.9200 - val_auc_2: 0.9158\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9593 - specificity_at_sensitivity_2: 0.9797 - recall_2: 0.8488 - precision_2: 0.8639 - auc_2: 0.9135\n",
            "Epoch 340: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3699 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9593 - specificity_at_sensitivity_2: 0.9797 - recall_2: 0.8488 - precision_2: 0.8639 - auc_2: 0.9135 - val_loss: 0.2974 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9730 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9054 - val_precision_2: 0.8272 - val_auc_2: 0.9520\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3530 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9663 - specificity_at_sensitivity_2: 0.9789 - recall_2: 0.8596 - precision_2: 0.8547 - auc_2: 0.9249\n",
            "Epoch 341: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3530 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9663 - specificity_at_sensitivity_2: 0.9789 - recall_2: 0.8596 - precision_2: 0.8547 - auc_2: 0.9249 - val_loss: 0.3242 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8481 - val_precision_2: 0.9054 - val_auc_2: 0.9253\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9756 - specificity_at_sensitivity_2: 0.9936 - recall_2: 0.8476 - precision_2: 0.8373 - auc_2: 0.9231\n",
            "Epoch 342: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3575 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9756 - specificity_at_sensitivity_2: 0.9936 - recall_2: 0.8476 - precision_2: 0.8373 - auc_2: 0.9231 - val_loss: 0.3409 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9737 - val_specificity_at_sensitivity_2: 0.9762 - val_recall_2: 0.8816 - val_precision_2: 0.8375 - val_auc_2: 0.9290\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9886 - recall_2: 0.7778 - precision_2: 0.8485 - auc_2: 0.9047\n",
            "Epoch 343: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3820 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9886 - recall_2: 0.7778 - precision_2: 0.8485 - auc_2: 0.9047 - val_loss: 0.3625 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9500 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7875 - val_precision_2: 0.9130 - val_auc_2: 0.9120\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9769 - specificity_at_sensitivity_2: 0.9796 - recall_2: 0.8382 - precision_2: 0.8430 - auc_2: 0.9073\n",
            "Epoch 344: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3857 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9769 - specificity_at_sensitivity_2: 0.9796 - recall_2: 0.8382 - precision_2: 0.8430 - auc_2: 0.9073 - val_loss: 0.4850 - val_accuracy: 0.7437 - val_sensitivity_at_specificity_2: 0.9444 - val_specificity_at_sensitivity_2: 0.9773 - val_recall_2: 0.8750 - val_precision_2: 0.6632 - val_auc_2: 0.8953\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9435 - specificity_at_sensitivity_2: 0.9720 - recall_2: 0.8023 - precision_2: 0.8659 - auc_2: 0.8952\n",
            "Epoch 345: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4047 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9435 - specificity_at_sensitivity_2: 0.9720 - recall_2: 0.8023 - precision_2: 0.8659 - auc_2: 0.8952 - val_loss: 0.3626 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9451 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8352 - val_precision_2: 0.9157 - val_auc_2: 0.9181\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9708 - specificity_at_sensitivity_2: 0.9732 - recall_2: 0.8480 - precision_2: 0.8333 - auc_2: 0.9103\n",
            "Epoch 346: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3810 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9708 - specificity_at_sensitivity_2: 0.9732 - recall_2: 0.8480 - precision_2: 0.8333 - auc_2: 0.9103 - val_loss: 0.3864 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9540 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7816 - val_precision_2: 0.9315 - val_auc_2: 0.9111\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9747 - recall_2: 0.8086 - precision_2: 0.8562 - auc_2: 0.8990\n",
            "Epoch 347: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3992 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9747 - recall_2: 0.8086 - precision_2: 0.8562 - auc_2: 0.8990 - val_loss: 0.2916 - val_accuracy: 0.9000 - val_sensitivity_at_specificity_2: 0.9868 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9079 - val_precision_2: 0.8846 - val_auc_2: 0.9583\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3696 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9860 - specificity_at_sensitivity_2: 0.9661 - recall_2: 0.7972 - precision_2: 0.8444 - auc_2: 0.9201\n",
            "Epoch 348: val_accuracy did not improve from 0.91875\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3696 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9860 - specificity_at_sensitivity_2: 0.9661 - recall_2: 0.7972 - precision_2: 0.8444 - auc_2: 0.9201 - val_loss: 0.3828 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9041 - val_specificity_at_sensitivity_2: 0.9885 - val_recall_2: 0.7808 - val_precision_2: 0.9194 - val_auc_2: 0.8899\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9405 - specificity_at_sensitivity_2: 0.9605 - recall_2: 0.8214 - precision_2: 0.8415 - auc_2: 0.8957\n",
            "Epoch 349: val_accuracy improved from 0.91875 to 0.93750, saving model to ECG_Model_Lead_4.h5\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4059 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9405 - specificity_at_sensitivity_2: 0.9605 - recall_2: 0.8214 - precision_2: 0.8415 - auc_2: 0.8957 - val_loss: 0.2388 - val_accuracy: 0.9375 - val_sensitivity_at_specificity_2: 0.9865 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9595 - val_precision_2: 0.9103 - val_auc_2: 0.9788\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9371 - specificity_at_sensitivity_2: 0.9814 - recall_2: 0.7862 - precision_2: 0.8503 - auc_2: 0.8913\n",
            "Epoch 350: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4077 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9371 - specificity_at_sensitivity_2: 0.9814 - recall_2: 0.7862 - precision_2: 0.8503 - auc_2: 0.8913 - val_loss: 0.4286 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9205 - val_specificity_at_sensitivity_2: 0.9861 - val_recall_2: 0.9091 - val_precision_2: 0.7477 - val_auc_2: 0.9084\n",
            "Epoch 351/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4053 - accuracy: 0.8194 - sensitivity_at_specificity_2: 0.9559 - specificity_at_sensitivity_2: 0.9671 - recall_2: 0.8015 - precision_2: 0.8134 - auc_2: 0.8976\n",
            "Epoch 351: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4019 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9533 - specificity_at_sensitivity_2: 0.9706 - recall_2: 0.7867 - precision_2: 0.8194 - auc_2: 0.8995 - val_loss: 0.3424 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9605 - val_specificity_at_sensitivity_2: 0.9881 - val_recall_2: 0.8553 - val_precision_2: 0.8553 - val_auc_2: 0.9320\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3479 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9815 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.8642 - precision_2: 0.8537 - auc_2: 0.9317\n",
            "Epoch 352: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3479 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9815 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.8642 - precision_2: 0.8537 - auc_2: 0.9317 - val_loss: 0.3385 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9459 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8243 - val_precision_2: 0.8472 - val_auc_2: 0.9217\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4028 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9333 - specificity_at_sensitivity_2: 0.9613 - recall_2: 0.8000 - precision_2: 0.8571 - auc_2: 0.8975\n",
            "Epoch 353: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4028 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9333 - specificity_at_sensitivity_2: 0.9613 - recall_2: 0.8000 - precision_2: 0.8571 - auc_2: 0.8975 - val_loss: 0.3140 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 0.9610 - val_specificity_at_sensitivity_2: 0.9880 - val_recall_2: 0.8442 - val_precision_2: 0.9155 - val_auc_2: 0.9397\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3990 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9189 - specificity_at_sensitivity_2: 0.9884 - recall_2: 0.7162 - precision_2: 0.9060 - auc_2: 0.8930\n",
            "Epoch 354: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3990 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9189 - specificity_at_sensitivity_2: 0.9884 - recall_2: 0.7162 - precision_2: 0.9060 - auc_2: 0.8930 - val_loss: 0.4086 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9625 - val_specificity_at_sensitivity_2: 0.9875 - val_recall_2: 0.8000 - val_precision_2: 0.8000 - val_auc_2: 0.9035\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3773 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9620 - specificity_at_sensitivity_2: 0.9938 - recall_2: 0.8418 - precision_2: 0.8160 - auc_2: 0.9154\n",
            "Epoch 355: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3773 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9620 - specificity_at_sensitivity_2: 0.9938 - recall_2: 0.8418 - precision_2: 0.8160 - auc_2: 0.9154 - val_loss: 0.3102 - val_accuracy: 0.9000 - val_sensitivity_at_specificity_2: 0.9753 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8395 - val_precision_2: 0.9577 - val_auc_2: 0.9550\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4477 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9259 - specificity_at_sensitivity_2: 0.9557 - recall_2: 0.7654 - precision_2: 0.8435 - auc_2: 0.8709\n",
            "Epoch 356: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4477 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9259 - specificity_at_sensitivity_2: 0.9557 - recall_2: 0.7654 - precision_2: 0.8435 - auc_2: 0.8709 - val_loss: 0.3134 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 0.9759 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8916 - val_precision_2: 0.8916 - val_auc_2: 0.9459\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9333 - specificity_at_sensitivity_2: 0.9806 - recall_2: 0.7758 - precision_2: 0.8477 - auc_2: 0.8874\n",
            "Epoch 357: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4176 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9333 - specificity_at_sensitivity_2: 0.9806 - recall_2: 0.7758 - precision_2: 0.8477 - auc_2: 0.8874 - val_loss: 0.3410 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9726 - val_specificity_at_sensitivity_2: 0.9885 - val_recall_2: 0.8356 - val_precision_2: 0.8714 - val_auc_2: 0.9321\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.8625 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.8148 - precision_2: 0.9041 - auc_2: 0.9205\n",
            "Epoch 358: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3548 - accuracy: 0.8625 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.8148 - precision_2: 0.9041 - auc_2: 0.9205 - val_loss: 0.3858 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9383 - val_specificity_at_sensitivity_2: 0.9747 - val_recall_2: 0.8395 - val_precision_2: 0.8608 - val_auc_2: 0.9046\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3649 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9691 - specificity_at_sensitivity_2: 0.9873 - recall_2: 0.8272 - precision_2: 0.8816 - auc_2: 0.9193\n",
            "Epoch 359: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3649 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9691 - specificity_at_sensitivity_2: 0.9873 - recall_2: 0.8272 - precision_2: 0.8816 - auc_2: 0.9193 - val_loss: 0.3721 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9012 - val_precision_2: 0.8391 - val_auc_2: 0.9185\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9695 - specificity_at_sensitivity_2: 0.9808 - recall_2: 0.8232 - precision_2: 0.8654 - auc_2: 0.9081\n",
            "Epoch 360: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3869 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9695 - specificity_at_sensitivity_2: 0.9808 - recall_2: 0.8232 - precision_2: 0.8654 - auc_2: 0.9081 - val_loss: 0.3416 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9211 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8947 - val_precision_2: 0.8395 - val_auc_2: 0.9309\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3080 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9740 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8247 - precision_2: 0.8944 - auc_2: 0.9447\n",
            "Epoch 361: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3080 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9740 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8247 - precision_2: 0.8944 - auc_2: 0.9447 - val_loss: 0.2855 - val_accuracy: 0.9000 - val_sensitivity_at_specificity_2: 0.9750 - val_specificity_at_sensitivity_2: 0.9875 - val_recall_2: 0.8750 - val_precision_2: 0.9211 - val_auc_2: 0.9542\n",
            "Epoch 362/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3730 - accuracy: 0.8264 - sensitivity_at_specificity_2: 0.9448 - specificity_at_sensitivity_2: 0.9930 - recall_2: 0.8138 - precision_2: 0.8369 - auc_2: 0.9121\n",
            "Epoch 362: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3647 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9494 - specificity_at_sensitivity_2: 0.9938 - recall_2: 0.8101 - precision_2: 0.8366 - auc_2: 0.9161 - val_loss: 0.2774 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_2: 0.9881 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8571 - val_precision_2: 0.9351 - val_auc_2: 0.9692\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9427 - specificity_at_sensitivity_2: 0.9755 - recall_2: 0.8471 - precision_2: 0.8526 - auc_2: 0.9047\n",
            "Epoch 363: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3870 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9427 - specificity_at_sensitivity_2: 0.9755 - recall_2: 0.8471 - precision_2: 0.8526 - auc_2: 0.9047 - val_loss: 0.3697 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 0.9205 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8068 - val_precision_2: 0.9861 - val_auc_2: 0.9087\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9408 - specificity_at_sensitivity_2: 0.9669 - recall_2: 0.7692 - precision_2: 0.8387 - auc_2: 0.8847\n",
            "Epoch 364: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4330 - accuracy: 0.8000 - sensitivity_at_specificity_2: 0.9408 - specificity_at_sensitivity_2: 0.9669 - recall_2: 0.7692 - precision_2: 0.8387 - auc_2: 0.8847 - val_loss: 0.3111 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9873 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9241 - val_precision_2: 0.8295 - val_auc_2: 0.9580\n",
            "Epoch 365/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3370 - accuracy: 0.8646 - sensitivity_at_specificity_2: 0.9643 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.8643 - precision_2: 0.8582 - auc_2: 0.9323\n",
            "Epoch 365: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3367 - accuracy: 0.8656 - sensitivity_at_specificity_2: 0.9810 - specificity_at_sensitivity_2: 0.9938 - recall_2: 0.8544 - precision_2: 0.8710 - auc_2: 0.9328 - val_loss: 0.3868 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.8961 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7403 - val_precision_2: 0.8906 - val_auc_2: 0.8975\n",
            "Epoch 366/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3529 - accuracy: 0.8611 - sensitivity_at_specificity_2: 0.9385 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.8231 - precision_2: 0.8629 - auc_2: 0.9164\n",
            "Epoch 366: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3592 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9444 - specificity_at_sensitivity_2: 0.9886 - recall_2: 0.8194 - precision_2: 0.8613 - auc_2: 0.9154 - val_loss: 0.3484 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9639 - val_specificity_at_sensitivity_2: 0.9870 - val_recall_2: 0.8554 - val_precision_2: 0.8765 - val_auc_2: 0.9267\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9441 - specificity_at_sensitivity_2: 0.9858 - recall_2: 0.7598 - precision_2: 0.9067 - auc_2: 0.8973\n",
            "Epoch 367: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4085 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9441 - specificity_at_sensitivity_2: 0.9858 - recall_2: 0.7598 - precision_2: 0.9067 - auc_2: 0.8973 - val_loss: 0.4039 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9036 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8554 - val_precision_2: 0.7802 - val_auc_2: 0.9000\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.8781 - sensitivity_at_specificity_2: 0.9812 - specificity_at_sensitivity_2: 0.9812 - recall_2: 0.8562 - precision_2: 0.8954 - auc_2: 0.9394\n",
            "Epoch 368: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3178 - accuracy: 0.8781 - sensitivity_at_specificity_2: 0.9812 - specificity_at_sensitivity_2: 0.9812 - recall_2: 0.8562 - precision_2: 0.8954 - auc_2: 0.9394 - val_loss: 0.4040 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9467 - val_specificity_at_sensitivity_2: 0.9647 - val_recall_2: 0.6933 - val_precision_2: 0.8667 - val_auc_2: 0.8937\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3264 - accuracy: 0.8625 - sensitivity_at_specificity_2: 0.9740 - specificity_at_sensitivity_2: 0.9880 - recall_2: 0.8442 - precision_2: 0.8667 - auc_2: 0.9353\n",
            "Epoch 369: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3264 - accuracy: 0.8625 - sensitivity_at_specificity_2: 0.9740 - specificity_at_sensitivity_2: 0.9880 - recall_2: 0.8442 - precision_2: 0.8667 - auc_2: 0.9353 - val_loss: 0.3623 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9651 - val_specificity_at_sensitivity_2: 0.9730 - val_recall_2: 0.8953 - val_precision_2: 0.8191 - val_auc_2: 0.9199\n",
            "Epoch 370/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3732 - accuracy: 0.8090 - sensitivity_at_specificity_2: 0.9706 - specificity_at_sensitivity_2: 0.9868 - recall_2: 0.7574 - precision_2: 0.8240 - auc_2: 0.9121\n",
            "Epoch 370: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3725 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9744 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.7692 - precision_2: 0.8276 - auc_2: 0.9137 - val_loss: 0.3307 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9467 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8933 - val_precision_2: 0.8272 - val_auc_2: 0.9322\n",
            "Epoch 371/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3743 - accuracy: 0.8299 - sensitivity_at_specificity_2: 0.9577 - specificity_at_sensitivity_2: 0.9726 - recall_2: 0.8169 - precision_2: 0.8345 - auc_2: 0.9135\n",
            "Epoch 371: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3896 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9615 - specificity_at_sensitivity_2: 0.9695 - recall_2: 0.8269 - precision_2: 0.8113 - auc_2: 0.9089 - val_loss: 0.3197 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_2: 0.9759 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9398 - val_precision_2: 0.8667 - val_auc_2: 0.9493\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3404 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9640 - specificity_at_sensitivity_2: 0.9890 - recall_2: 0.7554 - precision_2: 0.8824 - auc_2: 0.9283\n",
            "Epoch 372: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3404 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9640 - specificity_at_sensitivity_2: 0.9890 - recall_2: 0.7554 - precision_2: 0.8824 - auc_2: 0.9283 - val_loss: 0.2912 - val_accuracy: 0.9000 - val_sensitivity_at_specificity_2: 0.9744 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8846 - val_precision_2: 0.9079 - val_auc_2: 0.9462\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4161 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9202 - specificity_at_sensitivity_2: 0.9682 - recall_2: 0.8037 - precision_2: 0.8344 - auc_2: 0.8863\n",
            "Epoch 373: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4161 - accuracy: 0.8188 - sensitivity_at_specificity_2: 0.9202 - specificity_at_sensitivity_2: 0.9682 - recall_2: 0.8037 - precision_2: 0.8344 - auc_2: 0.8863 - val_loss: 0.2967 - val_accuracy: 0.9000 - val_sensitivity_at_specificity_2: 0.9512 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8902 - val_precision_2: 0.9125 - val_auc_2: 0.9465\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3551 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9465 - specificity_at_sensitivity_2: 0.9850 - recall_2: 0.8770 - precision_2: 0.8586 - auc_2: 0.9195\n",
            "Epoch 374: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3551 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9465 - specificity_at_sensitivity_2: 0.9850 - recall_2: 0.8770 - precision_2: 0.8586 - auc_2: 0.9195 - val_loss: 0.4123 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9114 - val_precision_2: 0.7347 - val_auc_2: 0.9189\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3727 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9605 - specificity_at_sensitivity_2: 0.9930 - recall_2: 0.8588 - precision_2: 0.8444 - auc_2: 0.9123\n",
            "Epoch 375: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3727 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9605 - specificity_at_sensitivity_2: 0.9930 - recall_2: 0.8588 - precision_2: 0.8444 - auc_2: 0.9123 - val_loss: 0.3298 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9762 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8690 - val_precision_2: 0.8902 - val_auc_2: 0.9333\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3768 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9812 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.7312 - precision_2: 0.9286 - auc_2: 0.9278\n",
            "Epoch 376: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3768 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9812 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.7312 - precision_2: 0.9286 - auc_2: 0.9278 - val_loss: 0.4350 - val_accuracy: 0.7688 - val_sensitivity_at_specificity_2: 0.9459 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8108 - val_precision_2: 0.7229 - val_auc_2: 0.8905\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9634 - specificity_at_sensitivity_2: 0.9936 - recall_2: 0.8963 - precision_2: 0.8122 - auc_2: 0.9212\n",
            "Epoch 377: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3738 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9634 - specificity_at_sensitivity_2: 0.9936 - recall_2: 0.8963 - precision_2: 0.8122 - auc_2: 0.9212 - val_loss: 0.3308 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8272 - val_precision_2: 0.9437 - val_auc_2: 0.9408\n",
            "Epoch 378/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3991 - accuracy: 0.8229 - sensitivity_at_specificity_2: 0.9286 - specificity_at_sensitivity_2: 0.9925 - recall_2: 0.7403 - precision_2: 0.9120 - auc_2: 0.9036\n",
            "Epoch 378: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4088 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9306 - specificity_at_sensitivity_2: 0.9864 - recall_2: 0.7457 - precision_2: 0.8836 - auc_2: 0.8979 - val_loss: 0.3635 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9630 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.8272 - val_precision_2: 0.8590 - val_auc_2: 0.9191\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9317 - specificity_at_sensitivity_2: 0.9811 - recall_2: 0.8323 - precision_2: 0.8375 - auc_2: 0.9038\n",
            "Epoch 379: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3819 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9317 - specificity_at_sensitivity_2: 0.9811 - recall_2: 0.8323 - precision_2: 0.8375 - auc_2: 0.9038 - val_loss: 0.3327 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9620 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7975 - val_precision_2: 0.9000 - val_auc_2: 0.9349\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3684 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9341 - specificity_at_sensitivity_2: 0.9804 - recall_2: 0.7784 - precision_2: 0.9220 - auc_2: 0.9177\n",
            "Epoch 380: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3684 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9341 - specificity_at_sensitivity_2: 0.9804 - recall_2: 0.7784 - precision_2: 0.9220 - auc_2: 0.9177 - val_loss: 0.3469 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9625 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9000 - val_precision_2: 0.8675 - val_auc_2: 0.9383\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3693 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9647 - specificity_at_sensitivity_2: 0.9867 - recall_2: 0.8588 - precision_2: 0.8391 - auc_2: 0.9142\n",
            "Epoch 381: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.3693 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9647 - specificity_at_sensitivity_2: 0.9867 - recall_2: 0.8588 - precision_2: 0.8391 - auc_2: 0.9142 - val_loss: 0.3646 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9512 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7073 - val_precision_2: 0.9508 - val_auc_2: 0.9279\n",
            "Epoch 382/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3994 - accuracy: 0.7951 - sensitivity_at_specificity_2: 0.9660 - specificity_at_sensitivity_2: 0.9858 - recall_2: 0.7211 - precision_2: 0.8548 - auc_2: 0.9079\n",
            "Epoch 382: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3997 - accuracy: 0.7969 - sensitivity_at_specificity_2: 0.9571 - specificity_at_sensitivity_2: 0.9809 - recall_2: 0.7423 - precision_2: 0.8403 - auc_2: 0.9037 - val_loss: 0.3432 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_2: 0.9444 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8611 - val_precision_2: 0.8986 - val_auc_2: 0.9193\n",
            "Epoch 383/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4014 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9388 - specificity_at_sensitivity_2: 0.9929 - recall_2: 0.8163 - precision_2: 0.8163 - auc_2: 0.8968\n",
            "Epoch 383: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4065 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9394 - specificity_at_sensitivity_2: 0.9935 - recall_2: 0.8000 - precision_2: 0.8250 - auc_2: 0.8935 - val_loss: 0.3474 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9625 - val_specificity_at_sensitivity_2: 0.9875 - val_recall_2: 0.7500 - val_precision_2: 0.9375 - val_auc_2: 0.9355\n",
            "Epoch 384/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3943 - accuracy: 0.8194 - sensitivity_at_specificity_2: 0.9645 - specificity_at_sensitivity_2: 0.9864 - recall_2: 0.8227 - precision_2: 0.8112 - auc_2: 0.9052\n",
            "Epoch 384: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3994 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9610 - specificity_at_sensitivity_2: 0.9880 - recall_2: 0.8247 - precision_2: 0.7937 - auc_2: 0.9026 - val_loss: 0.3646 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9452 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7808 - val_precision_2: 0.8261 - val_auc_2: 0.9166\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3600 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9615 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.7500 - precision_2: 0.9070 - auc_2: 0.9283\n",
            "Epoch 385: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3600 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9615 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.7500 - precision_2: 0.9070 - auc_2: 0.9283 - val_loss: 0.3452 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9747 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8734 - val_precision_2: 0.8313 - val_auc_2: 0.9303\n",
            "Epoch 386/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4212 - accuracy: 0.8021 - sensitivity_at_specificity_2: 0.9527 - specificity_at_sensitivity_2: 0.9714 - recall_2: 0.8446 - precision_2: 0.7862 - auc_2: 0.8945\n",
            "Epoch 386: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4045 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9573 - specificity_at_sensitivity_2: 0.9744 - recall_2: 0.8537 - precision_2: 0.8000 - auc_2: 0.9015 - val_loss: 0.2876 - val_accuracy: 0.9312 - val_sensitivity_at_specificity_2: 0.9706 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8971 - val_precision_2: 0.9385 - val_auc_2: 0.9527\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9459 - specificity_at_sensitivity_2: 0.9926 - recall_2: 0.8054 - precision_2: 0.8663 - auc_2: 0.9027\n",
            "Epoch 387: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3957 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9459 - specificity_at_sensitivity_2: 0.9926 - recall_2: 0.8054 - precision_2: 0.8663 - auc_2: 0.9027 - val_loss: 0.3570 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9750 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8625 - val_precision_2: 0.8519 - val_auc_2: 0.9252\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9518 - specificity_at_sensitivity_2: 0.9805 - recall_2: 0.8072 - precision_2: 0.8701 - auc_2: 0.9050\n",
            "Epoch 388: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3830 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9518 - specificity_at_sensitivity_2: 0.9805 - recall_2: 0.8072 - precision_2: 0.8701 - auc_2: 0.9050 - val_loss: 0.3360 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9560 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8352 - val_precision_2: 0.9157 - val_auc_2: 0.9244\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3769 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9877 - specificity_at_sensitivity_2: 0.9618 - recall_2: 0.8282 - precision_2: 0.8710 - auc_2: 0.9160\n",
            "Epoch 389: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3769 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9877 - specificity_at_sensitivity_2: 0.9618 - recall_2: 0.8282 - precision_2: 0.8710 - auc_2: 0.9160 - val_loss: 0.3327 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9157 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7952 - val_precision_2: 0.9296 - val_auc_2: 0.9243\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9236 - specificity_at_sensitivity_2: 0.9816 - recall_2: 0.7516 - precision_2: 0.8939 - auc_2: 0.8986\n",
            "Epoch 390: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3903 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9236 - specificity_at_sensitivity_2: 0.9816 - recall_2: 0.7516 - precision_2: 0.8939 - auc_2: 0.8986 - val_loss: 0.3107 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9355 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8817 - val_precision_2: 0.9011 - val_auc_2: 0.9341\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9506 - specificity_at_sensitivity_2: 0.9747 - recall_2: 0.8580 - precision_2: 0.8274 - auc_2: 0.9047\n",
            "Epoch 391: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3965 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9506 - specificity_at_sensitivity_2: 0.9747 - recall_2: 0.8580 - precision_2: 0.8274 - auc_2: 0.9047 - val_loss: 0.3929 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 0.9873 - val_recall_2: 0.7407 - val_precision_2: 0.9231 - val_auc_2: 0.9091\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.8875 - sensitivity_at_specificity_2: 0.9342 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8026 - precision_2: 0.9531 - auc_2: 0.9237\n",
            "Epoch 392: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3482 - accuracy: 0.8875 - sensitivity_at_specificity_2: 0.9342 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8026 - precision_2: 0.9531 - auc_2: 0.9237 - val_loss: 0.4317 - val_accuracy: 0.7563 - val_sensitivity_at_specificity_2: 0.9259 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8272 - val_precision_2: 0.7283 - val_auc_2: 0.8946\n",
            "Epoch 393/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3671 - accuracy: 0.8472 - sensitivity_at_specificity_2: 0.9673 - specificity_at_sensitivity_2: 0.9704 - recall_2: 0.8562 - precision_2: 0.8562 - auc_2: 0.9179\n",
            "Epoch 393: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3635 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9641 - specificity_at_sensitivity_2: 0.9739 - recall_2: 0.8443 - precision_2: 0.8545 - auc_2: 0.9195 - val_loss: 0.3879 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9277 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7711 - val_precision_2: 0.8421 - val_auc_2: 0.9016\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9562 - specificity_at_sensitivity_2: 0.9781 - recall_2: 0.8467 - precision_2: 0.8227 - auc_2: 0.9283\n",
            "Epoch 394: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.3313 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9562 - specificity_at_sensitivity_2: 0.9781 - recall_2: 0.8467 - precision_2: 0.8227 - auc_2: 0.9283 - val_loss: 0.3108 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_2: 0.9405 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8214 - val_precision_2: 0.9718 - val_auc_2: 0.9398\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3413 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9691 - specificity_at_sensitivity_2: 0.9873 - recall_2: 0.8086 - precision_2: 0.8912 - auc_2: 0.9301\n",
            "Epoch 395: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3413 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9691 - specificity_at_sensitivity_2: 0.9873 - recall_2: 0.8086 - precision_2: 0.8912 - auc_2: 0.9301 - val_loss: 0.3128 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9500 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8500 - val_precision_2: 0.8947 - val_auc_2: 0.9400\n",
            "Epoch 396/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4086 - accuracy: 0.8160 - sensitivity_at_specificity_2: 0.9128 - specificity_at_sensitivity_2: 0.9856 - recall_2: 0.7852 - precision_2: 0.8478 - auc_2: 0.8898\n",
            "Epoch 396: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4125 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9162 - specificity_at_sensitivity_2: 0.9869 - recall_2: 0.7904 - precision_2: 0.8408 - auc_2: 0.8881 - val_loss: 0.3520 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9383 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8642 - val_precision_2: 0.8434 - val_auc_2: 0.9198\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9682 - specificity_at_sensitivity_2: 0.9816 - recall_2: 0.8408 - precision_2: 0.8627 - auc_2: 0.9300\n",
            "Epoch 397: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3391 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9682 - specificity_at_sensitivity_2: 0.9816 - recall_2: 0.8408 - precision_2: 0.8627 - auc_2: 0.9300 - val_loss: 0.3229 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 0.9265 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8382 - val_precision_2: 0.8906 - val_auc_2: 0.9114\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9441 - specificity_at_sensitivity_2: 0.9874 - recall_2: 0.7888 - precision_2: 0.8759 - auc_2: 0.9097\n",
            "Epoch 398: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3813 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9441 - specificity_at_sensitivity_2: 0.9874 - recall_2: 0.7888 - precision_2: 0.8759 - auc_2: 0.9097 - val_loss: 0.3712 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9351 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8052 - val_precision_2: 0.8493 - val_auc_2: 0.9063\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3627 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9346 - specificity_at_sensitivity_2: 0.9940 - recall_2: 0.8301 - precision_2: 0.8523 - auc_2: 0.9136\n",
            "Epoch 399: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3627 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9346 - specificity_at_sensitivity_2: 0.9940 - recall_2: 0.8301 - precision_2: 0.8523 - auc_2: 0.9136 - val_loss: 0.3406 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9296 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7887 - val_precision_2: 0.9032 - val_auc_2: 0.9185\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3674 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9497 - specificity_at_sensitivity_2: 0.9938 - recall_2: 0.8113 - precision_2: 0.8377 - auc_2: 0.9115\n",
            "Epoch 400: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3674 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9497 - specificity_at_sensitivity_2: 0.9938 - recall_2: 0.8113 - precision_2: 0.8377 - auc_2: 0.9115 - val_loss: 0.3221 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9500 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8500 - val_precision_2: 0.8718 - val_auc_2: 0.9318\n",
            "Epoch 401/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3999 - accuracy: 0.8021 - sensitivity_at_specificity_2: 0.9521 - specificity_at_sensitivity_2: 0.9789 - recall_2: 0.7740 - precision_2: 0.8248 - auc_2: 0.9002\n",
            "Epoch 401: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3961 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9518 - specificity_at_sensitivity_2: 0.9805 - recall_2: 0.7831 - precision_2: 0.8442 - auc_2: 0.9010 - val_loss: 0.3968 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9538 - val_specificity_at_sensitivity_2: 0.9684 - val_recall_2: 0.8154 - val_precision_2: 0.7910 - val_auc_2: 0.9040\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9818 - specificity_at_sensitivity_2: 0.9871 - recall_2: 0.8364 - precision_2: 0.8214 - auc_2: 0.9110\n",
            "Epoch 402: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.3779 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9818 - specificity_at_sensitivity_2: 0.9871 - recall_2: 0.8364 - precision_2: 0.8214 - auc_2: 0.9110 - val_loss: 0.2475 - val_accuracy: 0.9187 - val_sensitivity_at_specificity_2: 1.0000 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9241 - val_precision_2: 0.9125 - val_auc_2: 0.9707\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9512 - specificity_at_sensitivity_2: 0.9872 - recall_2: 0.8049 - precision_2: 0.9103 - auc_2: 0.9193\n",
            "Epoch 403: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3571 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9512 - specificity_at_sensitivity_2: 0.9872 - recall_2: 0.8049 - precision_2: 0.9103 - auc_2: 0.9193 - val_loss: 0.3361 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9367 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8608 - val_precision_2: 0.8831 - val_auc_2: 0.9271\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3740 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9458 - specificity_at_sensitivity_2: 0.9935 - recall_2: 0.8494 - precision_2: 0.8246 - auc_2: 0.9105\n",
            "Epoch 404: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3740 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9458 - specificity_at_sensitivity_2: 0.9935 - recall_2: 0.8494 - precision_2: 0.8246 - auc_2: 0.9105 - val_loss: 0.3775 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9294 - val_specificity_at_sensitivity_2: 0.9867 - val_recall_2: 0.7647 - val_precision_2: 0.9155 - val_auc_2: 0.9109\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9576 - specificity_at_sensitivity_2: 0.9935 - recall_2: 0.8182 - precision_2: 0.8710 - auc_2: 0.9229\n",
            "Epoch 405: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3539 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9576 - specificity_at_sensitivity_2: 0.9935 - recall_2: 0.8182 - precision_2: 0.8710 - auc_2: 0.9229 - val_loss: 0.3352 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9759 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9036 - val_precision_2: 0.8523 - val_auc_2: 0.9457\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9535 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.7733 - precision_2: 0.9110 - auc_2: 0.9146\n",
            "Epoch 406: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3574 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9535 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.7733 - precision_2: 0.9110 - auc_2: 0.9146 - val_loss: 0.3371 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9551 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8202 - val_precision_2: 0.9241 - val_auc_2: 0.9327\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9416 - specificity_at_sensitivity_2: 0.9819 - recall_2: 0.7857 - precision_2: 0.8176 - auc_2: 0.8938\n",
            "Epoch 407: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4086 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9416 - specificity_at_sensitivity_2: 0.9819 - recall_2: 0.7857 - precision_2: 0.8176 - auc_2: 0.8938 - val_loss: 0.2706 - val_accuracy: 0.9062 - val_sensitivity_at_specificity_2: 0.9870 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9351 - val_precision_2: 0.8780 - val_auc_2: 0.9646\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3719 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9595 - specificity_at_sensitivity_2: 0.9728 - recall_2: 0.8035 - precision_2: 0.8854 - auc_2: 0.9152\n",
            "Epoch 408: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3719 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9595 - specificity_at_sensitivity_2: 0.9728 - recall_2: 0.8035 - precision_2: 0.8854 - auc_2: 0.9152 - val_loss: 0.3376 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9647 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9176 - val_precision_2: 0.8478 - val_auc_2: 0.9412\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9471 - specificity_at_sensitivity_2: 0.9924 - recall_2: 0.8677 - precision_2: 0.8497 - auc_2: 0.9096\n",
            "Epoch 409: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3765 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9471 - specificity_at_sensitivity_2: 0.9924 - recall_2: 0.8677 - precision_2: 0.8497 - auc_2: 0.9096 - val_loss: 0.3791 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9429 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8286 - val_precision_2: 0.8169 - val_auc_2: 0.9090\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3475 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9438 - specificity_at_sensitivity_2: 0.9875 - recall_2: 0.8500 - precision_2: 0.8831 - auc_2: 0.9255\n",
            "Epoch 410: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3475 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9438 - specificity_at_sensitivity_2: 0.9875 - recall_2: 0.8500 - precision_2: 0.8831 - auc_2: 0.9255 - val_loss: 0.3580 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7857 - val_precision_2: 0.9041 - val_auc_2: 0.9181\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.8656 - sensitivity_at_specificity_2: 0.9762 - specificity_at_sensitivity_2: 0.9868 - recall_2: 0.8810 - precision_2: 0.8655 - auc_2: 0.9371\n",
            "Epoch 411: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3211 - accuracy: 0.8656 - sensitivity_at_specificity_2: 0.9762 - specificity_at_sensitivity_2: 0.9868 - recall_2: 0.8810 - precision_2: 0.8655 - auc_2: 0.9371 - val_loss: 0.2992 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9867 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7600 - val_precision_2: 0.9344 - val_auc_2: 0.9498\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3509 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9883 - specificity_at_sensitivity_2: 0.9933 - recall_2: 0.8363 - precision_2: 0.8512 - auc_2: 0.9256\n",
            "Epoch 412: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3509 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9883 - specificity_at_sensitivity_2: 0.9933 - recall_2: 0.8363 - precision_2: 0.8512 - auc_2: 0.9256 - val_loss: 0.3018 - val_accuracy: 0.9187 - val_sensitivity_at_specificity_2: 0.9506 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8889 - val_precision_2: 0.9474 - val_auc_2: 0.9348\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3747 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9396 - specificity_at_sensitivity_2: 0.9942 - recall_2: 0.7383 - precision_2: 0.8943 - auc_2: 0.9120\n",
            "Epoch 413: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3747 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9396 - specificity_at_sensitivity_2: 0.9942 - recall_2: 0.7383 - precision_2: 0.8943 - auc_2: 0.9120 - val_loss: 0.3223 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9634 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8537 - val_precision_2: 0.8750 - val_auc_2: 0.9395\n",
            "Epoch 414/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3901 - accuracy: 0.8256 - sensitivity_at_specificity_2: 0.9184 - specificity_at_sensitivity_2: 0.9910 - recall_2: 0.8639 - precision_2: 0.8355 - auc_2: 0.8988\n",
            "Epoch 414: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3784 - accuracy: 0.8276 - sensitivity_at_specificity_2: 0.9264 - specificity_at_sensitivity_2: 0.9921 - recall_2: 0.8589 - precision_2: 0.8383 - auc_2: 0.9057 - val_loss: 0.3576 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9535 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8256 - val_precision_2: 0.8659 - val_auc_2: 0.9211\n",
            "Epoch 415/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3326 - accuracy: 0.8750 - sensitivity_at_specificity_2: 0.9732 - specificity_at_sensitivity_2: 0.9856 - recall_2: 0.8591 - precision_2: 0.8951 - auc_2: 0.9404\n",
            "Epoch 415: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3401 - accuracy: 0.8719 - sensitivity_at_specificity_2: 0.9697 - specificity_at_sensitivity_2: 0.9806 - recall_2: 0.8545 - precision_2: 0.8924 - auc_2: 0.9370 - val_loss: 0.3654 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9277 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8072 - val_precision_2: 0.9178 - val_auc_2: 0.9142\n",
            "Epoch 416/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3414 - accuracy: 0.8646 - sensitivity_at_specificity_2: 0.9645 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.8369 - precision_2: 0.8806 - auc_2: 0.9302\n",
            "Epoch 416: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3536 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9677 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.8323 - precision_2: 0.8658 - auc_2: 0.9242 - val_loss: 0.2775 - val_accuracy: 0.9000 - val_sensitivity_at_specificity_2: 0.9870 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9221 - val_precision_2: 0.8765 - val_auc_2: 0.9657\n",
            "Epoch 417/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4073 - accuracy: 0.8125 - sensitivity_at_specificity_2: 0.9370 - specificity_at_sensitivity_2: 0.9814 - recall_2: 0.7165 - precision_2: 0.8349 - auc_2: 0.8915\n",
            "Epoch 417: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4077 - accuracy: 0.8094 - sensitivity_at_specificity_2: 0.9384 - specificity_at_sensitivity_2: 0.9828 - recall_2: 0.7260 - precision_2: 0.8346 - auc_2: 0.8927 - val_loss: 0.3833 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9277 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8072 - val_precision_2: 0.8590 - val_auc_2: 0.9042\n",
            "Epoch 418/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3522 - accuracy: 0.8507 - sensitivity_at_specificity_2: 0.9710 - specificity_at_sensitivity_2: 0.9800 - recall_2: 0.8333 - precision_2: 0.8519 - auc_2: 0.9252\n",
            "Epoch 418: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3357 - accuracy: 0.8625 - sensitivity_at_specificity_2: 0.9744 - specificity_at_sensitivity_2: 0.9878 - recall_2: 0.8462 - precision_2: 0.8684 - auc_2: 0.9328 - val_loss: 0.2789 - val_accuracy: 0.9062 - val_sensitivity_at_specificity_2: 0.9744 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.9103 - val_precision_2: 0.8987 - val_auc_2: 0.9561\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9643 - specificity_at_sensitivity_2: 0.9737 - recall_2: 0.7917 - precision_2: 0.8693 - auc_2: 0.9098\n",
            "Epoch 419: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3844 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9643 - specificity_at_sensitivity_2: 0.9737 - recall_2: 0.7917 - precision_2: 0.8693 - auc_2: 0.9098 - val_loss: 0.3244 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9634 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8780 - val_precision_2: 0.8372 - val_auc_2: 0.9361\n",
            "Epoch 420/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3982 - accuracy: 0.8160 - sensitivity_at_specificity_2: 0.9542 - specificity_at_sensitivity_2: 0.9778 - recall_2: 0.8039 - precision_2: 0.8425 - auc_2: 0.9014\n",
            "Epoch 420: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3983 - accuracy: 0.8156 - sensitivity_at_specificity_2: 0.9471 - specificity_at_sensitivity_2: 0.9800 - recall_2: 0.8000 - precision_2: 0.8447 - auc_2: 0.9003 - val_loss: 0.3561 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.8923 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8000 - val_precision_2: 0.8667 - val_auc_2: 0.8959\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3614 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9816 - specificity_at_sensitivity_2: 0.9682 - recall_2: 0.8221 - precision_2: 0.8272 - auc_2: 0.9201\n",
            "Epoch 421: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3614 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9816 - specificity_at_sensitivity_2: 0.9682 - recall_2: 0.8221 - precision_2: 0.8272 - auc_2: 0.9201 - val_loss: 0.2651 - val_accuracy: 0.9250 - val_sensitivity_at_specificity_2: 0.9647 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8824 - val_precision_2: 0.9740 - val_auc_2: 0.9580\n",
            "Epoch 422/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4033 - accuracy: 0.8299 - sensitivity_at_specificity_2: 0.9430 - specificity_at_sensitivity_2: 0.9615 - recall_2: 0.7975 - precision_2: 0.8811 - auc_2: 0.8972\n",
            "Epoch 422: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.4021 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9341 - specificity_at_sensitivity_2: 0.9673 - recall_2: 0.7904 - precision_2: 0.8571 - auc_2: 0.8959 - val_loss: 0.3213 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9625 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8500 - val_precision_2: 0.8718 - val_auc_2: 0.9358\n",
            "Epoch 423/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3133 - accuracy: 0.8750 - sensitivity_at_specificity_2: 0.9767 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8372 - precision_2: 0.8780 - auc_2: 0.9435\n",
            "Epoch 423: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3177 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9792 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8194 - precision_2: 0.8806 - auc_2: 0.9417 - val_loss: 0.3257 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9394 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8182 - val_precision_2: 0.8710 - val_auc_2: 0.9134\n",
            "Epoch 424/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3371 - accuracy: 0.8750 - sensitivity_at_specificity_2: 0.9648 - specificity_at_sensitivity_2: 0.9863 - recall_2: 0.8873 - precision_2: 0.8630 - auc_2: 0.9298\n",
            "Epoch 424: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3399 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9551 - specificity_at_sensitivity_2: 0.9878 - recall_2: 0.8654 - precision_2: 0.8654 - auc_2: 0.9262 - val_loss: 0.4014 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7143 - val_precision_2: 0.8955 - val_auc_2: 0.9041\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3409 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9684 - specificity_at_sensitivity_2: 0.9753 - recall_2: 0.8291 - precision_2: 0.8733 - auc_2: 0.9257\n",
            "Epoch 425: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3409 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9684 - specificity_at_sensitivity_2: 0.9753 - recall_2: 0.8291 - precision_2: 0.8733 - auc_2: 0.9257 - val_loss: 0.3816 - val_accuracy: 0.8188 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8101 - val_precision_2: 0.8205 - val_auc_2: 0.9115\n",
            "Epoch 426/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3452 - accuracy: 0.8576 - sensitivity_at_specificity_2: 0.9535 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.8062 - precision_2: 0.8667 - auc_2: 0.9213\n",
            "Epoch 426: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3381 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9577 - specificity_at_sensitivity_2: 0.9944 - recall_2: 0.8099 - precision_2: 0.8647 - auc_2: 0.9253 - val_loss: 0.3338 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_2: 0.9518 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8193 - val_precision_2: 0.9714 - val_auc_2: 0.9280\n",
            "Epoch 427/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3186 - accuracy: 0.8854 - sensitivity_at_specificity_2: 0.9708 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8467 - precision_2: 0.9062 - auc_2: 0.9328\n",
            "Epoch 427: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3314 - accuracy: 0.8750 - sensitivity_at_specificity_2: 0.9671 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8289 - precision_2: 0.9000 - auc_2: 0.9285 - val_loss: 0.3390 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9518 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7952 - val_precision_2: 0.9296 - val_auc_2: 0.9262\n",
            "Epoch 428/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3442 - accuracy: 0.8507 - sensitivity_at_specificity_2: 0.9730 - specificity_at_sensitivity_2: 0.9857 - recall_2: 0.8514 - precision_2: 0.8571 - auc_2: 0.9310\n",
            "Epoch 428: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3555 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9695 - specificity_at_sensitivity_2: 0.9872 - recall_2: 0.8415 - precision_2: 0.8519 - auc_2: 0.9236 - val_loss: 0.4367 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9178 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8082 - val_precision_2: 0.7662 - val_auc_2: 0.8758\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3427 - accuracy: 0.8656 - sensitivity_at_specificity_2: 0.9589 - specificity_at_sensitivity_2: 0.9828 - recall_2: 0.8493 - precision_2: 0.8552 - auc_2: 0.9257\n",
            "Epoch 429: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3427 - accuracy: 0.8656 - sensitivity_at_specificity_2: 0.9589 - specificity_at_sensitivity_2: 0.9828 - recall_2: 0.8493 - precision_2: 0.8552 - auc_2: 0.9257 - val_loss: 0.3331 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9189 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7568 - val_precision_2: 0.9180 - val_auc_2: 0.9129\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9691 - specificity_at_sensitivity_2: 0.9873 - recall_2: 0.8333 - precision_2: 0.8544 - auc_2: 0.9189\n",
            "Epoch 430: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3607 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9691 - specificity_at_sensitivity_2: 0.9873 - recall_2: 0.8333 - precision_2: 0.8544 - auc_2: 0.9189 - val_loss: 0.2952 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9620 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8354 - val_precision_2: 0.9041 - val_auc_2: 0.9450\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9867 - specificity_at_sensitivity_2: 0.9882 - recall_2: 0.8133 - precision_2: 0.8714 - auc_2: 0.9362\n",
            "Epoch 431: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3250 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9867 - specificity_at_sensitivity_2: 0.9882 - recall_2: 0.8133 - precision_2: 0.8714 - auc_2: 0.9362 - val_loss: 0.3631 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9620 - val_specificity_at_sensitivity_2: 0.9753 - val_recall_2: 0.7722 - val_precision_2: 0.9385 - val_auc_2: 0.9218\n",
            "Epoch 432/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3246 - accuracy: 0.8646 - sensitivity_at_specificity_2: 0.9645 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.8298 - precision_2: 0.8864 - auc_2: 0.9328\n",
            "Epoch 432: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3252 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9623 - specificity_at_sensitivity_2: 0.9938 - recall_2: 0.8176 - precision_2: 0.8904 - auc_2: 0.9327 - val_loss: 0.3780 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9200 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7733 - val_precision_2: 0.8788 - val_auc_2: 0.9020\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9490 - specificity_at_sensitivity_2: 0.9816 - recall_2: 0.7834 - precision_2: 0.8483 - auc_2: 0.9068\n",
            "Epoch 433: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3861 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9490 - specificity_at_sensitivity_2: 0.9816 - recall_2: 0.7834 - precision_2: 0.8483 - auc_2: 0.9068 - val_loss: 0.3015 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9765 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8471 - val_precision_2: 0.9231 - val_auc_2: 0.9485\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2896 - accuracy: 0.8656 - sensitivity_at_specificity_2: 0.9931 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8414 - precision_2: 0.8592 - auc_2: 0.9509\n",
            "Epoch 434: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.2896 - accuracy: 0.8656 - sensitivity_at_specificity_2: 0.9931 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8414 - precision_2: 0.8592 - auc_2: 0.9509 - val_loss: 0.2915 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 0.9639 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8434 - val_precision_2: 0.9333 - val_auc_2: 0.9429\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3234 - accuracy: 0.8656 - sensitivity_at_specificity_2: 0.9626 - specificity_at_sensitivity_2: 0.9925 - recall_2: 0.8556 - precision_2: 0.9091 - auc_2: 0.9335\n",
            "Epoch 435: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3234 - accuracy: 0.8656 - sensitivity_at_specificity_2: 0.9626 - specificity_at_sensitivity_2: 0.9925 - recall_2: 0.8556 - precision_2: 0.9091 - auc_2: 0.9335 - val_loss: 0.3851 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_2: 0.9610 - val_specificity_at_sensitivity_2: 0.9880 - val_recall_2: 0.8312 - val_precision_2: 0.7711 - val_auc_2: 0.9118\n",
            "Epoch 436/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3348 - accuracy: 0.8819 - sensitivity_at_specificity_2: 0.9530 - specificity_at_sensitivity_2: 0.9784 - recall_2: 0.8725 - precision_2: 0.8966 - auc_2: 0.9296\n",
            "Epoch 436: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3250 - accuracy: 0.8844 - sensitivity_at_specificity_2: 0.9568 - specificity_at_sensitivity_2: 0.9810 - recall_2: 0.8642 - precision_2: 0.9032 - auc_2: 0.9349 - val_loss: 0.3331 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9296 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7324 - val_precision_2: 0.9811 - val_auc_2: 0.9325\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9620 - specificity_at_sensitivity_2: 0.9815 - recall_2: 0.8418 - precision_2: 0.8261 - auc_2: 0.9142\n",
            "Epoch 437: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3670 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9620 - specificity_at_sensitivity_2: 0.9815 - recall_2: 0.8418 - precision_2: 0.8261 - auc_2: 0.9142 - val_loss: 0.4111 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9059 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7765 - val_precision_2: 0.8250 - val_auc_2: 0.8875\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3560 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9770 - specificity_at_sensitivity_2: 0.9658 - recall_2: 0.7931 - precision_2: 0.8679 - auc_2: 0.9241\n",
            "Epoch 438: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3560 - accuracy: 0.8219 - sensitivity_at_specificity_2: 0.9770 - specificity_at_sensitivity_2: 0.9658 - recall_2: 0.7931 - precision_2: 0.8679 - auc_2: 0.9241 - val_loss: 0.3523 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9600 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7867 - val_precision_2: 0.8429 - val_auc_2: 0.9198\n",
            "Epoch 439/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3241 - accuracy: 0.8566 - sensitivity_at_specificity_2: 0.9565 - specificity_at_sensitivity_2: 0.9917 - recall_2: 0.8478 - precision_2: 0.8797 - auc_2: 0.9341\n",
            "Epoch 439: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3367 - accuracy: 0.8483 - sensitivity_at_specificity_2: 0.9542 - specificity_at_sensitivity_2: 0.9927 - recall_2: 0.8366 - precision_2: 0.8707 - auc_2: 0.9285 - val_loss: 0.3063 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9444 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8333 - val_precision_2: 0.8955 - val_auc_2: 0.9362\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3162 - accuracy: 0.8719 - sensitivity_at_specificity_2: 0.9641 - specificity_at_sensitivity_2: 0.9935 - recall_2: 0.8982 - precision_2: 0.8621 - auc_2: 0.9385\n",
            "Epoch 440: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3162 - accuracy: 0.8719 - sensitivity_at_specificity_2: 0.9641 - specificity_at_sensitivity_2: 0.9935 - recall_2: 0.8982 - precision_2: 0.8621 - auc_2: 0.9385 - val_loss: 0.2874 - val_accuracy: 0.9000 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8205 - val_precision_2: 0.9697 - val_auc_2: 0.9543\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3422 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9861 - specificity_at_sensitivity_2: 0.9773 - recall_2: 0.7639 - precision_2: 0.8397 - auc_2: 0.9302\n",
            "Epoch 441: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3422 - accuracy: 0.8281 - sensitivity_at_specificity_2: 0.9861 - specificity_at_sensitivity_2: 0.9773 - recall_2: 0.7639 - precision_2: 0.8397 - auc_2: 0.9302 - val_loss: 0.3693 - val_accuracy: 0.8250 - val_sensitivity_at_specificity_2: 0.9341 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8132 - val_precision_2: 0.8706 - val_auc_2: 0.9090\n",
            "Epoch 442/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2980 - accuracy: 0.8785 - sensitivity_at_specificity_2: 0.9925 - specificity_at_sensitivity_2: 0.9935 - recall_2: 0.8284 - precision_2: 0.9024 - auc_2: 0.9458\n",
            "Epoch 442: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.2957 - accuracy: 0.8781 - sensitivity_at_specificity_2: 0.9934 - specificity_at_sensitivity_2: 0.9940 - recall_2: 0.8224 - precision_2: 0.9124 - auc_2: 0.9474 - val_loss: 0.3137 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9885 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8161 - val_precision_2: 0.9221 - val_auc_2: 0.9425\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3758 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9613 - specificity_at_sensitivity_2: 0.9818 - recall_2: 0.8903 - precision_2: 0.8118 - auc_2: 0.9164\n",
            "Epoch 443: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3758 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9613 - specificity_at_sensitivity_2: 0.9818 - recall_2: 0.8903 - precision_2: 0.8118 - auc_2: 0.9164 - val_loss: 0.3325 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9333 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8000 - val_precision_2: 0.9091 - val_auc_2: 0.9229\n",
            "Epoch 444/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3489 - accuracy: 0.8403 - sensitivity_at_specificity_2: 0.9605 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8026 - precision_2: 0.8841 - auc_2: 0.9242\n",
            "Epoch 444: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3598 - accuracy: 0.8313 - sensitivity_at_specificity_2: 0.9529 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.7941 - precision_2: 0.8766 - auc_2: 0.9193 - val_loss: 0.3113 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9655 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8506 - val_precision_2: 0.8810 - val_auc_2: 0.9388\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.8656 - sensitivity_at_specificity_2: 0.9618 - specificity_at_sensitivity_2: 0.9755 - recall_2: 0.8535 - precision_2: 0.8701 - auc_2: 0.9261\n",
            "Epoch 445: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3408 - accuracy: 0.8656 - sensitivity_at_specificity_2: 0.9618 - specificity_at_sensitivity_2: 0.9755 - recall_2: 0.8535 - precision_2: 0.8701 - auc_2: 0.9261 - val_loss: 0.2947 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_2: 0.9647 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8235 - val_precision_2: 0.9722 - val_auc_2: 0.9544\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9517 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8138 - precision_2: 0.8872 - auc_2: 0.9322\n",
            "Epoch 446: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3212 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9517 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8138 - precision_2: 0.8872 - auc_2: 0.9322 - val_loss: 0.3275 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7692 - val_precision_2: 0.9091 - val_auc_2: 0.9269\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3509 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9695 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.7988 - precision_2: 0.8506 - auc_2: 0.9230\n",
            "Epoch 447: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3509 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9695 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.7988 - precision_2: 0.8506 - auc_2: 0.9230 - val_loss: 0.3534 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9595 - val_specificity_at_sensitivity_2: 0.9884 - val_recall_2: 0.8784 - val_precision_2: 0.8228 - val_auc_2: 0.9240\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.8844 - sensitivity_at_specificity_2: 0.9818 - specificity_at_sensitivity_2: 0.9935 - recall_2: 0.8485 - precision_2: 0.9211 - auc_2: 0.9486\n",
            "Epoch 448: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.2950 - accuracy: 0.8844 - sensitivity_at_specificity_2: 0.9818 - specificity_at_sensitivity_2: 0.9935 - recall_2: 0.8485 - precision_2: 0.9211 - auc_2: 0.9486 - val_loss: 0.2853 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9868 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8816 - val_precision_2: 0.8701 - val_auc_2: 0.9557\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9684 - specificity_at_sensitivity_2: 0.9877 - recall_2: 0.8418 - precision_2: 0.8418 - auc_2: 0.9201\n",
            "Epoch 449: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3566 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9684 - specificity_at_sensitivity_2: 0.9877 - recall_2: 0.8418 - precision_2: 0.8418 - auc_2: 0.9201 - val_loss: 0.3854 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9054 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7703 - val_precision_2: 0.8906 - val_auc_2: 0.8891\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9804 - specificity_at_sensitivity_2: 0.9880 - recall_2: 0.8235 - precision_2: 0.8400 - auc_2: 0.9267\n",
            "Epoch 450: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3494 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9804 - specificity_at_sensitivity_2: 0.9880 - recall_2: 0.8235 - precision_2: 0.8400 - auc_2: 0.9267 - val_loss: 0.3195 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9398 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8434 - val_precision_2: 0.8974 - val_auc_2: 0.9274\n",
            "Epoch 451/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3556 - accuracy: 0.8507 - sensitivity_at_specificity_2: 0.9684 - specificity_at_sensitivity_2: 0.9692 - recall_2: 0.8354 - precision_2: 0.8859 - auc_2: 0.9225\n",
            "Epoch 451: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3545 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9702 - specificity_at_sensitivity_2: 0.9737 - recall_2: 0.8393 - precision_2: 0.8704 - auc_2: 0.9232 - val_loss: 0.3127 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9747 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8354 - val_precision_2: 0.8800 - val_auc_2: 0.9418\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3419 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9489 - specificity_at_sensitivity_2: 0.9861 - recall_2: 0.8352 - precision_2: 0.8963 - auc_2: 0.9256\n",
            "Epoch 452: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3419 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9489 - specificity_at_sensitivity_2: 0.9861 - recall_2: 0.8352 - precision_2: 0.8963 - auc_2: 0.9256 - val_loss: 0.3427 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_2: 0.9545 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8636 - val_precision_2: 0.8539 - val_auc_2: 0.9223\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3299 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9551 - specificity_at_sensitivity_2: 0.9878 - recall_2: 0.8141 - precision_2: 0.8881 - auc_2: 0.9314\n",
            "Epoch 453: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3299 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9551 - specificity_at_sensitivity_2: 0.9878 - recall_2: 0.8141 - precision_2: 0.8881 - auc_2: 0.9314 - val_loss: 0.2924 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_2: 0.9750 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8625 - val_precision_2: 0.9200 - val_auc_2: 0.9436\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3108 - accuracy: 0.8844 - sensitivity_at_specificity_2: 0.9752 - specificity_at_sensitivity_2: 0.9874 - recall_2: 0.8820 - precision_2: 0.8875 - auc_2: 0.9400\n",
            "Epoch 454: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3108 - accuracy: 0.8844 - sensitivity_at_specificity_2: 0.9752 - specificity_at_sensitivity_2: 0.9874 - recall_2: 0.8820 - precision_2: 0.8875 - auc_2: 0.9400 - val_loss: 0.3745 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9540 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7816 - val_precision_2: 0.9315 - val_auc_2: 0.9136\n",
            "Epoch 455/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3322 - accuracy: 0.8472 - sensitivity_at_specificity_2: 0.9724 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8276 - precision_2: 0.8633 - auc_2: 0.9328\n",
            "Epoch 455: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3476 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9691 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8272 - precision_2: 0.8535 - auc_2: 0.9255 - val_loss: 0.3548 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9306 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8472 - val_precision_2: 0.8356 - val_auc_2: 0.9123\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3953 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9371 - specificity_at_sensitivity_2: 0.9887 - recall_2: 0.7692 - precision_2: 0.8462 - auc_2: 0.8974\n",
            "Epoch 456: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.3953 - accuracy: 0.8344 - sensitivity_at_specificity_2: 0.9371 - specificity_at_sensitivity_2: 0.9887 - recall_2: 0.7692 - precision_2: 0.8462 - auc_2: 0.8974 - val_loss: 0.3351 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9643 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7976 - val_precision_2: 0.8816 - val_auc_2: 0.9308\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3457 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9597 - specificity_at_sensitivity_2: 0.9883 - recall_2: 0.8255 - precision_2: 0.8601 - auc_2: 0.9236\n",
            "Epoch 457: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3457 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9597 - specificity_at_sensitivity_2: 0.9883 - recall_2: 0.8255 - precision_2: 0.8601 - auc_2: 0.9236 - val_loss: 0.3377 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9419 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8372 - val_precision_2: 0.8571 - val_auc_2: 0.9222\n",
            "Epoch 458/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3245 - accuracy: 0.8646 - sensitivity_at_specificity_2: 0.9701 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8263 - precision_2: 0.9324 - auc_2: 0.9389\n",
            "Epoch 458: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3289 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9669 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8287 - precision_2: 0.9146 - auc_2: 0.9330 - val_loss: 0.4259 - val_accuracy: 0.7812 - val_sensitivity_at_specificity_2: 0.9250 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8875 - val_precision_2: 0.7320 - val_auc_2: 0.9138\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.8625 - sensitivity_at_specificity_2: 0.9679 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.8333 - precision_2: 0.8784 - auc_2: 0.9248\n",
            "Epoch 459: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3471 - accuracy: 0.8625 - sensitivity_at_specificity_2: 0.9679 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.8333 - precision_2: 0.8784 - auc_2: 0.9248 - val_loss: 0.2998 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9643 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8333 - val_precision_2: 0.9333 - val_auc_2: 0.9367\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9615 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.8590 - precision_2: 0.8221 - auc_2: 0.9184\n",
            "Epoch 460: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3634 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9615 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.8590 - precision_2: 0.8221 - auc_2: 0.9184 - val_loss: 0.3118 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9620 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7722 - val_precision_2: 0.9683 - val_auc_2: 0.9471\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3748 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9732 - specificity_at_sensitivity_2: 0.9825 - recall_2: 0.7718 - precision_2: 0.8846 - auc_2: 0.9139\n",
            "Epoch 461: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3748 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9732 - specificity_at_sensitivity_2: 0.9825 - recall_2: 0.7718 - precision_2: 0.8846 - auc_2: 0.9139 - val_loss: 0.3540 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9643 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8690 - val_precision_2: 0.8588 - val_auc_2: 0.9282\n",
            "Epoch 462/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3236 - accuracy: 0.8646 - sensitivity_at_specificity_2: 0.9708 - specificity_at_sensitivity_2: 0.9868 - recall_2: 0.8686 - precision_2: 0.8500 - auc_2: 0.9377\n",
            "Epoch 462: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3490 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9459 - specificity_at_sensitivity_2: 0.9884 - recall_2: 0.8446 - precision_2: 0.8333 - auc_2: 0.9210 - val_loss: 0.3711 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9359 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7564 - val_precision_2: 0.9516 - val_auc_2: 0.9085\n",
            "Epoch 463/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3117 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9704 - specificity_at_sensitivity_2: 0.9917 - recall_2: 0.8000 - precision_2: 0.9231 - auc_2: 0.9461\n",
            "Epoch 463: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3206 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9760 - specificity_at_sensitivity_2: 0.9869 - recall_2: 0.8084 - precision_2: 0.9000 - auc_2: 0.9384 - val_loss: 0.4062 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9286 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8452 - val_precision_2: 0.8452 - val_auc_2: 0.8910\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9701 - specificity_at_sensitivity_2: 0.9739 - recall_2: 0.8323 - precision_2: 0.8742 - auc_2: 0.9266\n",
            "Epoch 464: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.3468 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9701 - specificity_at_sensitivity_2: 0.9739 - recall_2: 0.8323 - precision_2: 0.8742 - auc_2: 0.9266 - val_loss: 0.3456 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9468 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7979 - val_precision_2: 0.9494 - val_auc_2: 0.9245\n",
            "Epoch 465/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3264 - accuracy: 0.8566 - sensitivity_at_specificity_2: 0.9587 - specificity_at_sensitivity_2: 0.9854 - recall_2: 0.8099 - precision_2: 0.8750 - auc_2: 0.9330\n",
            "Epoch 465: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3246 - accuracy: 0.8586 - sensitivity_at_specificity_2: 0.9556 - specificity_at_sensitivity_2: 0.9871 - recall_2: 0.8074 - precision_2: 0.8790 - auc_2: 0.9314 - val_loss: 0.3389 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7722 - val_precision_2: 0.9104 - val_auc_2: 0.9284\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9651 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.8198 - precision_2: 0.8704 - auc_2: 0.9193\n",
            "Epoch 466: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3620 - accuracy: 0.8375 - sensitivity_at_specificity_2: 0.9651 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.8198 - precision_2: 0.8704 - auc_2: 0.9193 - val_loss: 0.4158 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9294 - val_specificity_at_sensitivity_2: 0.9867 - val_recall_2: 0.7176 - val_precision_2: 0.8714 - val_auc_2: 0.8923\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9805 - specificity_at_sensitivity_2: 0.9940 - recall_2: 0.8442 - precision_2: 0.8553 - auc_2: 0.9377\n",
            "Epoch 467: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3235 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9805 - specificity_at_sensitivity_2: 0.9940 - recall_2: 0.8442 - precision_2: 0.8553 - auc_2: 0.9377 - val_loss: 0.2865 - val_accuracy: 0.9000 - val_sensitivity_at_specificity_2: 0.9535 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8372 - val_precision_2: 0.9730 - val_auc_2: 0.9439\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3192 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9812 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.8562 - precision_2: 0.8616 - auc_2: 0.9369\n",
            "Epoch 468: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3192 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9812 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.8562 - precision_2: 0.8616 - auc_2: 0.9369 - val_loss: 0.3131 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 0.9444 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8889 - val_precision_2: 0.8649 - val_auc_2: 0.9317\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3771 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9419 - specificity_at_sensitivity_2: 0.9865 - recall_2: 0.7849 - precision_2: 0.8766 - auc_2: 0.9111\n",
            "Epoch 469: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3771 - accuracy: 0.8250 - sensitivity_at_specificity_2: 0.9419 - specificity_at_sensitivity_2: 0.9865 - recall_2: 0.7849 - precision_2: 0.8766 - auc_2: 0.9111 - val_loss: 0.3381 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9405 - val_specificity_at_sensitivity_2: 0.9868 - val_recall_2: 0.8810 - val_precision_2: 0.8810 - val_auc_2: 0.9242\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3426 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9649 - specificity_at_sensitivity_2: 0.9866 - recall_2: 0.8480 - precision_2: 0.9006 - auc_2: 0.9256\n",
            "Epoch 470: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3426 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9649 - specificity_at_sensitivity_2: 0.9866 - recall_2: 0.8480 - precision_2: 0.9006 - auc_2: 0.9256 - val_loss: 0.3264 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9286 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8429 - val_precision_2: 0.8676 - val_auc_2: 0.9257\n",
            "Epoch 471/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3382 - accuracy: 0.8438 - sensitivity_at_specificity_2: 0.9653 - specificity_at_sensitivity_2: 0.9931 - recall_2: 0.8889 - precision_2: 0.8153 - auc_2: 0.9339\n",
            "Epoch 471: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3426 - accuracy: 0.8406 - sensitivity_at_specificity_2: 0.9688 - specificity_at_sensitivity_2: 0.9937 - recall_2: 0.8687 - precision_2: 0.8225 - auc_2: 0.9293 - val_loss: 0.3092 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9756 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7683 - val_precision_2: 0.9692 - val_auc_2: 0.9528\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3110 - accuracy: 0.8781 - sensitivity_at_specificity_2: 1.0000 - specificity_at_sensitivity_2: 0.9686 - recall_2: 0.8571 - precision_2: 0.8961 - auc_2: 0.9452\n",
            "Epoch 472: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3110 - accuracy: 0.8781 - sensitivity_at_specificity_2: 1.0000 - specificity_at_sensitivity_2: 0.9686 - recall_2: 0.8571 - precision_2: 0.8961 - auc_2: 0.9452 - val_loss: 0.4081 - val_accuracy: 0.8062 - val_sensitivity_at_specificity_2: 0.9444 - val_specificity_at_sensitivity_2: 0.9886 - val_recall_2: 0.8333 - val_precision_2: 0.7595 - val_auc_2: 0.9002\n",
            "Epoch 473/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3481 - accuracy: 0.8507 - sensitivity_at_specificity_2: 0.9583 - specificity_at_sensitivity_2: 0.9861 - recall_2: 0.8264 - precision_2: 0.8686 - auc_2: 0.9250\n",
            "Epoch 473: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3522 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9571 - specificity_at_sensitivity_2: 0.9809 - recall_2: 0.8160 - precision_2: 0.8750 - auc_2: 0.9231 - val_loss: 0.2652 - val_accuracy: 0.9062 - val_sensitivity_at_specificity_2: 0.9556 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8889 - val_precision_2: 0.9412 - val_auc_2: 0.9518\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3266 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9625 - specificity_at_sensitivity_2: 0.9875 - recall_2: 0.8438 - precision_2: 0.8710 - auc_2: 0.9327\n",
            "Epoch 474: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3266 - accuracy: 0.8594 - sensitivity_at_specificity_2: 0.9625 - specificity_at_sensitivity_2: 0.9875 - recall_2: 0.8438 - precision_2: 0.8710 - auc_2: 0.9327 - val_loss: 0.3448 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_2: 0.9639 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8313 - val_precision_2: 0.8734 - val_auc_2: 0.9230\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3118 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9879 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8182 - precision_2: 0.8882 - auc_2: 0.9394\n",
            "Epoch 475: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3118 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9879 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8182 - precision_2: 0.8882 - auc_2: 0.9394 - val_loss: 0.2533 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 1.0000 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8966 - val_precision_2: 0.8966 - val_auc_2: 0.9617\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9817 - specificity_at_sensitivity_2: 0.9679 - recall_2: 0.8415 - precision_2: 0.8679 - auc_2: 0.9275\n",
            "Epoch 476: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3441 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9817 - specificity_at_sensitivity_2: 0.9679 - recall_2: 0.8415 - precision_2: 0.8679 - auc_2: 0.9275 - val_loss: 0.2930 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9865 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8514 - val_precision_2: 0.8630 - val_auc_2: 0.9518\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3094 - accuracy: 0.8906 - sensitivity_at_specificity_2: 0.9783 - specificity_at_sensitivity_2: 0.9835 - recall_2: 0.8696 - precision_2: 0.8759 - auc_2: 0.9435\n",
            "Epoch 477: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3094 - accuracy: 0.8906 - sensitivity_at_specificity_2: 0.9783 - specificity_at_sensitivity_2: 0.9835 - recall_2: 0.8696 - precision_2: 0.8759 - auc_2: 0.9435 - val_loss: 0.2802 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 0.9659 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8750 - val_precision_2: 0.9167 - val_auc_2: 0.9508\n",
            "Epoch 478/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3138 - accuracy: 0.8681 - sensitivity_at_specificity_2: 0.9930 - specificity_at_sensitivity_2: 0.9931 - recall_2: 0.8252 - precision_2: 0.9008 - auc_2: 0.9442\n",
            "Epoch 478: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3208 - accuracy: 0.8625 - sensitivity_at_specificity_2: 0.9809 - specificity_at_sensitivity_2: 0.9877 - recall_2: 0.8408 - precision_2: 0.8742 - auc_2: 0.9394 - val_loss: 0.3265 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9324 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8108 - val_precision_2: 0.8696 - val_auc_2: 0.9213\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9805 - specificity_at_sensitivity_2: 0.9940 - recall_2: 0.7857 - precision_2: 0.8832 - auc_2: 0.9348\n",
            "Epoch 479: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3332 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9805 - specificity_at_sensitivity_2: 0.9940 - recall_2: 0.7857 - precision_2: 0.8832 - auc_2: 0.9348 - val_loss: 0.4171 - val_accuracy: 0.7937 - val_sensitivity_at_specificity_2: 0.9630 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8519 - val_precision_2: 0.7667 - val_auc_2: 0.9054\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.8781 - sensitivity_at_specificity_2: 0.9744 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.8462 - precision_2: 0.8980 - auc_2: 0.9362\n",
            "Epoch 480: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3148 - accuracy: 0.8781 - sensitivity_at_specificity_2: 0.9744 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.8462 - precision_2: 0.8980 - auc_2: 0.9362 - val_loss: 0.2703 - val_accuracy: 0.9000 - val_sensitivity_at_specificity_2: 0.9494 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8354 - val_precision_2: 0.9565 - val_auc_2: 0.9495\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2748 - accuracy: 0.8906 - sensitivity_at_specificity_2: 0.9859 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8521 - precision_2: 0.8963 - auc_2: 0.9566\n",
            "Epoch 481: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.2748 - accuracy: 0.8906 - sensitivity_at_specificity_2: 0.9859 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8521 - precision_2: 0.8963 - auc_2: 0.9566 - val_loss: 0.2880 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8205 - val_precision_2: 0.9552 - val_auc_2: 0.9437\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2782 - accuracy: 0.8781 - sensitivity_at_specificity_2: 0.9806 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.8387 - precision_2: 0.9028 - auc_2: 0.9534\n",
            "Epoch 482: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.2782 - accuracy: 0.8781 - sensitivity_at_specificity_2: 0.9806 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.8387 - precision_2: 0.9028 - auc_2: 0.9534 - val_loss: 0.3080 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9615 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8590 - val_precision_2: 0.8933 - val_auc_2: 0.9393\n",
            "Epoch 483/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3356 - accuracy: 0.8750 - sensitivity_at_specificity_2: 0.9398 - specificity_at_sensitivity_2: 0.9871 - recall_2: 0.8496 - precision_2: 0.8760 - auc_2: 0.9252\n",
            "Epoch 483: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3333 - accuracy: 0.8719 - sensitivity_at_specificity_2: 0.9404 - specificity_at_sensitivity_2: 0.9882 - recall_2: 0.8543 - precision_2: 0.8716 - auc_2: 0.9273 - val_loss: 0.3543 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9487 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7821 - val_precision_2: 0.9104 - val_auc_2: 0.9132\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3470 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9706 - specificity_at_sensitivity_2: 0.9867 - recall_2: 0.8294 - precision_2: 0.8924 - auc_2: 0.9281\n",
            "Epoch 484: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3470 - accuracy: 0.8562 - sensitivity_at_specificity_2: 0.9706 - specificity_at_sensitivity_2: 0.9867 - recall_2: 0.8294 - precision_2: 0.8924 - auc_2: 0.9281 - val_loss: 0.3040 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.9620 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8608 - val_precision_2: 0.8718 - val_auc_2: 0.9393\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9756 - specificity_at_sensitivity_2: 0.9936 - recall_2: 0.8598 - precision_2: 0.8813 - auc_2: 0.9440\n",
            "Epoch 485: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3042 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9756 - specificity_at_sensitivity_2: 0.9936 - recall_2: 0.8598 - precision_2: 0.8813 - auc_2: 0.9440 - val_loss: 0.3116 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9877 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8148 - val_precision_2: 0.8919 - val_auc_2: 0.9471\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.8875 - sensitivity_at_specificity_2: 0.9592 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8435 - precision_2: 0.9051 - auc_2: 0.9394\n",
            "Epoch 486: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3084 - accuracy: 0.8875 - sensitivity_at_specificity_2: 0.9592 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8435 - precision_2: 0.9051 - auc_2: 0.9394 - val_loss: 0.3761 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9333 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7556 - val_precision_2: 0.9315 - val_auc_2: 0.9090\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2875 - accuracy: 0.8813 - sensitivity_at_specificity_2: 0.9742 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.8710 - precision_2: 0.8824 - auc_2: 0.9491\n",
            "Epoch 487: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.2875 - accuracy: 0.8813 - sensitivity_at_specificity_2: 0.9742 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.8710 - precision_2: 0.8824 - auc_2: 0.9491 - val_loss: 0.3409 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_2: 0.9487 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7692 - val_precision_2: 0.9231 - val_auc_2: 0.9274\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3398 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9815 - specificity_at_sensitivity_2: 0.9747 - recall_2: 0.8025 - precision_2: 0.8844 - auc_2: 0.9300\n",
            "Epoch 488: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3398 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9815 - specificity_at_sensitivity_2: 0.9747 - recall_2: 0.8025 - precision_2: 0.8844 - auc_2: 0.9300 - val_loss: 0.3335 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.9467 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8400 - val_precision_2: 0.8630 - val_auc_2: 0.9217\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3459 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9548 - specificity_at_sensitivity_2: 0.9790 - recall_2: 0.8588 - precision_2: 0.8736 - auc_2: 0.9236\n",
            "Epoch 489: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3459 - accuracy: 0.8531 - sensitivity_at_specificity_2: 0.9548 - specificity_at_sensitivity_2: 0.9790 - recall_2: 0.8588 - precision_2: 0.8736 - auc_2: 0.9236 - val_loss: 0.3502 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_2: 0.8861 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8101 - val_precision_2: 0.9143 - val_auc_2: 0.8975\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3247 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9815 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8148 - precision_2: 0.8742 - auc_2: 0.9358\n",
            "Epoch 490: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3247 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9815 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8148 - precision_2: 0.8742 - auc_2: 0.9358 - val_loss: 0.2865 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_2: 0.9886 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8636 - val_precision_2: 0.9157 - val_auc_2: 0.9564\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9576 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8606 - precision_2: 0.8452 - auc_2: 0.9330\n",
            "Epoch 491: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3263 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9576 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8606 - precision_2: 0.8452 - auc_2: 0.9330 - val_loss: 0.2713 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 0.9762 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8571 - val_precision_2: 0.9231 - val_auc_2: 0.9633\n",
            "Epoch 492/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3155 - accuracy: 0.8785 - sensitivity_at_specificity_2: 0.9742 - specificity_at_sensitivity_2: 0.9774 - recall_2: 0.8710 - precision_2: 0.9000 - auc_2: 0.9378\n",
            "Epoch 492: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3127 - accuracy: 0.8844 - sensitivity_at_specificity_2: 0.9765 - specificity_at_sensitivity_2: 0.9800 - recall_2: 0.8765 - precision_2: 0.9030 - auc_2: 0.9403 - val_loss: 0.3735 - val_accuracy: 0.8313 - val_sensitivity_at_specificity_2: 0.9103 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7692 - val_precision_2: 0.8696 - val_auc_2: 0.9012\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9744 - specificity_at_sensitivity_2: 0.9756 - recall_2: 0.7949 - precision_2: 0.8857 - auc_2: 0.9348\n",
            "Epoch 493: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3359 - accuracy: 0.8500 - sensitivity_at_specificity_2: 0.9744 - specificity_at_sensitivity_2: 0.9756 - recall_2: 0.7949 - precision_2: 0.8857 - auc_2: 0.9348 - val_loss: 0.2777 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_2: 0.9634 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8415 - val_precision_2: 0.9324 - val_auc_2: 0.9503\n",
            "Epoch 494/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3323 - accuracy: 0.8611 - sensitivity_at_specificity_2: 0.9655 - specificity_at_sensitivity_2: 0.9930 - recall_2: 0.8759 - precision_2: 0.8523 - auc_2: 0.9324\n",
            "Epoch 494: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3458 - accuracy: 0.8469 - sensitivity_at_specificity_2: 0.9636 - specificity_at_sensitivity_2: 0.9935 - recall_2: 0.8667 - precision_2: 0.8412 - auc_2: 0.9271 - val_loss: 0.3141 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9412 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8588 - val_precision_2: 0.9012 - val_auc_2: 0.9329\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3003 - accuracy: 0.8844 - sensitivity_at_specificity_2: 0.9752 - specificity_at_sensitivity_2: 0.9748 - recall_2: 0.8447 - precision_2: 0.9189 - auc_2: 0.9483\n",
            "Epoch 495: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.3003 - accuracy: 0.8844 - sensitivity_at_specificity_2: 0.9752 - specificity_at_sensitivity_2: 0.9748 - recall_2: 0.8447 - precision_2: 0.9189 - auc_2: 0.9483 - val_loss: 0.2528 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9783 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8587 - val_precision_2: 0.9186 - val_auc_2: 0.9568\n",
            "Epoch 496/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3352 - accuracy: 0.8576 - sensitivity_at_specificity_2: 0.9846 - specificity_at_sensitivity_2: 0.9873 - recall_2: 0.8154 - precision_2: 0.8618 - auc_2: 0.9317\n",
            "Epoch 496: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.3252 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9867 - specificity_at_sensitivity_2: 0.9824 - recall_2: 0.8400 - precision_2: 0.8750 - auc_2: 0.9365 - val_loss: 0.2515 - val_accuracy: 0.9062 - val_sensitivity_at_specificity_2: 1.0000 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8734 - val_precision_2: 0.9324 - val_auc_2: 0.9648\n",
            "Epoch 497/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3046 - accuracy: 0.8785 - sensitivity_at_specificity_2: 0.9786 - specificity_at_sensitivity_2: 0.9932 - recall_2: 0.8857 - precision_2: 0.8671 - auc_2: 0.9427\n",
            "Epoch 497: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.3251 - accuracy: 0.8687 - sensitivity_at_specificity_2: 0.9618 - specificity_at_sensitivity_2: 0.9939 - recall_2: 0.8535 - precision_2: 0.8758 - auc_2: 0.9316 - val_loss: 0.2934 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_2: 0.9885 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8506 - val_precision_2: 0.9136 - val_auc_2: 0.9525\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2719 - accuracy: 0.9000 - sensitivity_at_specificity_2: 0.9935 - specificity_at_sensitivity_2: 0.9854 - recall_2: 0.8824 - precision_2: 0.9247 - auc_2: 0.9557\n",
            "Epoch 498: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.2719 - accuracy: 0.9000 - sensitivity_at_specificity_2: 0.9935 - specificity_at_sensitivity_2: 0.9854 - recall_2: 0.8824 - precision_2: 0.9247 - auc_2: 0.9557 - val_loss: 0.3802 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9143 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8429 - val_precision_2: 0.7973 - val_auc_2: 0.8987\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3200 - accuracy: 0.8750 - sensitivity_at_specificity_2: 0.9811 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8553 - precision_2: 0.8889 - auc_2: 0.9387\n",
            "Epoch 499: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.3200 - accuracy: 0.8750 - sensitivity_at_specificity_2: 0.9811 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8553 - precision_2: 0.8889 - auc_2: 0.9387 - val_loss: 0.3345 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_2: 0.9524 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.7857 - val_precision_2: 0.8919 - val_auc_2: 0.9288\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.8719 - sensitivity_at_specificity_2: 0.9821 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8512 - precision_2: 0.8994 - auc_2: 0.9485\n",
            "Epoch 500: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.2954 - accuracy: 0.8719 - sensitivity_at_specificity_2: 0.9821 - specificity_at_sensitivity_2: 1.0000 - recall_2: 0.8512 - precision_2: 0.8994 - auc_2: 0.9485 - val_loss: 0.3707 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_2: 0.8919 - val_specificity_at_sensitivity_2: 1.0000 - val_recall_2: 0.8108 - val_precision_2: 0.8824 - val_auc_2: 0.8902\n"
          ]
        }
      ],
      "source": [
        "#Model Execution\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Initializing Device Specification\n",
        "device_spec = tf.DeviceSpec(job =\"localhost\", replica = 0, device_type = \"GPU\")\n",
        "\n",
        "# Printing the DeviceSpec\n",
        "print('Device Spec: ', device_spec.to_string())\n",
        "\n",
        "# Enabling device logging\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "# Specifying the device\n",
        "with tf.device(device_spec):\n",
        "\n",
        "#with tf.device('/gpu:10'):\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\"ECG_Model_Lead_4.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "    mycallback=tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=180, mode=\"auto\")\n",
        "\n",
        "    history = model.fit(\n",
        "          train_data,\n",
        "          steps_per_epoch=10,\n",
        "          epochs=500,\n",
        "          verbose=1,\n",
        "          validation_data = val_data,\n",
        "          validation_steps=5,\n",
        "          callbacks = [mycallback,checkpoint]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kr7lsoa02UaJ",
        "outputId": "191b3602-c0ff-4425-cb47-3645e0b0ec05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy:  0.8999999761581421\n",
            "Validation Accuracy:  0.9375\n",
            "Validation Specificity:  1.0\n",
            "Validation Sensitivity:  1.0\n",
            "Validation Recall:  1.0\n",
            "Validation Precision:  1.0\n",
            "Validation Loss:  0.2387600690126419\n",
            "Validation AUC:  0.9787868857383728\n"
          ]
        }
      ],
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity_2']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity_2']\n",
        "Validation_Recall=history.history['val_recall_2']\n",
        "Validation_Precision=history.history['val_precision_2']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "Validation_AUC=history.history['val_auc_2']\n",
        "\n",
        "print(\"Training Accuracy: \",np.max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",np.max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",np.max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",np.max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",np.max(Validation_Recall))\n",
        "print(\"Validation Precision: \",np.max(Validation_Precision))\n",
        "print(\"Validation Loss: \",np.min(Validation_Loss))\n",
        "print(\"Validation AUC: \",np.max(Validation_AUC))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvYBl8Er2UaJ",
        "outputId": "788b9efd-a0f8-41d2-955e-8502be70d8c6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to compute moving average\n",
        "def moving_average(data, window_size):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "# Smoothed accuracy values\n",
        "smoothed_train_acc = moving_average(history.history['accuracy'], window_size=5)\n",
        "smoothed_val_acc = moving_average(history.history['val_accuracy'], window_size=5)\n",
        "\n",
        "# Plotting the smoothed training accuracy and validation accuracy\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(smoothed_train_acc, label='Train', linewidth=2)\n",
        "plt.plot(smoothed_val_acc, label='Validate', linewidth=2)\n",
        "\n",
        "# Set the font size for tick labels, legend, and axis labels\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.legend(fontsize=18)\n",
        "\n",
        "# Set axis labels and title with larger font size\n",
        "plt.title('Model Accuracy', fontsize=17)\n",
        "plt.xlabel('Epoch', fontsize=17)\n",
        "plt.ylabel('Accuracy', fontsize=17)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk7zT-9V2UaJ",
        "outputId": "e40c3bd0-351e-437f-ed01-2d6f7133bb87"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to compute moving average\n",
        "def moving_average(data, window_size):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "# Smoothed accuracy values\n",
        "smoothed_train_acc = moving_average(history.history['loss'], window_size=5)\n",
        "smoothed_val_acc = moving_average(history.history['val_loss'], window_size=5)\n",
        "\n",
        "# Plotting the smoothed training accuracy and validation accuracy\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(smoothed_train_acc, label='Train', linewidth=2)\n",
        "plt.plot(smoothed_val_acc, label='Validate', linewidth=2)\n",
        "\n",
        "# Set the font size for tick labels, legend, and axis labels\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.legend(fontsize=18)\n",
        "\n",
        "# Set axis labels and title with larger font size\n",
        "plt.title('Model Loss', fontsize=17)\n",
        "plt.xlabel('Epoch', fontsize=17)\n",
        "plt.ylabel('Accuracy', fontsize=17)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "c2wqNLC72UaJ",
        "outputId": "8fabd360-6658-4825-d2a9-e1ba362a8500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "value of i:  1\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "predicted_class 0, _ 0.3728705942630768\n",
            "File: A0271.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.10767051577568054\n",
            "File: A0274.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.11565909534692764\n",
            "File: A0217.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.13065014779567719\n",
            "File: A0231.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.5327700972557068\n",
            "File: A0019.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.7128469944000244\n",
            "File: A0222.npy, Actual Label: 0, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.29956692457199097\n",
            "File: A0109.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.6096629500389099\n",
            "File: A0071.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.1959541290998459\n",
            "File: A0272.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 0, _ 0.14464466273784637\n",
            "File: A0290.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.5872599482536316\n",
            "File: A0086.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.05838000029325485\n",
            "File: A0153.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.19933918118476868\n",
            "File: A0260.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.29884135723114014\n",
            "File: A0003.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.1062563881278038\n",
            "File: A0150.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.36491236090660095\n",
            "File: A0122.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2107446938753128\n",
            "File: A0126.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.9038585424423218\n",
            "File: A0121.npy, Actual Label: 0, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7202078700065613\n",
            "File: A0186.npy, Actual Label: 0, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.4309619069099426\n",
            "File: A0198.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.5576731562614441\n",
            "File: A0145.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.5084733366966248\n",
            "File: A0101.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.9713764786720276\n",
            "File: A0235.npy, Actual Label: 0, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.44335606694221497\n",
            "File: A0117.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.6008803248405457\n",
            "File: A0184.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.3121112287044525\n",
            "File: A0203.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.34287354350090027\n",
            "File: A0017.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.28348904848098755\n",
            "File: A0205.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 0, _ 0.4012601375579834\n",
            "File: A0257.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.07629764080047607\n",
            "File: A0247.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9167437553405762\n",
            "File: A0061.npy, Actual Label: 0, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.11695221066474915\n",
            "File: A0023.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.475681334733963\n",
            "File: A0279.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.06443943083286285\n",
            "File: A0214.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6848718523979187\n",
            "File: A0009.npy, Actual Label: 0, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2941269278526306\n",
            "File: A0026.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.11338533461093903\n",
            "File: A0007.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.5811687111854553\n",
            "File: A0064.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.37599849700927734\n",
            "File: A0220.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.4246727228164673\n",
            "File: A0267.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.562038004398346\n",
            "File: A0276.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 0, _ 0.0891169011592865\n",
            "File: A0065.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.5953211188316345\n",
            "File: A0004.npy, Actual Label: 0, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9240313768386841\n",
            "File: A0179.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.620647668838501\n",
            "File: A0264.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.4799652397632599\n",
            "File: A0285.npy, Actual Label: 1, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.604103684425354\n",
            "File: A0175.npy, Actual Label: 1, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.8210113048553467\n",
            "File: A0164.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9399847388267517\n",
            "File: A0254.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7292585968971252\n",
            "File: A0029.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9418197870254517\n",
            "File: A0281.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.9713236093521118\n",
            "File: A0075.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.16828180849552155\n",
            "File: A0002.npy, Actual Label: 1, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9015430212020874\n",
            "File: A0166.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.985908567905426\n",
            "File: A0037.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9701622724533081\n",
            "File: A0189.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.1951727718114853\n",
            "File: A0283.npy, Actual Label: 1, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6960530877113342\n",
            "File: A0208.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7980164885520935\n",
            "File: A0233.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2649417519569397\n",
            "File: A0176.npy, Actual Label: 1, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9803732633590698\n",
            "File: A0143.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9956359267234802\n",
            "File: A0177.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7387317419052124\n",
            "File: A0094.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7033441662788391\n",
            "File: A0107.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 0, _ 0.37828564643859863\n",
            "File: A0229.npy, Actual Label: 1, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7525091171264648\n",
            "File: A0141.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9930395483970642\n",
            "File: A0287.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.8244009017944336\n",
            "File: A0073.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9064896702766418\n",
            "File: A0059.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9890016317367554\n",
            "File: A0173.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9904562830924988\n",
            "File: A0133.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.21139302849769592\n",
            "File: A0090.npy, Actual Label: 1, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.8505539894104004\n",
            "File: A0125.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.9459200501441956\n",
            "File: A0089.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 1, _ 0.9870961904525757\n",
            "File: A0041.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.9844897985458374\n",
            "File: A0020.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.9530512094497681\n",
            "File: A0030.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.9884052276611328\n",
            "File: A0190.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.9563250541687012\n",
            "File: A0192.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.818200409412384\n",
            "File: A0206.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "predicted_class 1, _ 0.980941891670227\n",
            "File: A0157.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.9930372834205627\n",
            "File: A0016.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.9849355220794678\n",
            "File: A0193.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "predicted_class 0, _ 0.5191984176635742\n",
            "File: A0221.npy, Actual Label: 1, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.9605023860931396\n",
            "File: A0038.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 0, _ 0.5092232823371887\n",
            "File: A0149.npy, Actual Label: 1, Predicted Label: 0\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 1, _ 0.9767100214958191\n",
            "File: A0170.npy, Actual Label: 1, Predicted Label: 1\n",
            "value of i:  1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.6413947343826294\n",
            "File: A0210.npy, Actual Label: 1, Predicted Label: 1\n",
            "True labels:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "pred labels:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1]\n",
            "\n",
            "Overall Accuracy: 82.95%\n",
            "AUC: 0.8302325581395349\n",
            "Misclassifications:\n",
            "Class 0: 6 misclassifications\n",
            "Class 1: 9 misclassifications\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Proposed Testing Architecture\n",
        "\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "import shutil\n",
        "import scipy\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Normalization layer\n",
        "nrmzln_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "def create_image(file_path, save_dir):\n",
        "    # Load file\n",
        "    x = np.load(file_path)\n",
        "\n",
        "    x= x[0][:5000]\n",
        "    #x_size=np.array(x).flatten()\n",
        "\n",
        "    if len(x) < 5000:\n",
        "        print(f\"Skipping file: {file_path} due to insufficient length.\")\n",
        "        return\n",
        "\n",
        "    #sub_signal = signal[start_idx:end_idx]\n",
        "    #normalized_array = (sub_signal / max(sub_signal)).clip(-1, 1)\n",
        "\n",
        "    plt.figure(figsize=(1.60, 1.62))\n",
        "    plt.plot(x, 'gray')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    sub_image_path = os.path.join(save_dir, f\"{1}.png\")\n",
        "    plt.savefig(sub_image_path, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "#Image Processing and Classification by the Proposed CNN Model\n",
        "def load_image(img_path, target_size=(124, 124)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "\n",
        "    img_tensor = image.img_to_array(img)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "    nrmzln_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
        "    img_tensor = nrmzln_layer(img_tensor)\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "def predict_class(model, img_path, threshold=0.61): #0.51 with ECG_Model_Lead_4_75per_0_50 --> 75% acc. #misclassifications: 11 normal, 11 disease\n",
        "                                                    #0.61 with ECG_Model_Lead_4_83per_0_61 --> 82.95% acc  #misclassifications: 9 normal, 6 disease\n",
        "\n",
        "    img_tensor = load_image(img_path)\n",
        "    pred = model.predict(img_tensor)\n",
        "    return 1 if pred >= threshold else 0, pred[0][0]\n",
        "\n",
        "def evaluate_test_folder(model, test_folder):\n",
        "    class_labels = sorted(os.listdir(test_folder))\n",
        "    total_samples = 0\n",
        "    correct_predictions = 0\n",
        "    misclassifications = {0: 0, 1: 0}\n",
        "    skipped_files = []\n",
        "    true_labels = []\n",
        "    predicted_probabilities = []\n",
        "\n",
        "    for class_label in class_labels:\n",
        "        class_path = os.path.join(test_folder, class_label)\n",
        "        for npy_file in os.listdir(class_path):\n",
        "            npy_path = os.path.join(class_path, npy_file)\n",
        "\n",
        "            # Create three sub-images using create_image function\n",
        "            save_dir = \"path_to/temp_images/\"\n",
        "            create_image(npy_path, save_dir)\n",
        "\n",
        "            for i in range(1, 2):\n",
        "                print(\"value of i: \",i)\n",
        "                sub_image_path = os.path.join(save_dir, f\"{i}.png\")\n",
        "                predicted_class, _ = predict_class(model, sub_image_path)\n",
        "                print(f\"predicted_class {predicted_class}, _ {_}\")\n",
        "\n",
        "            # Get true class label based on folder name\n",
        "            true_class = 0 if class_label == 'disease' else 1\n",
        "\n",
        "            # Print details for each file\n",
        "            print(f\"File: {npy_file}, Actual Label: {true_class}, Predicted Label: {predicted_class}\")\n",
        "\n",
        "            # Print details for each image\n",
        "            #print(f\"Image: {image_file}, Actual Label: {true_class}, Predicted Label: {predicted_class}, Prediction Value: {prediction_value}\")\n",
        "\n",
        "            # Update metrics\n",
        "            total_samples += 1\n",
        "            correct_predictions += 1 if predicted_class == true_class else 0\n",
        "            true_labels.append(true_class)\n",
        "            predicted_probabilities.append(predicted_class)\n",
        "\n",
        "            # Track misclassifications\n",
        "            if predicted_class != true_class:\n",
        "                misclassifications[true_class] += 1\n",
        "\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    auc = roc_auc_score(true_labels, predicted_probabilities)\n",
        "\n",
        "    print(\"True labels: \",true_labels)\n",
        "    print(\"pred labels: \",predicted_probabilities)\n",
        "    print(f\"\\nOverall Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"AUC: {auc}\")\n",
        "    print(\"Misclassifications:\")\n",
        "    for class_label, count in misclassifications.items():\n",
        "        print(f\"Class {class_label}: {count} misclassifications\")\n",
        "\n",
        "    if skipped_files:\n",
        "        print(\"\\nSkipped Files:\")\n",
        "        for skipped_file in skipped_files:\n",
        "            print(skipped_file)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_probabilities)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['disease', 'normal'])\n",
        "    disp.plot(cmap='OrRd', values_format='d', ax=plt.gca(), colorbar=False)\n",
        "    #plt.title(\"Confusion Matrix\", fontsize=16)\n",
        "    plt.xlabel(\"Predicted Labels\", fontsize=14)\n",
        "    plt.ylabel(\"True Labels\", fontsize=14)\n",
        "    plt.xticks(fontsize=13)\n",
        "    plt.yticks(fontsize=13)\n",
        "\n",
        "    # Increase font size for the sample counts inside the matrix\n",
        "    for text in disp.text_.ravel():\n",
        "        text.set_fontsize(14)\n",
        "\n",
        "    # Save the confusion matrix plot\n",
        "    plt.savefig(\"path_to//confusion_matrix_lead_1.png\", dpi=800, bbox_inches='tight')\n",
        "\n",
        "    # Clean up temporary images\n",
        "    files = glob.glob(r'path_to/temp_images/*')\n",
        "    for items in files:\n",
        "        os.remove(items)\n",
        "\n",
        "# Load the model\n",
        "model_path = \"path_to/trained_model/ECG_Model_Lead_1_83per_0_61.h5\"\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Test folder path\n",
        "test_folder_path = 'path_to/test_folder/'\n",
        "\n",
        "# Evaluate the test folder\n",
        "evaluate_test_folder(model, test_folder_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}